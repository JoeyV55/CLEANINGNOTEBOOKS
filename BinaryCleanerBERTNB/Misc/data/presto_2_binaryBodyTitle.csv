pr;Util;NLP;APM;Network;DB;Interpreter;Error Handling;Logging;Lang;Data Structure;DevOps;i18n;Setup;Logic;Microservices;ML;Test;Search;IO;UI;Parser;Security;Cloud;Big Data;Event Handling;App;GIS;Title;Body;prIssue;issue;issueTitle;issueBody;issueComments;issueTitleLink;issueBodyLink;issueCommentsLink;isPR;isTrain;commitMessage;Comments
2;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add byte backed tuple and block implementations;the code only supportes fixed with columns   and has some hacks to get width information into the operators  but it does generally show the direction.;;0;add byte backed tuple and block implementations;the code only supportes  with columns  and has some hacks to get width information into the operators but it does generally show the direction;looks good enough ||;;;;1;1;add byte backed blocks and tuplesadd slice code from level dbtuples and blocks only support  with data;
4;1;0;0;0;0;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add support for variable length fields;;;0;add support for variable length fields;;good enough ||;;;;1;1;skip offset field for first variable length field;
5;1;0;0;0;0;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add tuple builder;;;0;add tuple builder;;;;;;1;1;introduce tuple builder;
6;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;extract slice interface;;;0;extract slice interface;;;;;;1;1;extract slice interface;
8;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;minor fixes;;;0;minor fixes;;;;;;1;1;rename testsumaggregation -> testaggregations;
9;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;add maskedvalueblock;block filters now simply returns a masked value block add filter to position block;;0;add maskedvalueblock;block filters now simply returns a masked value blockadd filter to position block;updated for review feed back (which you can see here  || ;;;;1;1;add maskedvalueblockblock filters now simply returns a masked value blockadd filter to position block;
15;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;get rid of empty blocks;filter methods now return optional<> instead. operators never produce an empty block.;;0;get rid of empty blocks;filter methods now return optional<> instead operators never produce an empty block;;;;;1;1;get rid of empty blocksfilter methods now return optional<> instead operators never produce an empty block;
20;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;add simple console printer;;;0;add simple console printer;;;;;;1;1;add simple console printer;
22;1;0;0;0;0;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;use guava objects.tostringhelper;;;0;use guava objectstostringhelper;;;;;;1;1;use guava objectstostringhelper;
23;1;0;0;0;0;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;added outputstreamsliceoutput;- also consolidated writezero(int length) generic impl into base class - removed duplicate of readslice from sliceinput;;0;added outputstreamsliceoutput;- also consolidated writezero(int length) generic impl into base class- removed duplicate of readslice from sliceinput;;;;;1;1;adding outputstreamsliceoutput;
24;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;implement cursor and blockstream;;;0;implement cursor and blockstream;;;;;;1;1;implement cursor and blockstream;
27;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add blockstream aggregation implementations and benchmarks;;;0;add blockstream aggregation implementations and benchmarks;;;;;;1;1;minor fixes for #27;
28;1;0;0;1;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;move some classes to new packages;;;0;move some classes to new packages;;;;;;1;1;move operators to comfbprestooperators;
29;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;remove old groupby and aggregation code;;;0;remove old groupby and aggregation code;;minor comments but overall ;;;;1;1;remove old groupby and aggregation code;
36;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;rewrite columnprocessor and data import;;;0;rewrite columnprocessor and data import;;;;;;1;1;rewrite columnprocessor and data import;
38;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;cursor redesign;;;0;cursor redesign;;;;;;1;1;changes for review #38;
39;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add query testing framework;;;0;add query testing framework;;great start! check out the comments and then merge it ||;;;;1;1;add query testing framework;
41;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;add double data type;;;0;add double data type;;;;;;1;1;use sizeof constants instead of literal numbers;
42;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;implement aggregation operator without group by;;;0;implement aggregation operator without group by;;;;;;1;1;implement aggregation operator without group by;
44;1;0;1;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;reorganize code;move all block related code to blocks with sub package for each encoding type move cvs import code to inject package move benchmark code to a benchmark package in tests;;0;reorganize code;move all block related code to blocks with sub package for each encoding typemove cvs import code to inject packagemove benchmark code to a benchmark package in tests;;;;;1;1;reorganize codemove all block related code to blocks with sub package for each encoding typemove cvs import code to inject packagemove benchmark code to a benchmark package in tests;
46;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add lineitem table for testing;;;0;add lineitem table for testing;;;;;;1;1;add lineitem table for testing;
50;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;additions to testqueries and other minor fixes;;;0;additions to testqueries and other minor fixes;;;;;;1;1;update average aggregation to operate on and produce doubles;
53;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;binary and comparison operators  tests and bug fixes;initial take on binary and comparison operators. for now  they can only operate on specific types. we need to figure out how to generalize them later.;;0;binary and comparison operators tests and bug fixes;initial take on binary and comparison operators for now they can only operate on specific types we need to figure out how to generalize them later;;;;;1;1;rename datascan2 and 3;
55;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;update cursor api comments;;;0;update cursor api comments;;;;;;1;1;update cursor comments;
56;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add isvalid method cursor;;;0;add isvalid method cursor;;;;;;1;1;add isvalid method cursor;
57;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;implement and operator;;;0;implement and operator;; applied comments from 2bf86a85dc67004e2b35c77602c40b2705105cde and rebased ||;;;;1;1;and operator;
60;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;implement or operator + other minor fixes;;;0;implement or operator + other minor fixes;;;;;;1;1;implement or operator;
61;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;cleanup and consolidate cursor test code;;;0;cleanup and consolidate cursor test code;;;;;;1;1;cleanup and consolidate cursor test code;
65;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;early benchmark framework;- benchmarks will need to extend abstractbenchmark class - this version hardcodes dropping data as csv and jmeter output files - jmeter *.jtl files can be picked up by jenkins performance plugin for build perf history - csv files will be used to submit data with post processing command to ods  all of the benchmarks can be run with: mvn clean install exec:java;;0;early benchmark framework;- benchmarks will need to extend abstractbenchmark class- this version hardcodes dropping data as csv and jmeter output files- jmeter *jtl files can be picked up by jenkins performance plugin for build perf history- csv files will be used to submit data with post processing command to odsall of the benchmarks can be run with:mvn clean install exec:java;open to suggestions on this i still need to convert the existing benchmarks into this format and we need to define a dataset that will be used (will need to be uploaded to build server) || this should be good to go now i added a workaround for getting in the benchmark tpch jar file via system property until intellij can fix their stuff || ;;;;1;1;address review comments in pull #65;
66;1;0;0;1;1;1;0;0;1;0;1;1;1;1;0;0;1;0;1;1;1;0;1;1;0;1;1;add sql parser;;;0;add sql parser;;;;;;1;1;add sql parser;
67;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;1;1;1;1;1;1;1;0;1;1;add joins to ast;;;0;add joins to ast;;;;;;1;1;add joins to ast;
68;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add basic support for distributed tuple streams;;;0;add basic support for distributed tuple streams;;;;;;1;1;address feedback from review #68;
69;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;ast visitor framework and basic semantic analysis;;;0;ast visitor framework and basic semantic analysis;;;;;;1;1;make visitor methods in ast printer protected;
70;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add all columns to test data set;;;0;add all columns to test data set;;;;;;1;1;add all columns to test data set;
71;1;0;0;0;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;yield support;;;0;yield support;;;;;;1;1;remove unused aggregationfunctionaddcurrentposition() method;
72;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0; where aggregations advance past end position and add tests;;;0; where aggregations advance past end position and add tests;;looks good except that this will conflict with my pull request || stop whining :p ||;;;;1;1; where aggregations advance past end position and add tests;
75;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;1;1;1;1;1;0;1;1;setup multi-module project structure;;;0;setup multi-module project structure;;;;;;1;1;setup multi-module project structure;
76;1;0;1;0;1;1;0;0;0;0;1;0;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;create dedicated ods output file generator to improve ods export speed & add benchmark warmups;- also adjust the iterations for the benchmarks to run a little faster;;0;create dedicated ods output file generator to improve ods export speed & add benchmark warmups;- also adjust the iterations for the benchmarks to run a little faster;;;;;1;1;create dedicated ods output file generator to improve ods export speed & add benchmark warmups- also adjust the iterations for the benchmarks to run a little faster;
77;1;0;0;0;0;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add basic presto tuplestream operators that will be needed for imports or just generally useful;- add delimitedtuplestream - add materializingtuplestream - migrate all cursors to calling: cursors.checkreadableposition(this) to validate read access availability;;0;add basic presto tuplestream operators that will be needed for imports or just generally useful;- add delimitedtuplestream- add materializingtuplestream- migrate all cursors to calling: cursorscheckreadableposition(this) to validate read access availability; ship it ||;;;;1;1;fix bug in blockbuilder;
81;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;1;1;0;1;0;1;1;0;1;0;refactor metadata interfaces;;;0;refactor metadata interfaces;;;;;;1;1;refactor metadata interfaces;
82;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;hive importer + bug fixes + performance optimizations;still a little rough around the edges  but does what we need for the demo.;;0;hive importer + bug fixes + performance optimizations;still a little rough around the edges but does what we need for the demo;other than the comments above ;;;;1;1;fix review comments in #82;
86;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;integrate metadata with hiveimportmanager;;;0;integrate metadata with hiveimportmanager;;;;;;1;1;integrate metadata with hiveimportmanager;
89;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;add basic interactive console;;;0;add basic interactive console;;;;;;1;1;add basic interactive console;
90;1;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;1;0;0;1;0;1;0;add table and column handles;;;0;add table and column handles;;;;;;1;1;add handles for native tables;
93;1;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;limit and topn operator;;;0;limit and topn operator;;;;;;1;1;fix review comments for pull #93;
94;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;actually use a filter in query benchmark;;;0;actually use a filter in query benchmark;;;;;;1;1;actually use a filter in query benchmark;
"95;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;add support for selecting with qualified wildcard from anonymous columns;queries of this form are now resolved correctly:      sql select t.* from (     select a + b     from u ) t      note that the expression  a + b  doesn t have an alias;;0;add support for selecting with qualified wildcard from anonymous columns;""queries of this form are now resolved correctly:``` sqlselect t*from (    select a + b    from u) t```note that the expression """"a + b"""" doesnt have an alias"";;;;;1;1;""add support for selecting with qualified wildcard from anonymous columnsqueries of this form are now supported:select t*from (    select a + b    from u) tnote that the expression """"a + b"""" doesnt have an alias"";"
97;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;add support for limit;;;0;add support for limit;;;;;;1;1;add support for limit;
98;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;topn benchmark;;;0;topn benchmark;;;;;;1;1;topn benchmark;
99;1;0;0;0;1;0;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;speed improvements;;;0;speed improvements;;;;;;1;1;minor performance improvement for aggregationoperator;
100;1;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add in memory order by operator;this is a very ghetto in memory implementation of order by that materializes all tuples and sorts them. this should be good for what we need at this point in time.;;0;add in memory order by operator;this is a very ghetto in memory implementation of order by that materializes all tuples and sorts them this should be good for what we need at this point in time;;;;;1;1;in memory orderby operator;
103;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;fix perf regression;;;0;fix perf regression;;;;;;1;1;dont insert final projection if final output matches underlying operators outputfix perf regression from 7cf6562f81b887c708add96711137ee3c1ee0395;
106;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;null support;add isnull(field) to tuplereadable null is stored in a bit vector at the head of the tuple aggregates (except) count skip null values;;0;null support;add isnull(field) to tuplereadablenull is stored in a bit vector at the head of the tupleaggregates (except) count skip null values;;;;;1;1;changes for review #106;
107;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;merge columnscan and align plan nodes into a single logical tablescan node;;;0;merge columnscan and align plan nodes into a single logical tablescan node;;otherwise ;;;;1;1;merge columnscan and align into a single logical tablescan node;
108;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add sum(double) benchmark;;;0;add sum(double) benchmark;;;;;;1;1;add sum(double) benchmark;
109;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;1;tuple info in operator;;;0;tuple info in operator;;;;;;1;1;add tuple info to operator blockiterable blockencoding and so on;
110;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;1;0;0;0;0;1;0;add distributed data imports;;;0;add distributed data imports;;good enough for me ||;;;;1;1;changes for review #110;
112;1;0;1;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;intermediate aggregates;;;0;intermediate aggregates;;;;;;1;1;add partial aggregation support;
113;1;0;0;1;1;0;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;update to spi package and fix imports;;;0;update to spi package and fix imports;;;;;;1;1;fix imports to use correct classes;
114;1;0;0;1;1;1;0;0;1;1;1;0;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add handles + jackson serialization formats;;;0;add handles + jackson serialization formats;;;;;;1;1;split handles;
115;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;1;add vectorized aggregationoperator;;;0;add vectorized aggregationoperator;;;;;;1;1;add vectorized aggregationoperator;
117;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add managers for metastore and datastreamproviders;- also make some needed  augmentations to metastore interface;;0;add managers for metastore and datastreamproviders;- also make some needed  augmentations to metastore interface;i will fix the remaining comments that touch a lot of files in another pull request || ;;;;1;1;more review comments for pull #117;
"118;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;aggregation function improvements;- add intermediate types to aggregation functioninfo (in preparation for distributed plan creation) - rename fullaggregationfunction to aggregationfunction -- the  public  aggregation class  - rename aggregationfunction to aggregationfunctionstep -- an aggregation function specialized on one of the execution steps (single-node  combine  intermediate  final) - mechanism for instantiating aggregation functions bound to inputs in physical plan. this is so that we can get rid of the hard-coded if-then-else checks in executionplanner  also  fix source of potential bugs in page.;;0;aggregation function improvements;""- add intermediate types to aggregation functioninfo (in preparation for distributed plan creation)- rename fullaggregationfunction to aggregationfunction -- the """"public"""" aggregation class - rename aggregationfunction to aggregationfunctionstep -- an aggregation function specialized on one of the execution steps (single-node combine intermediate final)- mechanism for instantiating aggregation functions bound to inputs in physical plan this is so that we can get rid of the hard-coded if-then-else checks in executionplanneralso fix source of potential bugs in page"";;;;;1;1;rename fullaggregationfunction and aggregationfunction;"
119;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;1;0;1;1;0;1;0;add splitmanager;;;0;add splitmanager;;;;;;1;1;add splitmanager;
123;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;1;1;0;1;0;1;1;0;1;0;don t contact metastore when reading data;;;0;dont contact metastore when reading data;;;;;;1;1;dont contact metastore when reading data;
124;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;0;use discovery instead of hard coded hiveclient;;;0;use discovery instead of hard coded hiveclient;;other than those extra copies generated this looks good enough for now ||;;;;1;1;inject importclientfactory instead of importclient;
126;1;0;1;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;migrate tpch test data system to be compliant with metadata and datastreamprovider;- this affects the benchmark code as well as the testqueries. - there is currently a temporary hack with the legacystoragemanager to allow it to interface with the executionplanner  but all those hacks should be removed once executionplanner switches to using datastreamproviders.;;0;migrate tpch test data system to be compliant with metadata and datastreamprovider;- this affects the benchmark code as well as the testqueries- there is currently a temporary hack with the legacystoragemanager to allow it to interface with the executionplanner but all those hacks should be removed once executionplanner switches to using datastreamproviders;did you run the benchmarks and verify that this doesnt effect the performance? || yup i did run the benchmarks and all the values seem to be in the appropriate ballparks this was on my local machinebtw updated revision based on comments || i was hoping that you could unify the tpchdataprovider and friends with the storagemanager and metadata interfaces but this is good enough for now merge it ||;;;;1;1;migrate tpch test data system to metadata and datastreamprovider paradigms;
127;1;0;1;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;replace slot/slotreference with sql-parseable symbol;also  other minor changes in preparation for distributed planning and execution;;0;replace slot/slotreference with sql-parseable symbol;also other minor changes in preparation for distributed planning and execution;;;;;1;1;replace slot with symbol and remove slotreferencesymbols are parseable sql identifiers so they can be used to serialize and deserialize rewritten expressions;
128;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;schedule improvements;;;0;schedule improvements;;;;;;1;1;wait for a query phase to start before starting the next phase;
131;1;0;0;0;1;1;0;0;0;1;1;0;0;0;0;0;0;0;0;0;1;0;0;1;0;1;0;distributed sql execution and other fixes;;;0;distributed sql execution and other fixes;;;;;;1;1;address review feedback #131;
132;1;0;0;1;1;1;0;0;0;1;1;0;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;initial feedback implementation;;;0;initial feedback implementation;;;;;;1;1;initial feedback implementation;
133;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;fix npe when printing null columns;;;0;fix npe when printing null columns;;;;;;1;1;fix npe when printing null columns;
134;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;minor feedback fixes;;;0;minor feedback fixes;;;;;;1;1;fix feedback state bug and remove sleep statement;
136;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;add more feedback data;;;0;add more feedback data;;looks good those minor issue can be  later ||;;;;1;1;add more feedback data;
137;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;0;0;1;1;0;1;0;fix  timeout and reliability issues;;;0;fix  timeout and reliability issues;;;;;;1;1;fix  timeout and reliability issues;
138;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;fix bug in reporting of running tasks;;;0;fix bug in reporting of running tasks;;;;;;1;1;fix bug in reporting of running tasks;
142;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;join logical planning and other fixes;;;0;join logical planning and other fixes;;;;;;1;1;graphviz printer for distributed plans;
143;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;add basic support for join  using;;;0;add basic support for join  using;;;;;;1;1;add basic support for join  using;
144;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;refactor columnprinter into outputprocessor;;;0;refactor columnprinter into outputprocessor;;good to go ||;;;;1;1;refactor columnprinter into outputprocessor;
145;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;0;1;new hash and sort;;;0;new hash and sort;;;;;;1;1;cleanup blockshash blocksindex pagesindexrename blockshash and blocksindex to channelhash and channelindexdocument datastructuresextract synthetic address code into shared utility;
146;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;single-node join plans  test and benchmark;;;0;single-node join plans test and benchmark;;push it ||;;;;1;1;add join sql benchmark;
148;1;0;1;0;1;0;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;devirtualize benchmark innerloop;;;0;devirtualize benchmark innerloop;;;;;;1;1;devirtualize benchmark innerloop;
149;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;add aligned output;;;0;add aligned output;;looks good but fix the field names issue before pushing ||;;;;1;1;extract statusprinter;
"150;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;move uses of  session  up the analysis stack;split session out of sessionmetadata and make all the components in the planning stack depend on metadata except for the analyzer.;;0;""move uses of """"session"""" up the analysis stack"";split session out of sessionmetadata and make all the components in the planning stack depend on metadata except for the analyzer;;;;;1;1;""move uses of """"session"""" up the analysis stacksplit session out of sessionmetadata and make all the components in the planning stack depend on metadata except for the analyzer"";"
154;1;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;log errors reported to the querystate object;;;0;log errors reported to the querystate object;;;;;;1;1;log errors reported to the querystate object;
155;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;inject httpclients;;;0;inject httpclients;;;;;;1;1;inject httpclients;
156;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;add debug flag to console;;;0;add debug flag to console;;;;;;1;1;add debug flag to console;
161;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;fix bug in group by column with output alias;;;0;fix bug in group by column with output alias;;;;;;1;1;fix bug in group by column with output alias;
163;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix bug in count aggregation from inline view;this query now works:  select count(*) from (select  ) x;;0;fix bug in count aggregation from inline view;this query now works:select count(*) from (select  ) x;;;;;1;1;fix bug in count aggregation from inline viewthis query now works:select count(*) from (select  ) x;
164;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;allow hash aggregation with no aggregation functions;;;0;allow hash aggregation with no aggregation functions;;;;;;1;1;allow hash aggregation with no aggregation functions;
165;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;1;0;0;0;0;0;1;0;add internal table support;;;0;add internal table support;;we should talk about the approach for exposing this kind of metadata in a generalized way im not convinced that adding tons of specialized methods to metadata is the right way but i need to think about it moreits good enough for now so ship it! ||;;;;1;1;add basic show tables;
167;1;0;0;1;1;1;1;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;schedule internal splits on current node;;;0;schedule internal splits on current node;;;;;;1;1;schedule internal splits on current node;
168;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;implement group by w/o aggregations;;;0;implement group by w/o aggregations;;;;;;1;1;add support for group by without aggregations;
169;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;implement order by;;;0;implement order by;;;;;;1;1;implement order by;
171;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;fixed bug when building sort execution plan;;;0; bug when building sort execution plan;;;;;;1;1; bug when building sort execution plan;
"172;1;0;0;1;1;1;0;0;0;0;1;1;1;1;0;0;0;0;1;1;0;0;1;1;0;1;0;cleanup and organize;;;0;cleanup and organize;;;;;;1;1;""remove leading """"sql:"""" from queries"";"
174;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;console improvements;;;0;console improvements;; ;;;;1;1;pipe query output to less;
175;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;implement partition pruning for hive tables;these changes depend on  https://github.com/facebook/presto-hive/pull/10;;0;implement partition pruning for hive tables;these changes depend on  https://githubcom/facebook/presto-hive/pull/10;;;;;1;1;partition pruning for hive tables;
176;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;fix bug when partition key does not appear in predicate;;;0;fix bug when partition key does not appear in predicate;;;;;;1;1;fix bug when partition key does not appear in predicate;
"177;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add dual table;;;0;add dual table;;""looks good for me now add optional the optional from clause! || do we need a dual table if we are going to have optional """"from"""" clause? || we thought we could use the dual table to implement that at least for now it might be nice to have it anyway for compatibility with oracle and mysql (they have a limited one for compatibility with oracle) || "";;;;1;1;add dual table;"
178;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;add system tables and add internal tables to metadata;;;0;add system tables and add internal tables to metadata;;;;;;1;1;add structure for system tables;
179;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;don t add special commands to history;;;0;dont add special commands to history;;;;;;1;1;dont add special commands to history;
181;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;implement distinct;;;0;implement distinct;;;;;;1;1;implement distinct;
182;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;0;bookkeeping;rewrite bookkeeping objects to be correct and thread safe added stage abstraction add more stats and cleanup stats collection record exceptions in info objects and propagate to client add multiline progress to console;;0;bookkeeping;rewrite bookkeeping objects to be correct and thread safeadded stage abstractionadd more stats and cleanup stats collectionrecord exceptions in info objects and propagate to clientadd multiline progress to console;;;;;1;1;add more execution stats and properly record query end time;
185;1;0;0;1;1;1;0;0;0;1;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;convert query queued time to mills;;;0;convert query queued time to mills;;;;;;1;1;convert query queued time to mills;
187;1;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;1;0;add max and min aggregations;;;0;add max and min aggregations;;;;;;1;1;add max and min aggregations;
188;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;add support for mysql;;;0;add support for mysql;;;;;;1;1;fix console default server uri;
191;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;column aligned console status output format;;;0;column aligned console status output format;;looks good other than that bug ||;;;;1;1;fix output size calculations;
194;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;fix stuck task issue;;;0;fix stuck task issue;;;;;;1;1;move finish to finally block;
195;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;make localexecutionplanner use a visitor;;;0;make localexecutionplanner use a visitor;;;;;;1;1;make localexecutionplanner use a visitor;
196;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;properly handle the user aborting the pager;;;0;properly handle the user aborting the pager;;;;;;1;1;properly handle the user aborting the pager;
197;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;fix split reporting code;;;0;fix split reporting code;;;;;;1;1;fix split reporting code;
203;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;rename newinmemoryorderbyoperator to inmemoryorderbyoperator;remove old inmemoryorderbyoperator code;;0;rename newinmemoryorderbyoperator to inmemoryorderbyoperator;remove old inmemoryorderbyoperator code;;;;;1;1;rename newinmemoryorderbyoperator to inmemoryorderbyoperator;
204;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;add flag to disable import support;;;0;add flag to disable import support;;wheres the config test!? ;;;;1;1;add flag to disable import support;
206;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;show decimal values in console status;;;0;show decimal values in console status;;c is for cookie thats good enough for me ||;;;;1;1;show decimal values in console status;
207;1;0;0;0;1;0;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;flat hash aggregation;;;0;flat hash aggregation;;;;;;1;1;add documentation null checks and minor cleanup for review #207;
208;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;0;nodes must now declare supporte import clients;;;0;nodes must now declare supporte import clients;;;;;;1;1;nodes must now declare supporte import clients;
209;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;0;limit target nodes for presto imports;;;0;limit target nodes for presto imports;;;;;;1;1;limit target nodes for presto imports;
210;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;limit threads;;;0;limit threads;;;;;;1;1;change task thread pool to an unlimited cached thread pool;
211;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;query gc;;;0;query gc;;other than that potential concurrency issue it ;;;;1;1;cancel abandonded queries;
213;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;handle aborting queries in console;;;0;handle aborting queries in console;;;;;;1;1;handle aborting queries in console;
214;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;show query status during planning;;;0;show query status during planning;;;;;;1;1;format positions for single line status output;
215;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;pass list of columns to importclient;;;0;pass list of columns to importclient;;;;;;1;1;pass list of columns to importclient;
217;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;record now returns byte for getstring();this depends on https://github.com/facebook/presto-hive/pull/14;;0;record now returns byte for getstring();this depends on https://githubcom/facebook/presto-hive/pull/14;;;;;1;1;record now returns byte for getstring();
218;1;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;handle multi-line queries in console;;;0;handle multi-line queries in console;;other then the minor comments and questions ;;;;1;1;fix quoted string handling in statementsplitter;
219;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add basic string functions;yes  the function invocation is a horrible hack and needs to be implemented correctly.;;0;add basic string functions;yes the function invocation is a horrible hack and needs to be implemented correctly;;;;;1;1;add basic string functions;
220;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;handle user interrupt (ctrl-c) in console;;;0;handle user interrupt (ctrl-c) in console;;;;;;1;1;handle user interrupt (ctrl-c) in console;
221;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;change to recordcursor and pass column ids instead of names to hive client api;;;0;change to recordcursor and pass column ids instead of names to hive client api;;;;;;1;1;pass correct column id to hive clientit was passing the column ordinal in the projected output instead of the underlying column id;
222;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;remove querystate from querycreatedevent;;;0;remove querystate from querycreatedevent;;;;;;1;1;remove state from querycreatedevent;
223;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;1;1;1;0;1;1;make catalog  schema and user configurable in client;;;0;make catalog schema and user configurable in client;;;;;;1;1;make catalog schema and user configurable in client;
224;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;partial query cancel;;;0;partial query cancel;;;;;;1;1;ctrl-c while query is running cancels leaf most running stage;
225;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;add proper cpu and user time to query stats;;;0;add proper cpu and user time to query stats;;;;;;1;1;add proper cpu and user time to query stats;
228;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;improve console status printing;;;0;improve console status printing;;;;;;1;1;clean up console status printing;
229;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add disabled tests for order by that highlight broken semantics;;;0;add disabled tests for order by that highlight broken semantics;;;;;;1;1;add disabled tests for order by that highlight broken semantics;
230;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;functions;;;0;functions;;;;;;1;1;implement round() function;
232;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;implement like;;;0;implement like;;;;;;1;1;implement like;
233;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;implement between;;;0;implement between;;;;;;1;1;implement between;
235;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;implement in list;;;0;implement in list;;;;;;1;1;implement in list;
238;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;implement case statement;;;0;implement case statement;;;;;;1;1;implement case statement;
239;1;0;0;1;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;implement cast;;;0;implement cast;;;;;;1;1;implement cast;
242;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;implement count column;;;0;implement count column;;;;;;1;1;implement count column;
245;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;1;make session available to expression interpreter and functions;session is passed from coordiator to tasks during creation add start time to session change current_timestamp to use session start time;;0;make session available to expression interpreter and functions;session is passed from coordiator to tasks during creationadd start time to sessionchange current_timestamp to use session start time;;;;;1;1;make session available to expression interpreter and functionssession is passed from coordiator to tasks during creationadd start time to sessionchange current_timestamp to use session start time;
246;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;0;support show tables and show columns for hive;;;0;support show tables and show columns for hive;;;;;;1;1;support show tables and show columns for hive;
251;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;1;1;0;1;1;1;1;0;1;0;add show partitions for hive;;;0;add show partitions for hive;;;;;;1;1;add show partitions for hive;
253;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;1;1;1;0;1;0;use dynamic columns for show partitions output;;;0;use dynamic columns for show partitions output;;;;;;1;1;use dynamic columns for show partitions output;
254;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;announce presto coordinators;;;0;announce presto coordinators;;;;;;1;1;announce presto coordinators;
255;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;make hive chunk size configurable;;;0;make hive chunk size configurable;;;;;;1;1;make hive chunk size configurable;
257;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;fix parsing of non-reserved keywords;;;0;fix parsing of non-reserved keywords;;;;;;1;1;fix parsing of non-reserved keywords;
258;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;optimize projections and filters during logical planning;;;0;optimize projections and filters during logical planning;;;;;;1;1;optimize projections and filters during logical planning;
264;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;count column should return 0 if all values are null;;;0;count column should return 0 if all values are null;;;;;;1;1;count column should return 0 if all values are null;
265;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;fix broken tests for count column;;;0;fix broken tests for count column;;;;;;1;1;fix broken tests for count column;
266;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;remove unused variable;;;0;remove unused variable;;;;;;1;1;remove unused variable;
267;1;0;0;1;1;1;1;0;0;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;allow stages with no tasks to  #260;;;0;allow stages with no tasks to  #260;;;;;;1;1;allow stages with no tasks to  #260;
268;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;optimize symbol -> channel/field mapping during expression interpretation;;;0;optimize symbol -> channel/field mapping during expression interpretation;;;;;;1;1;optimize symbol to channel/field resolution during expression interpretation;
269;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;print results normally for a query with no rows;;;0;print results normally for a query with no rows;;;;;;1;1;print results normally for a query with no rows;
270;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;1;1;0;0;1;0;1;0;allow null stageinfos when computing global stats;;;0;allow null stageinfos when computing global stats;;;;;;1;1;allow null stageinfos when computing global stats;
272;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;add logging for user  catalog  schema;;;0;add logging for user catalog schema;;;;;;1;1;add user catalog and schema to queryinfo and events;
274;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;fix npe and remove outputstats;;;0;fix npe and remove outputstats;;;;;;1;1;remove unused outputstats from outputprocessor;
275;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;add support for non-string partition keys to split pruning;;;0;add support for non-string partition keys to split pruning;;;;;;1;1;add support for non-string partition keys to split pruning;
276;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add start of a jdbc driver;;;0;add start of a jdbc driver;;;;;;1;1;add start of a jdbc driver;
277;1;0;0;1;1;1;0;0;0;1;1;1;0;0;0;0;1;0;1;1;1;0;0;1;0;1;0;covnert info stats objects to use datasize and duration;;;0;covnert info stats objects to use datasize and duration;;;;;;1;1;covnert info stats objects to use datasize and duration;
279;1;0;0;0;1;0;0;0;0;1;1;0;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;remove unused class;;;0;remove unused class;;;;;;1;1;remove unused class;
280;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;add per-node avg stats to console in debug mode;;;0;add per-node avg stats to console in debug mode;;;;;;1;1;add per-node avg stats to console in debug mode;
282;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0; when partition keys are strings;;;0; when partition keys are strings;;;;;;1;1; when partition keys are strings;
285;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;1;1;0;1;1;make presto build in eclipse;exclude the dependency:copy goal because eclipse can not handle it.;;0;make presto build in eclipse;exclude the dependency:copy goal because eclipse can not handle it;;;;;1;1;merge branch master of githubcom:facebook/presto;
288;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;1;1;0;1;1;1;1;0;1;0;add show functions;;;0;add show functions;;;;;;1;1;add show functions;
292;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;fix testquerymanagerconfig test;;;0;fix testquerymanagerconfig test;;;;;;1;1;fix testquerymanagerconfig test;
293;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;1;fix cancel for operators;;;0;fix cancel for operators;;;;;;1;1;fix cancel for operators;
296;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add disabled test for self joins;;;0;add disabled test for self joins;;;;;;1;1;add disabled test for self joins;
298;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add statistic aggregation functions;add standard deviation and variance aggregation for int64 and double for sample and population.;;0;add statistic aggregation functions;add standard deviation and variance aggregation for int64 and double for sample and population; looks good ship it! || dont forget to fix the tests with limit btw ||;;;;1;1;- make sql integration tests actually test something (trim the input not the output)- add equivalent tests with a double column;
299;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;hive progress;;;0;hive progress;;;;;;1;1;replace erroneous usages of getinput* with getcompleted*;
302;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;move spi to separate module;;;0;move spi to separate module;;;;;;1;1;move spi to separate module;
303;1;0;0;0;0;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add get_json_scalar function;;;0;add get_json_scalar function;;;;;;1;1;add json_extract_scalar and json_extract;
304;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;add basic help command;;;0;add basic help command;;;;;;1;1;add basic help command;
305;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;push down predicates through joins for partition pruning;;;0;push down predicates through joins for partition pruning;;;;;;1;1;push down predicates through joins for partition pruning;
307;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;add support for non-deterministic functions;;;0;add support for non-deterministic functions;;;;;;1;1;add support for non-deterministic functions;
308;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;0;minor jdbc driver improvements;;;0;minor jdbc driver improvements;;;;;;1;1;minor jdbc driver improvements;
310;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;plan rewriter framework + migrate optimizations to it;;;0;plan rewriter framework + migrate optimizations to it;;;;;;1;1;implement pruneunreferecedoutputs as a plan rewriter;
311;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix bug when rewriting negativeexpression;it was discarding the rewritten subexpression of arithmetic negations;;0;fix bug when rewriting negativeexpression;it was discarding the rewritten subexpression of arithmetic negations;;;;;1;1;fix bug when rewriting negativeexpressionit was discarding the rewritten subexpression of an arithmetic negation;
312;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;1;1;0;1;0;1;1;0;1;0;1;1;show proper messages for parser errors;;;0;show proper messages for parser errors;;sooooooo much better!! thanks! thanks!(also bad antlr bad antlr that requires ugly hacks) ||;;;;1;1;show proper messages for parser errors;
313;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;bypass interpreter for identity projections;;;0;bypass interpreter for identity projections;;;;;;1;1;bypass interpreter for identity projections;
315;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;move graphvizprinter to util with minor cleanup;;;0;move graphvizprinter to util with minor cleanup;;;;;;1;1;move graphvizprinter to util with minor cleanup;
316;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;add show tables with like predicate;;;0;add show tables with like predicate;; +1 ||;;;;1;1;add show tables with like predicate;
317;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;exchange operator;;;0;exchange operator;;looks good i _think_ :) ||;;;;1;1;simplify page buffer;
318;1;0;0;1;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;improve cancelation of queries;;;0;improve cancelation of queries;;;;;;1;1;improve cancelation of queries;
319;1;0;1;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add support for inputs at fields index > 0 for aggregations;;;0;add support for inputs at fields index > 0 for aggregations;;have you measured the impact of this on the benchmarks? || looks good  ||;;;;1;1;add support for inputs at fields other than 0 for aggregations;
322;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;code formatting;;;0;code formatting;;;;;;1;1;fix formatting;
323;1;0;0;0;1;0;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hash aggregation operator slice sizing bug;fixes this:  presto> select ds  stddev(cpu_msec) from hive_silver.default.hivedba_query_stats group by ds limit 20  query 0 failed: task 0.0.0 failed: java.lang.indexoutofboundsexception: end index (2625) must not be greater than size (2621)     at com.google.common.base.preconditions.checkpositionindexes(preconditions.jav a:388)     at com.facebook.presto.slice.slice.checkindexlength(slice.java:914)     at com.facebook.presto.slice.slice.setdouble(slice.java:480)     at com.facebook.presto.tuple.tupleinfo.setdouble(tupleinfo.java:337)     at com.facebook.presto.operator.aggregation.abstractvarianceaggregation.initia lize(abstractvarianceaggregation.java:69)     at com.facebook.presto.operator.hashaggregationoperator$fixedwidthaggregator.i nitialize(hashaggregationoperator.java:350)     at com.facebook.presto.operator.hashaggregationoperator$hashaggregationiterato r.aggregate(hashaggregationoperator.java:191)     at com.facebook.presto.operator.hashaggregationoperator$hashaggregationiterato r.computenext(hashaggregationoperator.java:234)     at com.facebook.presto.operator.abstractpageiterator.trytocomputenext(abstract pageiterator.java:137)     at com.facebook.presto.operator.abstractpageiterator.hasnext(abstractpageitera tor.java:130)     at com.facebook.presto.operator.filterandprojectoperator$filterandprojectitera tor.computenext(filterandprojectoperator.java:84)     at com.facebook.presto.operator.abstractpageiterator.trytocomputenext(abstract pageiterator.java:137)     at com.facebook.presto.operator.abstractpageiterator.hasnext(abstractpageitera tor.java:130)     at com.facebook.presto.operator.limitoperator$limititerator.computenext(limito perator.java:60)     at com.facebook.presto.operator.abstractpageiterator.trytocomputenext(abstract pageiterator.java:137)     at com.facebook.presto.operator.abstractpageiterator.hasnext(abstractpageitera tor.java:130)     at com.facebook.presto.execution.sqltaskexecution$splitworker.call(sqltaskexec ution.java:269)     at com.facebook.presto.execution.sqltaskexecution.run(sqltaskexecution.java:12 6)     at com.facebook.presto.execution.sqltaskmanager$taskstarter.run(sqltaskmanager .java:282)     at java.util.concurrent.executors$runnableadapter.call(executors.java:471)     at java.util.concurrent.futuretask$sync.innerrun(futuretask.java:334)     at java.util.concurrent.futuretask.run(futuretask.java:166)     at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1 110)     at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java: 603)     at java.lang.thread.run(thread.java:722) java.lang.indexoutofboundsexception: end index (2625) must not be greater than size (2621)     at com.google.common.base.preconditions.checkpositionindexes(preconditions.jav a:388)     at com.facebook.presto.slice.slice.checkindexlength(slice.java:914)     at com.facebook.presto.slice.slice.setdouble(slice.java:480)     at com.facebook.presto.tuple.tupleinfo.setdouble(tupleinfo.java:337)     at com.facebook.presto.operator.aggregation.abstractvarianceaggregation.initia lize(abstractvarianceaggregation.java:69)     at com.facebook.presto.operator.hashaggregationoperator$fixedwidthaggregator.i nitialize(hashaggregationoperator.java:350)     at com.facebook.presto.operator.hashaggregationoperator$hashaggregationiterato r.aggregate(hashaggregationoperator.java:191)     at com.facebook.presto.operator.hashaggregationoperator$hashaggregationiterato r.computenext(hashaggregationoperator.java:234)     at com.facebook.presto.operator.abstractpageiterator.trytocomputenext(abstract pageiterator.java:137)     at com.facebook.presto.operator.abstractpageiterator.hasnext(abstractpageitera tor.java:130)     at com.facebook.presto.operator.filterandprojectoperator$filterandprojectitera tor.computenext(filterandprojectoperator.java:84)     at com.facebook.presto.operator.abstractpageiterator.trytocomputenext(abstract pageiterator.java:137)     at com.facebook.presto.operator.abstractpageiterator.hasnext(abstractpageitera tor.java:130)     at com.facebook.presto.operator.limitoperator$limititerator.computenext(limito perator.java:60)     at com.facebook.presto.operator.abstractpageiterator.trytocomputenext(abstract pageiterator.java:137)     at com.facebook.presto.operator.abstractpageiterator.hasnext(abstractpageitera tor.java:130)     at com.facebook.presto.execution.sqltaskexecution$splitworker.call(sqltaskexec ution.java:269)     at com.facebook.presto.execution.sqltaskexecution.run(sqltaskexecution.java:12 6)     at com.facebook.presto.execution.sqltaskmanager$taskstarter.run(sqltaskmanager .java:282)     at java.util.concurrent.executors$runnableadapter.call(executors.java:471)     at java.util.concurrent.futuretask$sync.innerrun(futuretask.java:334)     at java.util.concurrent.futuretask.run(futuretask.java:166)     at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1 110)     at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java: 603)     at java.lang.thread.run(thread.java:722);;0;fix hash aggregation operator slice sizing bug;fixes this:presto> select ds stddev(cpu_msec) fromhive_silverdefaulthivedba_query_stats group by ds limit 20query 0 failed:task 000 failed  end index (2625) must not be greaterthan size (2621)    atcomgooglecommonbasepreconditionscheckpositionindexes(preconditionsjava:388)    at comfacebookprestosliceslicecheckindexlength(slicejava:914)    at comfacebookprestosliceslicesetdouble(slicejava:480)    at comfacebookprestotupletupleinfosetdouble(tupleinfojava:337)    atcomfacebookprestooperatoraggregationabstractvarianceaggregationinitialize(abstractvarianceaggregationjava:69)    atcomfacebookprestooperatorhashaggregationoperator$widthaggregatorinitialize(hashaggregationoperatorjava:350)    atcomfacebookprestooperatorhashaggregationoperator$hashaggregationiteratoraggregate(hashaggregationoperatorjava:191)    atcomfacebookprestooperatorhashaggregationoperator$hashaggregationiteratorcomputenext(hashaggregationoperatorjava:234)    atcomfacebookprestooperatorabstractpageiteratortrytocomputenext(abstractpageiteratorjava:137)    atcomfacebookprestooperatorabstractpageiteratorhasnext(abstractpageiteratorjava:130)    atcomfacebookprestooperatorfilterandprojectoperator$filterandprojectiteratorcomputenext(filterandprojectoperatorjava:84)    atcomfacebookprestooperatorabstractpageiteratortrytocomputenext(abstractpageiteratorjava:137)    atcomfacebookprestooperatorabstractpageiteratorhasnext(abstractpageiteratorjava:130)    atcomfacebookprestooperatorlimitoperator$limititeratorcomputenext(limitoperatorjava:60)    atcomfacebookprestooperatorabstractpageiteratortrytocomputenext(abstractpageiteratorjava:137)    atcomfacebookprestooperatorabstractpageiteratorhasnext(abstractpageiteratorjava:130)    atcomfacebookprestoexecutionsqltaskexecution$splitworkercall(sqltaskexecutionjava:269)    atcomfacebookprestoexecutionsqltaskexecutionrun(sqltaskexecutionjava:126)    atcomfacebookprestoexecutionsqltaskmanager$taskstarterrun(sqltaskmanagerjava:282)    at javautilconcurrentexecutors$runnableadaptercall(executorsjava:471)    at javautilconcurrentfuturetask$syncinnerrun(futuretaskjava:334)    at javautilconcurrentfuturetaskrun(futuretaskjava:166)    atjavautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1110)    atjavautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:603)    at javalangthreadrun(threadjava:722)javalangindexoutofboundsexception: end index (2625) must not be greaterthan size (2621)    atcomgooglecommonbasepreconditionscheckpositionindexes(preconditionsjava:388)    at comfacebookprestosliceslicecheckindexlength(slicejava:914)    at comfacebookprestosliceslicesetdouble(slicejava:480)    at comfacebookprestotupletupleinfosetdouble(tupleinfojava:337)    atcomfacebookprestooperatoraggregationabstractvarianceaggregationinitialize(abstractvarianceaggregationjava:69)    atcomfacebookprestooperatorhashaggregationoperator$fixedwidthaggregatorinitialize(hashaggregationoperatorjava:350)    atcomfacebookprestooperatorhashaggregationoperator$hashaggregationiteratoraggregate(hashaggregationoperatorjava:191)    atcomfacebookprestooperatorhashaggregationoperator$hashaggregationiteratorcomputenext(hashaggregationoperatorjava:234)    atcomfacebookprestooperatorabstractpageiteratortrytocomputenext(abstractpageiteratorjava:137)    atcomfacebookprestooperatorabstractpageiteratorhasnext(abstractpageiteratorjava:130)    atcomfacebookprestooperatorfilterandprojectoperator$filterandprojectiteratorcomputenext(filterandprojectoperatorjava:84)    atcomfacebookprestooperatorabstractpageiteratortrytocomputenext(abstractpageiteratorjava:137)    atcomfacebookprestooperatorabstractpageiteratorhasnext(abstractpageiteratorjava:130)    atcomfacebookprestooperatorlimitoperator$limititeratorcomputenext(limitoperatorjava:60)    atcomfacebookprestooperatorabstractpageiteratortrytocomputenext(abstractpageiteratorjava:137)    atcomfacebookprestooperatorabstractpageiteratorhasnext(abstractpageiteratorjava:130)    atcomfacebookprestoexecutionsqltaskexecution$splitworkercall(sqltaskexecutionjava:269)    atcomfacebookprestoexecutionsqltaskexecutionrun(sqltaskexecutionjava:126)    atcomfacebookprestoexecutionsqltaskmanager$taskstarterrun(sqltaskmanagerjava:282)    at javautilconcurrentexecutors$runnableadaptercall(executorsjava:471)    at javautilconcurrentfuturetask$syncinnerrun(futuretaskjava:334)    at javautilconcurrentfuturetaskrun(futuretaskjava:166)    atjavautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1110)    atjavautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:603)    at javalangthreadrun(threadjava:722);;;;;1;1;fix hash aggregation operator slice sizing bug;
326;1;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;1;0;0;1;0;0;0;add jsonavgbenchmarkresultwriter;;;0;add jsonavgbenchmarkresultwriter;;;;;;1;1;add jsonavgbenchmarkresultwriter;
329;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;handle smaller terminal windows properly;;;0;handle smaller terminal windows properly;;;;;;1;1;handle smaller terminal windows properly;
333;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;1;1;0;1;1;0;1;1;show query with error portion highlighted;;;0;show query with error portion highlighted;;;;;;1;1;show query with error portion highlighted;
334;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;add dummy eof token when highlighting errors;;;0;add dummy eof token when highlighting errors;;;;;;1;1;add dummy eof token when highlighting errors;
335;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;add support for complex join subexpressions and joins on multiple fields;;;0;add support for complex join subexpressions and joins on multiple fields;;;;;;1;1;simplify code;
337;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;upgrade to latest airlift with latest jackson and switch to more efficient json;jackson 1.9.12 fixes the bug we were seeing with nextfieldname method from jackson. the code no longer hangs when there is a space before a colon.  the json parsing function in presto should be substantially more perfomant now.;;0;upgrade to latest airlift with latest jackson and switch to more efficient json;jackson 1912 fixes the bug we were seeing with nextfieldname method from jackson the code no longer hangs when there is a space before a colonthe json parsing function in presto should be substantially more perfomant now;;;;;1;1;upgrade to latest airlift with latest jackson and use more efficient json;
338;1;0;0;0;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;0;1;0;1;0;add @jsoncreator annotation to planfragment;;;0;add @jsoncreator annotation to planfragment;;;;;;1;1;add @jsoncreator annotation to planfragment;
341;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;handle parsing doubles with exponents;;;0;handle parsing doubles with exponents;;;;;;1;1;handle parsing doubles with exponents;
342;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;fix divide by zero when no nodes;;;0;fix divide by zero when no nodes;;;;;;1;1;fix divide by zero when no nodes;
343;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;make hiveclient partitionchunk iteration bounded and pipelined;having threads block to fill a queue for an iterator turns out to be a little iffy since you need to deal with a way of cleaning up those thread resources if you never finish your iterator (especially if it is passed through an spi).  instead  what this does is add a suspendingexecutor that has the ability to halt and resume tasks submitted to it without holding up thread resources. once you tie that into the partition chunk iterator  what you have is a queue that halts tasks when it fills up  and resumes the executor when enough tasks have been drained from it without holding any thread resources.;;0;make hiveclient partitionchunk iteration bounded and pipelined;having threads block to fill a queue for an iterator turns out to be a little iffy since you need to deal with a way of cleaning up those thread resources if you never finish your iterator (especially if it is passed through an spi)instead what this does is add a suspendingexecutor that has the ability to halt and resume tasks submitted to it without holding up thread resources once you tie that into the partition chunk iterator what you have is a queue that halts tasks when it fills up and resumes the executor when enough tasks have been drained from it without holding any thread resources;;;;;1;1;make hiveclient partitionchunk iteration bounded and pipelined;
345;1;0;0;0;0;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;update timing stats incrementally;they were only being updated at the end of processing a split. bytes and rows are updated incrementally so we need timings to be updated at the same rate to get consistent row and data rate reports.;;0;update timing stats incrementally;they were only being updated at the end of processing a splitbytes and rows are updated incrementally so we need timings to be updated at the same rate to get consistent row and data rate reports;;;;;1;1;update timing stats incrementallythey were only being updated at the end of processing a splitbytes and rows are updated incrementally so we need timings to be updated at the same rate to get consistent row and data rate reports;
348;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;add basic endpoint for query execution;;;0;add basic endpoint for query execution;;;;;;1;1;add basic endpoint for query execution;
349;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;0;0;1;0;1;1;0;1;0;1;0;make plan fragment id a typed object;;;0;make plan fragment id a typed object;;;;;;1;1;make plan fragment id a typed object;
350;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;1;1;1;1;1;1;1;1;1;0;1;1;upgrade to jackson 2.x;;;0;upgrade to jackson 2x;;;;;;1;1;upgrade to jackson 2x;
352;1;0;1;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;1;0;1;0;1;0;1;0;improve benchmarks stats;;;0;improve benchmarks stats;;;;;;1;1;add cpu time user time and output size to benchmark stats;
355;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add string concatenation operator;;;0;add string concatenation operator;;;;;;1;1;add string concatenation operator;
356;1;0;0;0;0;1;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;fix client latency issues;;;0;fix client latency issues;;;;;;1;1;wake up waiters immediately when queue is finished;
359;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;1;1;0;1;1;add distributed sql integration tests;note: all of the std dev and variance tests are broken in distributed mode (currently tests are disabled for those);;0;add distributed sql integration tests;note: all of the std dev and variance tests are broken in distributed mode (currently tests are disabled for those);nice  ;;;;1;1;add distributed sql integration tests;
360;1;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;handle lexer errors properly in console;;;0;handle lexer errors properly in console;; nice ||;;;;1;1;handle lexer errors properly in console;
361;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix variance and std dev failing distributed tests;;;0;fix variance and std dev failing distributed tests;;;;;;1;1;fix variance and std dev failing distributed tests;
"363;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;hackathon project - csv output for the console;- add command line command execution to the console - add csv / tsv output format to the console  this implements  --execute  sql command  and sends the output to stdout. default format is  csv . available formats are  csv - comma separated tsv - tab separated csv_header - comma separated with an additional row that has the column names tsv_header - tab separated with an additional row that has the column names;;0;hackathon project - csv output for the console;""- add command line command execution to the console- add csv / tsv output format to the consolethis implements  --execute """"sql command"""" and sends the output to stdout default format is """"csv"""" available formats arecsv - comma separatedtsv - tab separatedcsv_header - comma separated with an additional row that has the column namestsv_header - tab separated with an additional row that has the column names"";;;;;1;1;apply code review feedback;"
365;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;support symlinktextinputformat for hive;;;0;support symlinktextinputformat for hive;;;;;;1;1;support symlinktextinputformat for hive;
369;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;0;1;0;1;0;convert to netty  client;this depends on https://github.com/airlift/airlift/pull/39;;0;convert to netty  client;this depends on https://githubcom/airlift/airlift/pull/39;;;;;1;1;convert to netty  client;
"371;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;add cron based import into presto.;this is driven by a configurable background service that accepts import requests through a rest endpoint.;;0;add cron based import into presto;this is driven by a configurable background service that accepts import requests through a rest endpoint;""there doesnt seem to be any global locking for `cronmanager` since were storing jobs in the database shouldnt we use the database for locking to avoid having to manually configure a single node to run this (and to prevent mistakes)? || there is no global locking in the code because it was decided that this runs only on a single node and therefore no global locking is necessary  || this is a better discussion to have offline but if this only runs on a single node with nothing to enforce that constraint then this seems excessive simply to enable scheduled retries of importsi dont like using the generic name """"cron"""" for a job system that is tied to imports none of the code is generic so shouldnt it go under the import package and namespace? no doubt we will have a generic job scheduling system in the future but this isnt it so we should use a more specific name/namespace || the `import_tables` table in `shardmanagerdao` already has everything thats needed here with the exception of an update interval and enabled flag i dont see the point of duplicating the data and having basically the same functionality given that this will need to be rewritten again to support real materialized views and transactional metadata || can you title the commit """"period import""""? ||  "";;;;1;1;add periodic importerthis is driven by a configurable background service that accepts import requests through a rest endpoint;"
372;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;add shutdown for executors;;;0;add shutdown for executors;;;;;;1;1;add shutdown for executors;
374;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;add plugin system;;;0;add plugin system;;this is mostly scaffolding and moving stuff around as the meat is in the comiq80resolver things do you plan to submit a code review for that?otherwise looks fine || ;;;;1;1;fixes for review #374;
375;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add sql benchmark for tpc-h query 1;;;0;add sql benchmark for tpc-h query 1;;looks good all of the tpch code should go to src/test though once the table handle plugin code is in place ||;;;;1;1;add sql benchmark for tpc-h query 1;
376;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix requiring hadoop native libraries;;;0;fix requiring hadoop native libraries;;;;;;1;1;fix requiring hadoop native libraries;
377;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;tweak exception handling;;;0;tweak exception handling;;;;;;1;1;tweak exception handling;
378;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;add strpos function;;;0;add strpos function;;;;;;1;1;add strpos function;
380;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;add support for prism table links;will add specific unit test in another commit to get this in first.;;0;add support for prism table links;will add specific unit test in another commit to get this in first;;;;;1;1;add support for prism table links;
383;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;1;1;0;1;0;type deser configurable for multiple types;turns out that not only the tablehandle but also the columnhandles need to be serialized and deserialized.  factor out the common code into a base class  add code for columnhandles.;;0;type deser configurable for multiple types;turns out that not only the tablehandle but also the columnhandlesneed to be serialized and deserialized  factor out the common codeinto a base class add code for columnhandles;;;;;1;1;type deser configurable for multiple typesturns out that not only the tablehandle but also the columnhandlesneed to be serialized and deserialized  factor out the common codeinto a base class add code for columnhandles;
384;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;cancel stops work;;;0;cancel stops work;;;;;;1;1;free splits as soon as posible;
385;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;add configuration for hdfs socks proxy;;;0;add configuration for hdfs socks proxy;; alright looks good to me too ||;;;;1;1;add configuration for hdfs socks proxy;
386;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;add window functions;;;0;add window functions;;looks good but @martint should review the planning code || other than those comments it  looks good ship it! ||;;;;1;1;address review comments for window functions;
390;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add temporary support for map  array  and struct by processing as strings;;;0;add temporary support for map array and struct by processing as strings;;;;;;1;1;add temporary support for map and array by processing as strings;
391;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;implement approximate count distinct;;;0;implement approximate count distinct;; it would be nice to have a test that uses sql ||;;;;1;1;add benchmark for approx_distinct aggregation;
392;1;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;remove jmeter benchmark output;;;0;remove jmeter benchmark output;;;;;;1;1;remove jmeter benchmark output;
397;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;make batch size for fetching partition info configurable and default it to 500;;;0;make batch size for fetching partition info configurable and default it to 500;;;;;;1;1;make batch size for fetching partition info configurable and default it to 500;
399;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;pipeline hive client;;;0;pipeline hive client;;;;;;1;1;address comments in review #399;
400;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;pipeline scheduling of query tasks;;;0;pipeline scheduling of query tasks;;;;;;1;1;use unlimited thread pool for allocating master task thread;
"403;1;0;0;1;1;1;1;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;minor fixes;;;0;minor fixes;;""this adds a block like this to the task stats:```    """"exchangestatus"""" : [ {      """"uri"""" : """"      """"state"""" : """"closed""""      """"lastupdate"""" : """"2013-03-06t03 51158z""""    } ]``` ||  "";;;;1;1;add log on state transitions;"
408;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;replace jersey mediatype with guava mediatype;jersey mediatype now requires internal classes only available in server jars;;0;replace jersey mediatype with guava mediatype;jersey mediatype now requires internal classes only available in server jars;;;;;1;1;replace jersey mediatype with guava mediatypejersey mediatype now requires internal classes only available in server jars;
413;1;0;0;1;1;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;1;0;1;0;1;0;fix plugin class loader  getresources implementation;;;0;fix plugin class loader  getresources implementation;;;;;;1;1;fix plugin class loader getresources implementation;
419;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;more task info;;;0;more task info;;;;;;1;1;add nomoresplits declarations to task info;
423;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;minor fixes;;;0;minor fixes;;;;;;1;1;do not count exchange splits;
424;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fixes;;;0;fixes;;;;;;1;1;make tests use bootstrap;
426;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;show proper error message when querying hive views;;;0;show proper error message when querying hive views;;;;;;1;1;show proper error message when querying hive views;
427;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;make hive view error message a constant;;;0;make hive view error message a constant;;;;;;1;1;make hive view error message a constant;
428;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;support queries with no matching partitions;when setting no more splits on exchanges  mark all exchange sources not just the ones that had locations assigned;;0;support queries with no matching partitions;when setting no more splits on exchanges mark all exchange sources not just the ones that had locations assigned;;;;;1;1;support queries with no matching partitionswhen setting no more splits on exchanges mark all exchange sources not just the ones that had locations assigned;
432;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;0;1;1;1;0;1;0;various fixes;;;0;various fixes;;;;;;1;1;dont update done queries;
433;1;0;0;0;1;0;0;0;0;1;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add request scheduled/complete stats to exchange operator;;;0;add request scheduled/complete stats to exchange operator;;;;;;1;1;add request scheduled/complete stats to exchange operator;
434;1;0;0;0;1;0;0;0;0;1;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;expose async  state in exchange info;;;0;expose async  state in exchange info;;;;;;1;1;expose async  state in exchange info;
435;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;remove 100k split limit;;;0;remove 100k split limit;;;;;;1;1;remove 100k split limit;
436;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;simple sql execution and create materialized view;;;0;simple sql execution and create materialized view;;other than those minor comments it ;;;;1;1;consolidate query state machine;
438;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;0;1;0;1;0;change to new async configuration name;;;0;change to new async configuration name;;;;;;1;1;change to new async configuration name;
"440;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;fixes;;;0;fixes;;;;;;1;1;""fix potential npe and improve claritythere was a potential npe due to the call to """"havingornull()"""" if the having clause is missing"";"
441;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;make threadpool sizes configurable;- query manager executor pool - import partition  chunk and shard pools;;0;make threadpool sizes configurable;- query manager executor pool- import partition chunk and shard pools;;;;;1;1;make threadpool sizes configurable- query manager executor pool- import partition chunk and shard pools;
442;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;update and cancel tasks in parallel;;;0;update and cancel tasks in parallel;;other than the comments above ;;;;1;1;address review comments;
443;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;0;1;0;1;0;upgrade to airlift 0.74-snapshot;;;0;upgrade to airlift 074-snapshot;;;;;;1;1;upgrade to airlift 074-snapshot;
449;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;use testingmbeanserver in testingprestoserver;;;0;use testingmbeanserver in testingprestoserver;;;;;;1;1;use testingmbeanserver in testingprestoserver;
451;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;1;1;0;1;0;1;1;0;1;0;metadata api;;;0;metadata api;;;;;;1;1;rewrite apis with optional parametersadds a qualifiedtableprefix object that may containcatalogcatalogschemacatalogschematablefor all those apis that take optional parameters;
452;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;optimizers api;do not work on this before  has been applied. this sits on top of that pull request.;;0;optimizers api;do not work on this before  has been applied this sits on top of that pull request;;;;;1;1;rework the planoptimizer api to take the session as a method parametermakes plan optimizer creation much simpler and allows for them to be singletons everywhereonce we have figured out how to manage the ordering between them thiscan then turn into a multibinder-like arrangement;
453;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;allow duplicate requests to add buffers;;;0;allow duplicate requests to add buffers;;;;;;1;1;allow duplicate requests to add buffers;
455;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;split stats;;;0;split stats;;;;;;1;1;print query url in client when in debug mode;
456;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;0;drop table;;;0;drop table;;other than those minor comments it ;;;;1;1;implement drop table for native tablesdrop tables from the native store clean up the shards on the nodes using a background cleaner process;
457;1;0;0;0;0;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix npe in executionstats;;;0;fix npe in executionstats;;;;;;1;1;fix npe in executionstats;
459;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;statement resource;;;0;statement resource;;;;;;1;1;add light weight query stats for clients;
460;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;1;1;1;1;1;1;1;1;1;0;1;1;make cli use new client api;;;0;make cli use new client api;;some minor style comments but all in all looks ok  ||;;;;1;1;move sql parser to separate module;
461;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;0;various fixes;;;0;various fixes;;other than those comments it ;;;;1;1;improve task split locality and debuggingadd locations of data to split to hint schedulerschedule splits closer to datacreate hive splits based on dfs blocksadd split info to task state for debugging;
462;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;quote identifiers when formatting expressions;this is to avoid issues with identifiers that are also sql keywords;;0;quote identifiers when formatting expressions;this is to avoid issues with identifiers that are also sql keywords;;;;;1;1;quote identifiers when formatting expressionsthis is to avoid issues with identifiers that are also sql keywords;
"464;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;simple heartbeat-based failure detector;this is a naive failure detector that watches discovery for  presto  announcements and monitors the remote services using the  url.  it considers a service failed if the percentage of failed requests over the last minute (exponentially decayed) is higher than a configurable threshold. it also supports a configurable warmup period during which newly discovered nodes are considered failed.;;0;simple heartbeat-based failure detector;""this is a naive failure detector that watches discovery for """"presto"""" announcements and monitors the remote services using the  urlit considers a service failed if the percentage of failed requests over the last minute (exponentially decayed) is higher than a configurable threshold it also supports a configurable warmup period during which newly discovered nodes are considered failed"";;;;;1;1;""simple heartbeat-based failure detectorthis is a naive failure detector that watches discovery for """"presto"""" announcements and monitors the remote services using the  urlit considers a service failed if the percentage of failed requests over the last minute (exponentially decayed) is higher than a configurable threshold it also supports a configurable warmup period during which newly discovered nodes are considered failed"";"
465;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fail remote tasks on bad responses or repeated failures;;;0;fail remote tasks on bad responses or repeated failures;;;;;;1;1;disable failure detector warmup interval in testdistributedqueries;
466;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;move noopfailuredetector to tests;;;0;move noopfailuredetector to tests;;;;;;1;1;move noopfailuredetector to tests;
468;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;0;0;fix overflow bug in status printer;;;0;fix overflow bug in status printer;;;;;;1;1;fix overflow bug in status printer;
469;1;0;0;1;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;1;1;1;1;1;0;1;1;more updates for new client api;;;0;more updates for new client api;;;;;;1;1;cleanup handling of states and failures;
470;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fixes;;;0;fixes;;;;;;1;1;fix deadlock issue;
471;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;0;optimize split assignment algorithm and tracking of nodes;;;0;optimize split assignment algorithm and tracking of nodes;;;;;;1;1;optimize split assignment algorithm and tracking of nodes;
472;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;choose all local and rack-local nodes and fill with random if needed;;;0;choose all local and rack-local nodes and fill with random if needed;;;;;;1;1;choose all local and rack-local nodes and fill with random if needed;
473;1;0;0;1;1;1;1;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fix another deadlock in httpremotetask;;;0;fix another deadlock in httpremotetask;;;;;;1;1;fix another deadlock in httpremotetask;
474;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;tolerate connection errors in client;;;0;tolerate connection errors in client;;;;;;1;1;tolerate connection errors in client;
475;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;fix console --execute;;;0;fix console --execute;;;;;;1;1;fix console --execute;
476;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;1;1;0;1;1;0;1;1;minor statement api cleanups;;;0;minor statement api cleanups;;;;;;1;1;minor statement api cleanups;
478;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;id improvements;;;0;id improvements;;;;;;1;1;add improved query id generator;
479;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;fix cancel;;;0;fix cancel;;;;;;1;1;support canceling a task before the create occurs;
"480;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;add event logging for split completion;the nectar payload in scribe will look like this:  {    completed_positions_rate_ten_sec : 437     completed_data_size_count_one_min : 1026901     event_type :  splitcompletion      task_id :  2.1.0      completed_data_size_total : 1026901     time_to_last_byte_ms : 24719     event_uuid :  fffb559f-7db3-40bb-aad4-56e001f1dbc8      completed_positions_count_ten_sec : 4370     time_to_first_byte_ms : 24716     completed_data_size_rate_thirty_sec : 34230.033333333     query_id :  2      execution_start_time :  2013-04-09t22:40:23.309z      wall_time_ms : 24720     completed_positions_rate_one_min : 72.833333333333     completed_data_size_count_ten_sec : 1026901     completed_positions_count_thirty_sec : 4370     completed_positions_count_one_min : 4370     cpu_time_ms : 210     split_info_json :  [{\ path\ :\ hdfs:\/\/dfs1.data.facebook.com:9000\/user\/facebook\/warehouse\/ad_account_bass_ad_obj_map\/ds=2013-04-06\/000000_0\  \ start\ :0 \ length\ :49792606 \ hosts\ :[\ hadoop2913.snc5.facebook.com.\/10.38.208.27\  \ hadoop417.snc5.facebook.com.\/10.38.27.21\  \ hadoop1829.snc5.facebook.com.\/10.38.106.27\ ]}]      completed_positions_total : 4370     completed_data_size_count_thirty_sec : 1026901     user_time_ms : 199     event_time :  2013-04-09t22:40:48.033z      completed_data_size_rate_ten_sec : 102690.1     completed_positions_rate_thirty_sec : 145.66666666667     completed_data_size_rate_one_min : 17115.016666667     event_host :  ehwang-mbp.local      stage_id :  2.1  };;0;add event logging for split completion;""the nectar payload in scribe will look like this:{  """"completed_positions_rate_ten_sec"""": 437  """"completed_data_size_count_one_min"""": 1026901  """"event_type"""": """"splitcompletion""""  """"task_id"""": """"210""""  """"completed_data_size_total"""": 1026901  """"time_to_last_byte_ms"""": 24719  """"event_uuid"""": """"fffb559f-7db3-40bb-aad4-56e001f1dbc8""""  """"completed_positions_count_ten_sec"""": 4370  """"time_to_first_byte_ms"""": 24716  """"completed_data_size_rate_thirty_sec"""": 34230033333333  """"query_id"""": """"2""""  """"execution_start_time"""": """"2013-04-09t22 23309z""""  """"wall_time_ms"""": 24720  """"completed_positions_rate_one_min"""": 72833333333333  """"completed_data_size_count_ten_sec"""": 1026901  """"completed_positions_count_thirty_sec"""": 4370  """"completed_positions_count_one_min"""": 4370  """"cpu_time_ms"""": 210  """"split_info_json"""": """"[{\""""path\"""":\""""hdfs:\/\/dfs1datafacebookcom:9000\/user\/facebook\/warehouse\/ad_account_bass_ad_obj_map\/ds2013-04-06\/000000_0\""""\""""start\"""":0\""""length\"""":49792606\""""hosts\"""":[\""""hadoop2913snc5facebookcom\/103820827\""""\""""hadoop417snc5facebookcom\/10382721\""""\""""hadoop1829snc5facebookcom\/103810627\""""]}]""""  """"completed_positions_total"""": 4370  """"completed_data_size_count_thirty_sec"""": 1026901  """"user_time_ms"""": 199  """"event_time"""": """"2013-04-09t22 48033z""""  """"completed_data_size_rate_ten_sec"""": 1026901  """"completed_positions_rate_thirty_sec"""": 14566666666667  """"completed_data_size_rate_one_min"""": 17115016666667  """"event_host"""": """"ehwang-mbplocal""""  """"stage_id"""": """"21""""}"";;;;;1;1;add event logging for presto split completion;"
481;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;move all jaxrs code to server module and remove dependency;;;0;move all jaxrs code to server module and remove dependency;;;;;;1;1;move all jaxrs code to server module and remove dependency;
483;1;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;move event class to presto-facebook;;;0;move event class to presto-facebook;;did you forget to add the new file to the commit? || its in the other repo || ;;;;1;1;move event class to presto-facebook;
484;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;enable jmx stats for dfsclient;this took way too long;;0;enable jmx stats for dfsclient;this took way too long;;;;;1;1;enable jmx stats for dfsclient;
486;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;fix bug in statementresource purger;;;0;fix bug in statementresource purger;;;;;;1;1;fix bug in statementresource purger;
488;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;improve error message for backquoted identifiers;;;0;improve error message for backquoted identifiers;;;;;;1;1;improve error message for backquoted identifiers;
490;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix setting timeouts for hive metastore client;;;0;fix setting timeouts for hive metastore client;;;;;;1;1;rename simplehivecluster to testinghivecluster;
"492;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;fix client hang for simple queries with no output stage;this makes e.g.  drop table  not hang in the cli.;;0;fix client hang for simple queries with no output stage;""this makes eg """"drop table"""" not hang in the cli"";;;;;1;1;""fix client hang for simple queries with no output stagethis makes eg """"drop table"""" not hang in the cli"";"
494;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;only return data if query was successful;;;0;only return data if query was successful;;;;;;1;1;only return data if query was successful;
499;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;create alias;do not work on this pull request until  was applied!;;0;create alias;;good to go ||;;;;1;1;revert logicalexecutionplanner changesthe sub planner is required because it gets a different symbol/type map which is needed for the execution;
500;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;add simple query dashboard;;;0;add simple query dashboard;;;;;;1;1;add simple query dashboard;
501;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix bug in tupleinfo.setnull/setnotnull;;;0;fix bug in tupleinfosetnull/setnotnull;;;;;;1;1;fix bug in tupleinfosetnull/setnotnull;
502;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;1;0;1;1;0;1;1;flush buffered console results during slow queries;;;0;flush buffered console results during slow queries;;nice! ||;;;;1;1;flush buffered console results during slow queries;
506;1;0;0;0;0;1;0;0;0;0;1;1;0;1;0;0;0;0;1;0;0;0;0;1;0;1;0;upgrade dfsclient and add slow node switching;;;0;upgrade dfsclient and add slow node switching;;;;;;1;1;expose slowdatanodeswitcher stats through jmx;
508;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;remove import client;;;0;remove import client;;;;;;1;1;do not fail when a split worker is gced;
510;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;fix parsing of identifiers that start with a digit;;;0;fix parsing of identifiers that start with a digit;;;;;;1;1;fix parsing of identifiers that start with a digit;
512;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;0;1;1;1;0;1;0;minor (hacky) refactoring to fix missing stats from completion event;;;0;minor (hacky) refactoring to fix missing stats from completion event;;looks good ;;;;1;1;minor (hacky) refactoring to fix missing stats from completion event;
513;1;0;0;1;1;1;1;0;0;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;record failures for any error during task scheduling;;;0;record failures for any error during task scheduling;;;;;;1;1;record failures for any error during task scheduling;
514;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;1;1;0;1;1;1;0;0;1;0;1;1;expressionformatter fixes;;;0;expressionformatter fixes;;;;;;1;1;rename expressionformattertostring() to formatexpression()to make it easier to import statically;
515;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;fix bug when ordering by window function;;;0;fix bug when ordering by window function;;;;;;1;1;fix bug when ordering by window function;
516;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;0;fix sql formatter and add tests;;;0;fix sql formatter and add tests;;;;;;1;1;fix sql formatter and add tests;
518;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0; when following symlinks across hdfs instances;;;0; when following symlinks across hdfs instances;;;;;;1;1;get filesystem for target path when following symlinks;
519;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;ask for partition info in exponentially increasing batch sizes;this should help speed up trivial queries (e.g.  limit) when the number of candidate partitions is large and the partition information hasn t been cached yet.;;0;ask for partition info in exponentially increasing batch sizes;this should help speed up trivial queries (eg limit) when the number of candidate partitions is large and the partition information hasnt been cached yet;;;;;1;1;ask for partition info in exponentially increasing batch sizesthis should help speed up trivial queries (eg limit) when the number of candidate partitions is large and the partition information hasnt been cached yet;
520;1;0;0;1;1;1;1;0;0;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fast trivial queries;;;0;fast trivial queries;;;;;;1;1;minor fixes and documentation;
521;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;1;0;1;0;1;0;show error for show columns if table does not exist;;;0;show error for show columns if table does not exist;;;;;;1;1;show error for show columns if table does not exist;
"522;1;0;0;0;1;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;show whether columns are partition keys in describe;;;0;show whether columns are partition keys in describe;;""looks good  we need a sql test for """"describe table"""" || "";;;;1;1;show whether columns are partition keys in describe;"
523;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix benchmarks;;;0;fix benchmarks;;;;;;1;1;fix broken show table test;
524;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add benchmark for like;;;0;add benchmark for like;;;;;;1;1;add benchmark for like;
525;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;fix starvation (task should run if the query is not done);;;0;fix starvation (task should run if the query is not done);;;;;;1;1;fix starvation (task should run if the query is not done);
526;1;0;1;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;0;0;0;1;0;1;0;add retry code back into hive client;remove other unnecessary uses of retrydriver move retrydriver to hive module;;0;add retry code back into hive client;remove other unnecessary uses of retrydrivermove retrydriver to hive module;;;;;1;1;add retry code back into hive clientremove other unnecessary uses of retrydrivermove retrydriver to hive module;
527;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;1;1;0;0;0;1;1;0;1;0;fix show partitions bug;supply a default value to bindings optional;;0;fix show partitions bug;supply a default value to bindings optional;;;;;1;1;fix show partitions bugsupply a default value to bindings optional;
528;1;0;0;0;1;1;0;0;1;0;0;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;fix calls to optional.get() without optional.ispresent();;;0;fix calls to optionalget() without optionalispresent();;;;;;1;1;fix calls to optionalget() without optionalispresent();
529;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;return multiple pages from statement resource;;;0;return multiple pages from statement resource;;;;;;1;1;return multiple pages from statement resource;
530;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;use unix timestamps in seconds for time functions;;;0;use unix timestamps in seconds for time functions;;;;;;1;1;use unix timestamps in seconds for time functions;
531;1;0;0;1;1;1;0;0;0;1;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;skip split address hints that do not resolve;;;0;skip split address hints that do not resolve;;;;;;1;1;skip split address hints that do not resolve;
532;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix symbol to qualifiedname conversion;;;0;fix symbol to qualifiedname conversion;;;;;;1;1;fix symbol to qualifiedname conversion;
534;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;minor fixes;;;0;minor fixes;;;;;;1;1;ignore add output buffer calls when query is finished;
536;1;0;1;0;1;0;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;improve metadata system;replace internal schema with connector metadata add sys.query and sys.task tables add jmx connector move local tests and benchmarks to use standard execution apis;;0;improve metadata system;replace internal schema with connector metadataadd sysquery and systask tablesadd jmx connectormove local tests and benchmarks to use standard execution apis;;;;;1;1;add benchmark smoke test to run in build;
541;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;hive connector fixes;;;0;hive connector fixes;;;;;;1;1;fix bugs with selecting and describing dual in hive connector;
542;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;add more data to sys.query and sys.task;rename heartbeat to heartbeat;;0;add more data to sysquery and systask;rename heartbeat to heartbeat;;;;;1;1;add more data to sysquery and systaskrename heartbeat to heartbeat;
543;1;0;0;0;0;1;0;0;0;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;expose hive flush cache via jmx;;;0;expose hive flush cache via jmx;;;;;;1;1;expose hive flush cache via jmx;
544;1;0;0;0;1;0;0;0;0;1;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;stop exchange operator immediately when task output is done;;;0;stop exchange operator immediately when task output is done;;;;;;1;1;stop exchange operator immediately when task output is done;
545;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;cache regexps for like and switch to joni;;;0;cache regexps for like and switch to joni;;;;;;1;1;use joni for matching like patterns;
548;1;0;1;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;limit the amount of memory for topn operator;;;0;limit the amount of memory for topn operator;;otherwise it ;;;;1;1;limit the amount of memory for topn operator;
549;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;optimize like expressions;- if pattern does not have % or _  replace with comparison expression - return new like expression with optimized operands;;0;optimize like expressions;- if pattern does not have % or _ replace with comparison expression- return new like expression with optimized operands;;;;;1;1;optimize like expressions- if pattern does not have % or _ replace with comparison expression- return new like expression with optimized operands;
550;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix null handling in like expressions;;;0;fix null handling in like expressions;;assuming a null escape should produce a null  yeah i checked the sql spec to be clear ||;;;;1;1;fix null handling in like expressions;
551;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add support for hive binary type;;;0;add support for hive binary type;;;;;;1;1;add support for hive binary type;
552;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;benchmark for in with constant list;;;0;benchmark for in with constant list;;nice :)  ship it! ||;;;;1;1;benchmark for in with constant list;
554;1;0;0;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;enable in benchmark;i forgot to add it to the benchmark suite;;0;enable in benchmark;i forgot to add it to the benchmark suite;;;;;1;1;add in benchmark to suite;
555;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;do not assume metastore.get_partitions_by_names returns partitions in the same order as requested;;;0;do not assume metastoreget_partitions_by_names returns partitions in the same order as requested;;;;;;1;1;do not assume metastoreget_partitions_by_names returns partitions in the same order as requested;
557;1;0;0;0;1;1;0;0;1;1;1;0;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add more information to events;add source  remote user address and user agent to session add partition id to hive split info;;0;add more information to events;add source remote user address and user agent to sessionadd partition id to hive split info;;;;;1;1;add partitionid to hivesplit info object;
558;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;add function type to show functions command;;;0;add function type to show functions command;;;;;;1;1;add function type to show functions command;
559;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add max split size to hive client;;;0;add max split size to hive client;;;;;;1;1;add max split size to hive client;
561;1;0;0;1;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;1;0;1;1;1;0;1;1;alter queries to support a querybody structure;;;0;alter queries to support a querybody structure;;;;;;1;1;alter queries to support a querybody structure;
562;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;support multiple wildcards in select list;;;0;support multiple wildcards in select list;;;;;;1;1;support multiple wildcards in select list;
563;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;expose some query/task manager stats via jmx;;;0;expose some query/task manager stats via jmx;;;;;;1;1;expose querymanager stats via jmx;
564;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add table name to hive split info;;;0;add table name to hive split info;;;;;;1;1;add table name to hive split info;
565;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;unpartitioned hive tables have no partition keys not no partitions;;;0;unpartitioned hive tables have no partition keys not no partitions;;;;;;1;1;unpartitioned hive tables have no partition keys not no partitions;
566;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;upgrade to hive-presto-shaded 0.5;;;0;upgrade to hive-presto-shaded 05;;;;;;1;1;upgrade to hive-presto-shaded 05;
567;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;add max page size limit;;;0;add max page size limit;;other than the comments this ;;;;1;1;add max page size limit;
569;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;better constrain buffer memory usage;add soft limit to exchange client buffer add soft limit to output sink buffer (sharedbuffer) size buffers in pagebuilder based on the size of previous page produced add more testing to exchange client;;0;better constrain buffer memory usage;add soft limit to exchange client bufferadd soft limit to output sink buffer (sharedbuffer)size buffers in pagebuilder based on the size of previous page producedadd more testing to exchange client;;;;;1;1;add sequence id to page buffer protocol to support failed/duplicate requests;
570;1;0;0;1;1;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;add missing @jsonproperty annotation to session source field;;;0;add missing @jsonproperty annotation to session source field;;;;;;1;1;add missing @jsonproperty annotation to session source field;
571;1;0;0;1;1;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;1;0;1;0;1;0;add com.fasterxml.jackson to parent-first packages;;;0;add comfasterxmljackson to parent-first packages;;;;;;1;1;add comfasterxmljackson to parent-first packages;
574;1;0;0;0;1;1;0;0;1;0;0;0;0;0;0;0;1;0;0;0;1;0;0;1;0;1;0;add union [all] support;;;0;add union [all] support;;i also threw in some unit test fixes and support for explicit table query syntax in the last few commits || great stuff! ship it! ||;;;;1;1;fix comments for pull #574;
578;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;limit size of response based on bytes not pages;;;0;limit size of response based on bytes not pages;;;;;;1;1;limit size of response based on bytes not pages;
580;1;0;0;1;0;1;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;use new shaded hadoop and hive artifacts;;;0;use new shaded hadoop and hive artifacts;;;;;;1;1;use new shaded hadoop and hive artifacts;
581;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;make query id actually unique;;;0;make query id actually unique;;;;;;1;1;make query id actually unique;
583;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;task manager fixes;;;0;task manager fixes;;;;;;1;1;fix sqltaskmanagerremoveoldtasks();
585;1;0;0;0;1;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;some extra commits for the union stuff;;;0;some extra commits for the union stuff;;;;;;1;1;move unsupported set operations to analyzer + some join rewriter fixes;
586;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;assure task info end time is set when task is done;;;0;assure task info end time is set when task is done;;;;;;1;1;assure task info end time is set when task is done;
587;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;provides a quick fix for the union ordering issue;;;0;provides a quick fix for the union ordering issue;;;;;;1;1;short term fix for union ordering expectation;
588;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;collapse project on filter;;;0;collapse project on filter;;;;;;1;1;collapse projection on filter into a single operator;
591;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;clear operator in worker after work is completed;;;0;clear operator in worker after work is completed;;;;;;1;1;clear operator in worker after work is completed;
592;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add tpch query 6 to benchmark;;;0;add tpch query 6 to benchmark;;;;;;1;1;add tpch query 6 to benchmark;
593;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;fix planning issue when grouping by repeated fields;;;0;fix planning issue when grouping by repeated fields;;;;;;1;1;fix planning issue when grouping by repeated fields;
594;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;avoid exponential backtracking when parsing nested expressions;;;0;avoid exponential backtracking when parsing nested expressions;;ship it ||;;;;1;1;avoid exponential backtracking when parsing nested expressions;
595;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;add queryid/stageid/taskid to worker thread names;;;0;add queryid/stageid/taskid to worker thread names;;;;;;1;1;add queryid/stageid/taskid to worker thread names;
597;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;really  when grouping by repeated fields;the previous fix was in the wrong place;;0;really  when grouping by repeated fields;the previous fix was in the wrong place;sure ||;;;;1;1;really  when grouping by repeated fieldsthe previous fix was in the wrong place;
598;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;normalize union input if the underlying projection differs from expected;;;0;normalize union input if the underlying projection differs from expected;;;;;;1;1;normalize union input if the underlying projection differs from expected;
600;1;0;1;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add basic regexp functions;;;0;add basic regexp functions;;add a benchmark too || ;;;;1;1;add basic regexp functions;
601;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add limit push down optimizer;;;0;add limit push down optimizer;;;;;;1;1;add limit push down optimizer;
605;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hang in like operator for invalid utf-8;;;0;fix hang in like operator for invalid utf-8;;;;;;1;1;fix hang in like operator for invalid utf-8;
606;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add support for is distinct from;;;0;add support for is distinct from;;;;;;1;1;add support for is distinct from;
609;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;some minor optimizations;;;0;some minor optimizations;;;;;;1;1;consider any matching host address node-local when hint doesnt have a port;
610;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;compiler;;;0;compiler;;looks good ship it! ||;;;;1;1;fallback to interpreter when compilation failed;
612;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;add the split_part string function;;;0;add the split_part string function;;;;;;1;1;add the split_part string function;
613;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;add url_extract and url_extract_param;;;0;add url_extract and url_extract_param;;;;;;1;1;add url_extract and url_extract_param;
615;1;0;0;0;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;codegen filter to record set;;;0;codegen filter to record set;;other than those minor comments it ;;;;1;1;rename byte code block methods for better consistency;
"616;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;1;0;0;0;1;0;make error message say  column  instead of  attribute;;;0;""make error message say """"column"""" instead of """"attribute"""""";;;;;;1;1;""make error message say """"column"""" instead of """"attribute"""""";"
618;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;excape single quotes when outputing string literal;;;0;excape single quotes when outputing string literal;;;;;;1;1;excape single quotes when outputing string literal;
619;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;refresh hive cached values in background;;;0;refresh hive cached values in background;;;;;;1;1;refresh hive cached values in background;
620;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;throw specific message for identifiers containing a colon;;;0;throw specific message for identifiers containing a colon;;;;;;1;1;throw specific message for identifiers containing a colon;
622;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;improve error messages;;;0;improve error messages;;;;;;1;1;improve error messages from function calls;
623;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add environment to event objects;;;0;add environment to event objects;;;;;;1;1;add environment to event objects;
624;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add json_array_length and json_array_contains;;;0;add json_array_length and json_array_contains;;other than the minor comments ;;;;1;1;add json_array_length and json_array_contains;
625;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;change sum(boolean) to count_if(boolean) with same null handeling as count;;;0;change sum(boolean) to count_if(boolean) with same null handeling as count;;;;;;1;1;change sum(boolean) to count_if(boolean) with same null handeling as count;
626;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;split url extraction into separate functions;;;0;split url extraction into separate functions;;;;;;1;1;split url extraction into separate functions;
"627;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;properly handle null in filter funtion result;;;0;properly handle null in filter funtion result;;""""""funtion"""" is misspelled in the commit message || "";;;;1;1;properly handle null in filter function result;"
628;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix comparisons of longs as doubles in interpreter;;;0;fix comparisons of longs as doubles in interpreter;;;;;;1;1;fix comparisons of longs as doubles in interpreter;
631;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;fix parsing of current_timestamp as a single expression;;;0;fix parsing of current_timestamp as a single expression;;;;;;1;1;fix parsing of current_timestamp as a single expression;
633;1;0;0;0;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;1;align compiler interpreter;;;0;align compiler interpreter;;;;;;1;1;add support for session functions;
634;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix bug in max/min aggregations with null strings;;;0;fix bug in max/min aggregations with null strings;;;;;;1;1;fix bug in max/min aggregations with null strings;
635;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;1;left join + predicate pushdown;;;0;left join + predicate pushdown;;with these changes a query with a where clause like the following one scans more partitions than necessary because the predicate is not considered for partition pruning:case when f(partition_key) then false when g(non_partition_key) then the key here is that for some values of partition_key the expression may evaluate to false regardless of what non_partition_key is bound to || i just ran all of the benchmarks and there is no noticeable performance degradation in joins or other operators || this is awesome great job! ||;;;;1;1;predicate pushdownincludes equality inference for joins and aggregationsincludes partition pruning;
636;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;reduce the number of expected groups;the current value of 100k means that each aggregation requires at least 400 kb of memory. for a query running ~120 splits per node  this adds up.;;0;reduce the number of expected groups;the current value of 100k means that each aggregation requires at least 400 kb of memory for a query running ~120 splits per node this adds up;;;;;1;1;reduce the number of expected groupsthe current value of 100k means that each aggregation requires at least 400 kb of memory for a query running ~120 splits per node this adds up;
638;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fix eclipse compile errors;the eclipse incremental compiler can not deal with the short expressions. hint with some casts.;;0;fix eclipse compile errors;the eclipse incremental compiler can not deal with the short expressions hint with some casts;;;;;1;1;fix eclipse java compile errorsthe eclipse incremental compiler can not deal with the short expressions hint with some casts;
641;1;0;0;0;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fix isnull call for classes generated against recordset;;;0;fix isnull call for classes generated against recordset;;;;;;1;1;fix isnull call for classes generated against recordset;
643;1;0;1;0;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;0;0;0;1;0;1;0;update operator stats when reading directly from recordset;;;0;update operator stats when reading directly from recordset;;;;;;1;1;update operator stats when reading directly from recordset;
644;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;add explain functionality to presto;;;0;add explain functionality to presto;;other than those minor changes it looks great ship it! ||;;;;1;1;add explain functionality;
646;1;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;1;0;1;1;0;0;0;1;0;1;0;add boolean support to render() function;;;0;add boolean support to render() function;; ;;;;1;1;add boolean support to render() function;
650;1;0;0;1;1;1;1;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix deadlock between stage with too many splits and substage with full output buffers;;;0;fix deadlock between stage with too many splits and substage with full output buffers;;;;;;1;1;fix deadlock between stage with too many splits and substage with full output buffers;
651;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add test for count with boolean argument;;;0;add test for count with boolean argument;;;;;;1;1;add test for count with boolean argument;
652;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;jdbc fixes;;;0;jdbc fixes;;other than the minor comments ;;;;1;1;use system proxy settings for jdbc driver;
654;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;add show schemas function;;;0;add show schemas function;;;;;;1;1;add show schemas function;
657;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;limit memory for entire task instead of per operator;;;0;limit memory for entire task instead of per operator;;;;;;1;1;fix  testdistributedqueriestestshowschemas;
658;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;0;1;0;1;0;rework tab complete to run a query and add tab complete for functions;;;0;rework tab complete to run a query and add tab complete for functions;;overall looks good ill re-review after the comments are addressed to make sure i didnt miss anything else || ;;;;1;1;rework tab complete to run a query and add tab complete for functions;
659;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;add support for right join;;;0;add support for right join;;;;;;1;1;add support for right join;
664;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;change operators to have pre allocated memory instead of a min flush size;;;0;change operators to have pre allocated memory instead of a min flush size;;;;;;1;1;change operators to have pre allocated memory instead of a min flush size;
670;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fix compilation of if and case statements with nulls;;;0;fix compilation of if and case statements with nulls;;;;;;1;1;fix compilation of if and case statements with nulls;
"671;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;add namespace to cli output;;;0;add namespace to cli output;;""rather than hard-coding the prompt name based on the session add a `prompt` option to `clientoptions` and have it default to """"presto"""" ||  "";;;;1;1;add schema to cli prompt;"
672;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;1;0;add format to explain queries  and add graphviz explain functionality;;;0;add format to explain queries and add graphviz explain functionality;;other than the minor comments ;;;;1;1;add format to explain queries and add graphviz explain functionality;
"673;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;0;filter active nodes by node version;;;0;filter active nodes by node version;;""the names """"implementationtitle"""" and """"implementationversion"""" seem overly long and are only named that way because the java `package` calls them that how about just """"name"""" and """"version""""? || "";;;;1;1;filter active nodes by node version;"
674;1;0;0;0;0;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;disable jackson field name canonicalization (string intern cache);close jackson parsers after use;;0;disable jackson field name canonicalization (string intern cache);close jackson parsers after use;;;;;1;1;disable jackson field name canonicalization (string intern cache)close jackson parsers after use;
675;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix compiler var-args warning;;;0;fix compiler var-args warning;;;;;;1;1;fix compiler var-args warning;
676;1;0;0;0;0;1;0;0;0;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;allow per-host configuration for hdfs;;;0;allow per-host configuration for hdfs;;please commit asap so i can test it ||;;;;1;1;make backgroundcacheloader package private;
677;1;0;0;0;1;0;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;stop processing if operatorstats says we ;;;0;stop processing if operatorstats says we ;;;;;;1;1;stop processing if operatorstats says we ;
678;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;parse hive column values as needed instead of all up front;;;0;parse hive column values as needed instead of all up front;;;;;;1;1;parse hive column values as needed instead of all up front;
681;1;0;0;0;1;0;0;0;0;1;1;0;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;exception fixes;;;0;exception fixes;;;;;;1;1;fix close exception in table writeronly report a bad close (with sources still left) if it was not causedby the operatorstats declare the query done anyway;
682;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;adjust the partition fetch batch characteristics;;;0;adjust the partition fetch batch characteristics;;;;;;1;1;adjust the partition fetch bound characteristicsthis was adjusted with emperically determined data;
683;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;1;1;0;0;0;0;0;0;only print wrap indicator for multiple rows;;;0;only print wrap indicator for multiple rows;;;;;;1;1;only print wrap indicator for multiple rows;
684;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;1;0;add function annotation for more verbose descriptions;;;0;add function annotation for more verbose descriptions;;did you mean to add the file `hiaiff`? || looks good after making above changes || aside from minor comments ;;;;1;1;add function annotation for more verbose descriptions;
685;1;0;0;1;0;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;hive timestamp fixes;;;0;hive timestamp fixes;;;;;;1;1;parse hive timestamps without fractional seconds;
686;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;1;1;1;1;0;1;1;use sql types for metadata;;;0;use sql types for metadata;;;;;;1;1;use sql types for metadata;
688;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;1;0;0;0;0;0;1;0;add -f <filename> option to run query from file;;;0;add -f <filename> option to run query from file;;;;;;1;1;add -f <filename> option to run query from file;
689;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;add vertical output;;;0;add vertical output;;other than the minor comments ;;;;1;1;add vertical output format;
690;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;fix tests;;;0;fix tests;;;;;;1;1;fix tests;
691;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;make pager configurable;;;0;make pager configurable;;;;;;1;1;make pager configurable;
692;1;0;0;0;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;0;0;0;1;0;1;1;stop operators when query is done;;;0;stop operators when query is done;;;;;;1;1;stop operators when query is done;
693;1;0;0;1;1;1;0;0;0;0;1;0;0;1;0;0;0;0;1;0;0;0;0;1;0;1;0;reduce requests;;;0;reduce requests;;looks good aside from comments ||;;;;1;1;wait on server side for out buffers to be createdwhen requesting data from an output buffer that doesnt exist yetwait for the buffer to be created on the server side;
694;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;add unsupported nodes to graphviz printer;;;0;add unsupported nodes to graphviz printer;;;;;;1;1;add unsupported nodes to graphviz printer;
696;1;0;0;0;1;1;0;0;1;0;0;0;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;predicate move around;;;0;predicate move around;;other than those minor comments it ;;;;1;1;fix review comments for pull #696;
698;1;0;0;1;0;0;0;0;0;1;1;0;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hangs in failing unit tests;;;0;fix hangs in failing unit tests;;;;;;1;1;fix hangs in failing unit tests;
699;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;1;1;1;1;1;0;1;0;update to responsehandler api change in airlift;;;0;update to responsehandler api change in airlift;;;;;;1;1;update to the new airlift units api;
701;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;extract testingdiscoveryserver to upper level;;;0;extract testingdiscoveryserver to upper level;;;;;;1;1;extract testingdiscoveryserver to upper level;
702;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;0;0;1;1;0;1;1;make queryabortedexception an ioexception;;;0;make queryabortedexception an ioexception;;;;;;1;1;make queryabortedexception an ioexception;
707;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;fixes for problems found in verifier;;;0;fixes for problems found in verifier;;;;;;1;1;dont close buffers for a failed queryclosed buffers signal to upstream tasks that everything finished cleanly;
708;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix eager evaluation of conditions;;;0;fix eager evaluation of conditions;;;;;;1;1;fix eager evaluation of conditions;
709;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix like escaping;makes it compliant to ansi;;0;fix like escaping;makes it compliant to ansi;aside from comment ;;;;1;1;fix like escaping;
710;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;add failed method to shared buffer to free writers on query failure;;;0;add failed method to shared buffer to free writers on query failure;;;;;;1;1;add failed method to shared buffer to free writers on query failure;
713;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;datetime function cleanup;;;0;datetime function cleanup;;;;;;1;1;add additional units for extract;
715;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix extract tests;;;0;fix extract tests;;;;;;1;1;fix extract tests;
719;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;1;0;1;1;0;1;1;use sql types in error messages;;;0;use sql types in error messages;; nice ||;;;;1;1;use sql types in error messages;
721;1;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;a few improvements for predicate move around;;;0;a few improvements for predicate move around;;;;;;1;1;make testeffectivepredicateextractor tests deterministic;
722;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;1;1;0;1;1;0;1;1;use escaping rather than enclosing quotes for tsv;;;0;use escaping rather than enclosing quotes for tsv;;;;;;1;1;use escaping rather than enclosing quotes for tsv;
723;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;1;1;1;0;1;0;support where and order by for show partitions;;;0;support where and order by for show partitions;;;;;;1;1;support where and order by for show partitions;
725;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;support limit for show partitions;;;0;support limit for show partitions;;;;;;1;1;support limit for show partitions;
728;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;handle stackoverflowerror from parser;;;0;handle stackoverflowerror from parser;;wow someone ran into this?  anyway  the query was over 3000 lines long ||;;;;1;1;handle stackoverflowerror from parser;
729;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;handle stackoverflowerror during analysis;;;0;handle stackoverflowerror during analysis;;;;;;1;1;handle stackoverflowerror during analysis;
730;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix non-deterministic predicate pushdown for aggregates and table scans;;;0;fix non-deterministic predicate pushdown for aggregates and table scans;;and yes i checked all other locations where this might happen and these are the only two points ||;;;;1;1;fix non-deterministic predicate pushdown for aggregates and table scans;
732;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;1;use supplier instead of provider for exchangeclient;;;0;use supplier instead of provider for exchangeclient;;;;;;1;1;use supplier instead of provider for exchangeclient;
733;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;1;use supplier instead of provider;;;0;use supplier instead of provider;;;;;;1;1;use supplier instead of provider for sourcehash;
734;1;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;add benchmark for sql join queries with predicates on the join clause;;;0;add benchmark for sql join queries with predicates on the join clause;;;;;;1;1;add benchmark for sql join queries with predicates on the join clause;
735;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;upgrade to airlift 0.79-snapshot;;;0;upgrade to airlift 079-snapshot;;;;;;1;1;upgrade to airlift 079-snapshot;
736;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add hive partition columns last to match hive;;;0;add hive partition columns last to match hive;;;;;;1;1;add hive partition columns last to match hive;
741;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;0;new operator framework;the commits are structured as follows - add new operator and testing framework - add new versions of all existing operators - convert execution engine to use new operators - add new scheduler that favors interactive queries - add blocking support to operators - rewrite the context and stats system  - convert compiler to new operators - convert benchmarks to new operators - convert storage manager to new operators - convert a few remaining tests - remove old operators  after this main body of work is reviewed  i will add additional commits to repackage and rename classes to the old style  because doing this before the review will make fixes more difficult.;;0;new operator framework;the commits are structured as follows- add new operator and testing framework- add new versions of all existing operators- convert execution engine to use new operators- add new scheduler that favors interactive queries- add blocking support to operators- rewrite the context and stats system - convert compiler to new operators- convert benchmarks to new operators- convert storage manager to new operators- convert a few remaining tests- remove old operatorsafter this main body of work is reviewed i will add additional commits to repackage and rename classes to the old style because doing this before the review will make fixes more difficult;i update the pull request to include the semi join changes || overall looks good @martint should review sqltaskexecution taskexecutor and newlocalexecutionplanner || last few commits ;;;;1;1;update ui to new stats;
742;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fix bad error message when response is empty in httpremotetask;;;0;fix bad error message when response is empty in httpremotetask;;;;;;1;1;fix bad error message when response is empty in httpremotetask;
745;1;0;0;1;1;1;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;switch back to resolver until aether is fixed;;;0;switch back to resolver until aether is ;;;;;;1;1;switch back to resolver until aether is ;
746;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;instrument thread pools;;;0;instrument thread pools;;;;;;1;1;instrument thread pools;
747;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;use more efficient api for finding split locations;;;0;use more efficient api for finding split locations;;;;;;1;1;use more efficient api for finding split locations;
751;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;parser changes for table sample;this request only has the changes made to the grammar for implementing tablesample.   used the syntax for tablesample from here:  parse tree for a sample query: https://gist.github.com/nileema/6458383;;0;parser changes for table sample;this request only has the changes made to the grammar for implementing tablesample used the syntax for tablesample from here:  tree for a sample query: https://gistgithubcom/nileema/6458383;;;;;1;1;parser changes for table sample;
752;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;fix for all columns with alias;for selecting all columns with alias (eg: select a.\* from orders a) we were building it as select true.\*  use the node.tostring instead which implements this correctly.;;0;fix for all columns with alias;for selecting all columns with alias (eg: select a\* from orders a) we were building it as select true\* use the nodetostring instead which implements this correctly;;;;;1;1;fix for all columns with alias;
754;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add logging for testexpressioncompiler;;;0;add logging for testexpressioncompiler;;;;;;1;1;add logging for testexpressioncompiler;
755;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;reduce memory usage on semi join test;it was failing sporadically on the distributed test due to heap space;;0;reduce memory usage on semi join test;it was failing sporadically on the distributed test due to heap space;;;;;1;1;reduce memory usage on semi join testit was failing sporadically on the distributed test due to heap space;
756;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hiveclient call to getfileblocklocations;;;0;fix hiveclient call to getfileblocklocations;;;;;;1;1;fix hiveclient call to getfileblocklocations;
757;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;remove native store related runtime configuration;;;0;remove native store related runtime configuration;;;;;;1;1;remove native store related runtime configuration;
758;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hash join handling of nulls;;;0;fix hash join handling of nulls;;;;;;1;1;fix hash join handling of nulls;
762;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;1;1;1;1;1;0;1;1;add license headers;;;0;add license headers;;;;;;1;1;add license headers;
763;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;1;1;1;1;1;0;1;1;fix code formatting and optimize imports;;;0;fix code formatting and optimize imports;;;;;;1;1;fix code formatting and optimize imports;
764;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;various fixes;;;0;various fixes;;;;;;1;1;run expression compiler tests in parallel;
765;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;updates;;;0;updates;;presto or prestocli?otherwise ;;;;1;1;rename server main class;
766;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;1;0;0;0;0;0;1;0;cli changes;;;0;cli changes;;looks good other than the mentioned things ||;;;;1;1;use single command mode for console;
770;1;0;0;1;1;1;0;0;0;0;1;1;1;1;0;0;1;0;1;0;0;0;1;1;0;1;0;limit the number of queries remembered after they are finished;prune the set of remembered queries down to a configurable number  but only consider queries that haven t heartbeat within the client timeout period.;;0;limit the number of queries remembered after they are finished;prune the set of remembered queries down to a configurable number but only consider queries that havent heartbeat within the client timeout period;;;;;1;1;limit the number of queries remembered after they are finishedprune the set of remembered queries down to a configurable number but only consider queries that havent heartbeat within the client timeout period;
774;1;0;0;0;0;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;convert to most succinct unit;;;0;convert to most succinct unit;;;;;;1;1;convert to most succinct unit;
"775;1;0;0;1;0;1;1;0;0;0;1;0;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;expose number of  live  nodes;;;0;""expose number of """"live"""" nodes"";;;;;;1;1;""expose number of """"live"""" nodes"";"
778;1;0;0;0;0;1;0;0;0;0;1;1;0;1;0;0;1;0;0;0;0;0;0;1;0;1;0;allow having multiple hive plugins;;;0;allow having multiple hive plugins;;;;;;1;1;allow having multiple hive plugins;
779;1;0;0;1;0;1;0;0;0;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;allow using hive plugin without discovery;;;0;allow using hive plugin without discovery;; you can configure the pool in the selector config in the catalog config just like any other config value of course all this stuff will go away when we load plugins dynamically ||;;;;1;1;allow using hive plugin without discovery;
780;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;fix network issue;only the last commit actually fixes this issue.  the others are useful fixes made while trying to fix the core issue;;0;fix network issue;only the last commit actually fixes this issue  the others are useful fixes made while trying to fix the core issue;;;;;1;1;assure operators are closed;
784;1;0;0;0;0;1;0;0;0;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix jmx stats for new operators;;;0;fix jmx stats for new operators;;;;;;1;1;remove unnecessary parenthesis;
785;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;add failure info to completion events;;;0;add failure info to completion events;;other than the comments this ;;;;1;1;add failure info to completion events;
787;1;0;0;0;0;1;0;0;0;0;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add counters for calls to operator addinput  getoutput  and finish;;;0;add counters for calls to operator addinput getoutput and finish;;;;;;1;1;add counters for calls to operator addinput getoutput and finish;
788;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;tablesample system implementation;recreating the pull request as it got closed earlier.;;0;tablesample system implementation;recreating the pull request as it got closed earlier;;;;;1;1;tablesample system implementation;
789;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;allow running locally without discovery;;;0;allow running locally without discovery;;;;;;1;1;verify that distributed tests use all nodes;
790;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;make cpu time tracking in operatorstats configurable;added task.cpu-timer-enabled  which can be used to turn off cpu time tracking;;0;make cpu time tracking in operatorstats configurable;added taskcpu-timer-enabled which can be used to turn off cpu time tracking;;;;;1;1;make cpu time tracking in operatorstats configurable withtaskcpu-timer-enabled;
792;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;random cleanups;;;0;random cleanups;;looks good but dont push until after the next release ||;;;;1;1;change default max split size;
793;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add functions for nan and infinity;add math functions related to nan and infinity.  - nan() - is_nan(value) - infinity() - is_infinity(value) - is_finite(value)  tested it on various combinations: https://gist.github.com/nileema/6734480;;0;add functions for nan and infinity;add math functions related to nan and infinity - nan()- is_nan(value)- infinity()- is_infinity(value)- is_finite(value)tested it on various combinations //gistgithubcom/nileema/6734480;rename is_infinity to is_infinite  || added all the tests in the gist to abstracttestqueries refactored the code in expressioninterpreter  || other than the minor comments  aside from comments looks good ||;;;;1;1;add functions for nan and infinity;
794;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;close recordreader when advance reaches the end or throws;;;0;close recordreader when advance reaches the end or throws;;;;;;1;1;close recordreader when advance reaches the end or throws;
795;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;scheduling fixes;;;0;scheduling fixes;;;;;;1;1;fix blocked writer leaks in sharedbufferremove old unused buffer apis;
796;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;protect against bad hadoop input formats;;;0;protect against bad hadoop input formats;;;;;;1;1;protect against bad hadoop input formats;
798;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;remove legacy config names;;;0;remove legacy config names;;;;;;1;1;remove legacy config names;
799;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;improve speed of tablesample tests;;;0;improve speed of tablesample tests;;;;;;1;1;improve speed of tablesample tests;
800;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;partitioned hash aggregations;this implements a fixed size partitioning for hash aggregations set by the  query.initial-hash-partitions  configuration option (default 8);;0;partitioned hash aggregations;this implements a  size partitioning for hash aggregations set by the `queryinitial-hash-partitions` configuration option (default 8);;;;;1;1;add hash partitioned aggregations;
801;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;fix license of classinfoloader;;;0;fix license of classinfoloader;;;;;;1;1;fix license of classinfoloader;
804;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;hive plugin cleanup;;;0;hive plugin cleanup;;i just finished reviewing the code and added a bunch of comments but now they are all gone  did you get any of my comments in email?  || i received 5 comments via email ||;;;;1;1;fix warnings for tests;
806;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;improve query performance for hive bucketed tables;;;0;improve query performance for hive bucketed tables;;;;;;1;1;improve query performance for hive bucketed tables;
807;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;allow parsing create table as select;;;0;allow parsing create table as select;;;;;;1;1;allow parsing create table as select;
808;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;fix bucket hashing test;;;0;fix bucket hashing test;;;;;;1;1;fix bucket hashing test;
809;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;split up querymanagerconfig;this renames the following property:     query.shard.max-threads  ->  task.shard.max-threads   additionally  a new config property  task.info.max-age  is split out from the  query.info.max-age  property. the task property controls how often the coordinator must heartbeat tasks on the workers. the query property controls how often the end user (statement client) must heartbeat the query on the coordinator.;;0;split up querymanagerconfig;this renames the following property:  `queryshardmax-threads` -> `taskshardmax-threads`additionally a new config property `taskinfomax-age` is split outfrom the `queryinfomax-age` property the task property controlshow often the coordinator must heartbeat tasks on the workers thequery property controls how often the end user (statement client)must heartbeat the query on the coordinator;nice! much cleaner!ship it! ||;;;;1;1;split up querymanagerconfigthis renames the following property:  queryshardmax-threads -> taskshardmax-threadsadditionally a new config property taskinfomax-age is split outfrom the queryinfomax-age property the task property controlshow often the coordinator must heartbeat tasks on the workers thequery property controls how often the end user (statement client)must heartbeat the query on the coordinator;
810;1;0;0;1;0;1;0;0;0;1;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;fixes;;;0;fixes;;looks good but @dain should also look at the second one to make sure we didnt make incorrect assumptions || ;;;;1;1;remove unused configuration;
811;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;1;0;0;0;0;1;0;parser changes for creating stratified samples with tablesample;this diff adds an optional  stratify on  clause to  tablesample  in the parser.  examples:   select * from temp tablesample bernoulli (50) stratify on (col_a)   select * from temp tablesample system (50) stratify on (col_a  col_b);;0;parser changes for creating stratified samples with tablesample;this diff adds an optional `stratify on` clause to `tablesample` in the parserexamples:`select * from temp tablesample bernoulli (50) stratify on (col_a)``select * from temp tablesample system (50) stratify on (col_a col_b)`;;;;;1;1;parser changes for creating stratified samples with tablesample;
812;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;1;1;0;1;1;fix overly broad exception handling;;;0;fix overly broad exception handling;;;;;;1;1;fix overly broad exception handling;
817;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;fix cli history behavior on user interrupt;this is a temporary fix until a new jline is released.;;0;fix cli history behavior on user interrupt;this is a temporary fix until a new jline is released;;;;;1;1;fix cli history behavior on user interruptthis is a temporary fix until a new jline is released;
818;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;0;1;0;1;0;update to airlift with jetty 9 client and server;;;0;update to airlift with jetty 9 client and server;;;;;;1;1;update to airlift with jetty 9 client and server;
821;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix for hive bucketed tables;additional checks to ensure that we apply bucketing only when a table is bucketed.;;0;fix for hive bucketed tables;additional checks to ensure that we apply bucketing only when a table is bucketed;;;;;1;1;fix for hive bucketed tables;
822;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;allow subclasses to use different partition types;;;0;allow subclasses to use different partition types;;;;;;1;1;allow subclasses to use different partition types;
825;1;0;0;1;1;1;1;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;only announce coordinator if configured as one;this fixes a bug introduced in the coordinatormodule refactoring that causes every node to announce itself as a coordinator.;;0;only announce coordinator if configured as one;this fixes a bug introduced in the coordinatormodule refactoringthat causes every node to announce itself as a coordinator;;;;;1;1;only announce coordinator if configured as onethis fixes a bug introduced in the coordinatormodule refactoringthat causes every node to announce itself as a coordinator;
831;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;1;make interpreter stateless;;;0;make interpreter stateless;;;;;;1;1;make interpreter stateless;
832;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;0;modify spi to enable range predicate pushdown and negotiation with connectors;as a simple extension of this new api  all of our connectors are now able to feed back domain information from partitions during the optimization phase to enable greater plan optimizations.;;0;modify spi to enable range predicate pushdown and negotiation with connectors;as a simple extension of this new api all of our connectors are now able to feed back domain information from partitions during the optimization phase to enable greater plan optimizations;minor comments this time around otherwise ;;;;1;1;add support for range predicate pushdownsthis work is a complete refactor of how we generate partitions in the planning/execution phasesinstead of generating partitions after planning we now integrate the generation directlyinto the optimization planning phase so that we can iterate our plan based on data returnedby the partitions that we discover this not only provides a number of opportunities foroptimization but also significantly simplifies the amount of cross-talk between thesplit generation and the planning phases as a result of these changes it makesit much easier to build native range predicate push downs;
834;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;handle binary rcfiles correctly;this also changes the unit tests to work correctly when the timezone is set to that of the hive installation.;;0;handle binary rcfiles correctly;this also changes the unit tests to work correctly when the timezone is set to that of the hive installation;huge :+1: as this lets me remove my nasty hack || ;;;;1;1;only use byteshiverecordcursor for columnarserdethis fixes reading data for tables that use lazybinarycolumnarserde;
835;1;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix tests when run with non-utc timezone;;;0;fix tests when run with non-utc timezone;;;;;;1;1;fix tests when run with non-utc timezone;
836;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;rename jdbc classes to start with presto;;;0;rename jdbc classes to start with presto;;;;;;1;1;rename jdbc classes to start with presto;
837;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;allow running embedded version of discovery;simplify deployment by allowing presto to run an embedded version of the discovery service. this embedded version only supports dynamic announcements. it does not have a static store.;;0;allow running embedded version of discovery;simplify deployment by allowing presto to run an embedded version of the discovery service this embedded version only supports dynamic announcements it does not have a static store;;;;;1;1;allow running embedded version of discoverysimplify deployment by allowing presto to run an embedded versionof the discovery service this embedded version only supportsdynamic announcements it does not have a static store;
846;1;0;0;1;0;1;0;0;0;0;1;0;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;example plugin;this connector exposes schemas defined in the  metadata-uri  catalog property.  the  metadata-uri  can reference a local file or a remote  resource.  the table data files are simple csv (no escaping supported) fetched from a location relative to the  metadata-uri .  the sample  etc/catalog/example.properties  file has uris for local file data and a sample remote dataset hosted on amazon s3.;;0;example plugin;this connector exposes schemas defined in the `metadata-uri` catalog property  the `metadata-uri` can reference a local file or a remote  resource  the table data files are simple csv (no escaping supported) fetched from a location relative to the `metadata-uri`  the sample `etc/catalog/exampleproperties` file has uris for local file data and a sample remote dataset hosted on amazon s3;rename the package to `example || ;;;;1;1;example plugin;
"857;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;cli hangs when the server goes away;presto cli hangs for a long time when the server goes away. add a check to see if the client is closed so that we can get out of this state by pressing ctrl-c;;0;cli hangs when the server goes away;presto cli hangs for a long time when the server goes away add a check to see if the client is closed so that we can get out of this state by pressing ctrl-c;""this actually fixes the `statementclient` which is used by jdbc not just the cli so something like """"fix client hang when the server goes away"""" would be a better commit message  "";;;;1;1;fix client hang when the server goes away;"
862;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;verify jvm requirements;;;0;verify jvm requirements;;[info] checking licenses[warning] missing header in: /home/travis/build/facebook/presto/presto-server/src/main/java/com/facebook/presto/server/prestojvmrequirementsjava || ;;;;1;1;verify jvm requirements;
863;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;0;show catalogs;list all the loaded catalogs - creates an in memory system table for all the catalog names.;;0;show catalogs;list all the loaded catalogs - creates an in memory system table for all the catalog names;the execution bits looks good to me but someone else should check the grammar parts || overall ;;;;1;1;show catalogs;
865;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add hive plugin for apache hadoop 1.x;;;0;add hive plugin for apache hadoop 1x;;;;;;1;1;add hive plugin for apache hadoop 1x;
866;1;0;0;1;1;1;1;0;1;1;1;0;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;restore binding for node resource;;;0;restore binding for node resource;;;;;;1;1;restore binding for node resource;
869;1;0;0;0;1;0;0;0;0;0;0;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;show correct error message when catalog name is incorrect;;;0;show correct error message when catalog name is incorrect;;;;;;1;1;correct error message for invalid catalog name;
870;1;0;0;0;1;0;0;0;0;1;1;0;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix test;;;0;fix test;;;;;;1;1;fix test;
873;1;0;0;1;0;1;0;0;0;0;1;0;0;1;0;0;1;0;1;0;0;0;0;0;0;1;0;fix tests for example- plugin;;;0;fix tests for example- plugin;;;;;;1;1;fix tests for example- plugin;
"878;1;0;0;0;1;1;0;0;1;0;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;cross joins;;;0;cross joins;;""id change the commit message to say something like """"add analyzer and planner support for cross joins""""other than those minor comments it  does this do cross joins across catalogs? || yep (note you will have to qualify at least one of your tables with the appropriate catalog and schemas) actually all joins can process across catalogs and schemas in the same way || thats great || "";;;;1;1;support cross joins;"
"879;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;rename tablewriter to materializedviewwriter;;;0;rename tablewriter to materializedviewwriter;;""why """"materialized view""""? the tablewriter is more general than that and applies also to create table as select etc or are you just getting it out of the way for the refactorings you are about to do? || looks good btw || "";;;;1;1;rename materialized view destination;"
883;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;1;0;0;0;0;0;0;0;add --source option to cli;this lets you set the source of the query for logging purposes. tested by running the cli with --help to make sure the option showed up  and added a unit test;;0;add --source option to cli;this lets you set the source of the query for logging purposes testedby running the cli with --help to make sure the option showed up andadded a unit test;;;;;1;1;add --source option to clithis lets you set the source of the query for logging purposes testedby running the cli with --help to make sure the option showed up andadded a unit test;
884;1;0;0;1;1;1;0;0;0;1;1;1;0;1;0;0;1;0;1;0;0;0;0;0;0;1;0;use uuid for native shard ids;;;0;use uuid for native shard ids;;;;;;1;1;use uuid for native shard ids;
885;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;implement show schemas from syntax;allows you to show schemas from a specific catalog. tested by running show schemas  and show schemas from multifeed;;0;implement show schemas from syntax;allows you to show schemas from a specific catalog tested by runningshow schemas and show schemas from multifeed;looks good but you should a test to abstracttestqueries (see testshowschemas) ||;;;;1;1;implement show schemas from syntaxallows you to show schemas from a specific catalog added a unit test;
888;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;execution performance improvements;change blocks and tupleinfo to only contain a single field value move looping into aggregation implementations use classloader magic to share base classes of aggregations without creating megamorphic call sites change aggregation to support multi-channel grouping change orderby  topn  and window to support multi-channel sorting change join to support multi-channel keys pipeline schedule splits in batches instead of one at a time;;0;execution performance improvements;change blocks and tupleinfo to only contain a single field valuemove looping into aggregation implementationsuse classloader magic to share base classes of aggregations without creating megamorphic call siteschange aggregation to support multi-channel groupingchange orderby topn and window to support multi-channel sortingchange join to support multi-channel keyspipeline schedule splits in batches instead of one at a time;i think one of your commits broke the hive integration tests when i try to run them on this branch they just hang || all feed back has been integrated  other than the noted file above the changes were trivial i added two new commits to the end to fix bugs i found during testing and need to be reviewed ||;;;;1;1;fix spurious illegalstateexception in statementresource;
889;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add custom cursor for rc binary format;ran the unit tests  and also ran a simple query against a table in the hivedev cluster;;0;add custom cursor for rc binary format;ran the unit tests and also ran a simple query against a table in the hivedev cluster;other than those minor comments it ;;;;1;1;add custom record cursor for rc binary files;
891;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add empty strings to hive integration test;;;0;add empty strings to hive integration test;;looks good  the test tables should be updated before this is pushed || i updated all the test tables ||;;;;1;1;add empty strings to hive integration test;
895;1;0;0;1;1;0;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add catalog and schema to jdbc string;;;0;add catalog and schema to jdbc string;;please also add a test for connecting with a catalog but no schema || overall ;;;;1;1;add catalog and schema to jdbc string;
898;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;refactor hiverecordset to make it easier to extend with new file formats;;;0;refactor hiverecordset to make it easier to extend with new file formats;;;;;;1;1;refactor hiverecordset to make it easier to extend with new file formats;
904;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;change date  time  timestamp and interval to be non-reserved words;;;0;change date time timestamp and interval to be non-reserved words;;;;;;1;1;change date time timestamp and interval to be non-reserved words;
905;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add unit tests for rc binary and rc text;;;0;add unit tests for rc binary and rc text;;;;;;1;1;add unit tests for rc binary and rc text;
906;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;implement distinct limit operator;;;0;implement distinct limit operator;;i would add a visitor for effectivepredicateextractor too the visitor should be the same as visitlimit || the operator code looks good to me other than removing the extra memory tracking code  additionally we need a unit test for the operator || awesome ;;;;1;1;implement distinct limit operator;
"907;1;0;0;1;1;0;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;implement some functions in presto jdbc driver;got basic queries running in squirrel sql client;;0;implement some functions in presto jdbc driver;got basic queries running in squirrel sql client;""minor nit: no need to say """"presto"""" in the commit message || aside from minor comments  `testcatalogtablecolumnnames` failed in the travis ci build || aside from failing test (see inline comment) and minor nits @electrum any chance to have this in the next release? || "";;;;1;1;implement some functions in jdbc driver;"
"909;1;0;0;1;1;1;1;0;0;0;1;1;1;1;0;0;1;0;1;1;0;1;1;1;0;1;0;implement use catalog and use schema;;;0;implement use catalog and use schema;;""this is only for the cli so i dont think it should go in the parser should be easy enough to do using the tokens from the statement splitter || the issue is that the tokens would need to go in the grammar anyway otherwise wed be relying on accidental behavior (ie that a word such as """"use"""" parses as an identifier etc) it would also be harder to support quoted identifiers and more flexible syntaxthe correct way would be to use embedded parsers but thats really hard to get right with antlr and not worth the pain thats why we decided to go with this approach || id like to see the `console` one more time after the comments are addressed before this is pushed || if it is easy can you add a quick unit test for the statement processing code  if it is not easy i have confidence this will workother then the above comments   "";;;;1;1;use catalog and use schema;"
"911;1;0;0;1;1;1;1;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;0;add a summarized print of tablescannode tupledomain to cut down on logging size;formatting:  where there are a small number of range segments:  presto> explain select ds  id  count(1) as count from table where ds >=  2013-11-15  and (type= a  or type= b ) group by ds  id   --- - output[ds  id  count]        id := id        count := count   - aggregate[ds  id] => [ds:varchar  id:varchar  count:bigint]          count := count( expr )     - project => [ds:varchar  id:varchar  expr:bigint]            expr := 1       - tablescan[default:default:table  original constrant=(( ds  >=  2013-11-15 ) and (( type  =  a ) or ( type  =  b )))  domain={ds => domain{ranges=[[2013-11-15]  [2013-11-16]  [2013-11-17]  [2013-11-18]  [2013-11-19]  [2013-11-20]]  nullallowed=false}  type => domain{ranges=[[a]  [b]]  nullallowed=false}}] => [id:varchar  ds:varchar]              id := hivecolumnhandle{clientid=default  name=id  ordinalposition=1  hivetype=string  hivecolumnindex=6  partitionkey=false}              ds := hivecolumnhandle{clientid=default  name=ds  ordinalposition=2  hivetype=string  hivecolumnindex=-1  partitionkey=true}              type := hivecolumnhandle{clientid=default  name=type  ordinalposition=3  hivetype=string  hivecolumnindex=-1  partitionkey=true}  (1 row)  when there are a large number of range segments:  presto> explain select ds  id  count(1) as count from table where ds >=  2012-11-15  and (type= a  or type= b ) group by ds  id  ##                                                                                                                                                                                                                                                               query plan - output[ds  id  count]        id := id        count := count   - aggregate[ds  id] => [ds:varchar  id:varchar  count:bigint]          count := count( expr )     - project => [ds:varchar  id:varchar  expr:bigint]            expr := 1       - tablescan[default:default:table  original constrant=(( ds  >=  2012-11-15 ) and (( type  =  a ) or ( type  =  b )))  domain={ds => summarized:domain{ranges=[[2013-08-04  2013-12-15]]  nullallowed=false}  type => domain{ranges=[[a]  [b]]  nullallowed=false}}] => [id:varchar  ds:varchar]              id := hivecolumnhandle{clientid=default  name=id  ordinalposition=1  hivetype=string  hivecolumnindex=1  partitionkey=false}              ds := hivecolumnhandle{clientid=default  name=ds  ordinalposition=2  hivetype=string  hivecolumnindex=-1  partitionkey=true}              type := hivecolumnhandle{clientid=default  name=type  ordinalposition=3  hivetype=string  hivecolumnindex=-1  partitionkey=true}  (1 row);;0;add a summarized print of tablescannode tupledomain to cut down on logging size;""formatting:where there are a small number of range segments:presto> explain select ds id count(1) as count from table where ds > 2013-11-15 and (typea or typeb) group by ds id---- output[ds id count]       id : id       count : count  - aggregate[ds id] > [ds:varchar id:varchar count:bigint]         count : count(""""expr"""")    - project > [ds:varchar id:varchar expr:bigint]           expr : 1      - tablescan[default table original constrant((""""ds"""" > 2013-11-15) and ((""""type""""  a) or (""""type""""  b))) domain{ds > domain{ranges[[2013-11-15] [2013-11-16] [2013-11-17] [2013-11-18] [2013-11-19] [2013-11-20]] nullallowedfalse} type > domain{ranges[[a] [b]] nullallowedfalse}}] > [id:varchar ds:varchar]             id : hivecolumnhandle{clientiddefault nameid ordinalposition1 hivetypestring hivecolumnindex6 partitionkeyfalse}             ds : hivecolumnhandle{clientiddefault nameds ordinalposition2 hivetypestring hivecolumnindex-1 partitionkeytrue}             type : hivecolumnhandle{clientiddefault nametype ordinalposition3 hivetypestring hivecolumnindex-1 partitionkeytrue}(1 row)when there are a large number of range segments:presto> explain select ds id count(1) as count from table where ds > 2012-11-15 and (typea or typeb) group by ds id##                                                                                                                                                                                                                                                               query plan- output[ds id count]       id : id       count : count  - aggregate[ds id] > [ds:varchar id:varchar count:bigint]         count : count(""""expr"""")    - project > [ds:varchar id:varchar expr:bigint]           expr : 1      - tablescan[default table original constrant((""""ds"""" > 2012-11-15) and ((""""type""""  a) or (""""type""""  b))) domain{ds > summarized:domain{ranges[[2013-08-04 2013-12-15]] nullallowedfalse} type > domain{ranges[[a] [b]] nullallowedfalse}}] > [id:varchar ds:varchar]             id : hivecolumnhandle{clientiddefault nameid ordinalposition1 hivetypestring hivecolumnindex1 partitionkeyfalse}             ds : hivecolumnhandle{clientiddefault nameds ordinalposition2 hivetypestring hivecolumnindex-1 partitionkeytrue}             type : hivecolumnhandle{clientiddefault nametype ordinalposition3 hivetypestring hivecolumnindex-1 partitionkeytrue}(1 row)"";""the github formatting is a little screwed up but you get the idea im open to suggestions on different formatting || how about this:```output[ds id count]        id : id        count : count    aggregate[ds id] > [ds:varchar id:varchar count:bigint]            count : count(""""expr"""")        project > [ds:varchar id:varchar expr:bigint]                expr : 1            tablescan[default table original constraint((""""ds"""" > 2013-11-15) and ((""""type""""  a) or (""""type""""  b)))] > [id:varchar ds:varchar]                 id : hivecolumnhandle{clientiddefault nameid ordinalposition1 hivetypestring hivecolumnindex6 partitionkeyfalse}                 ds : hivecolumnhandle{clientiddefault nameds ordinalposition2 hivetypestring hivecolumnindex-1 partitionkeytrue}                     :: [2013-11-15 2013-11-16 2013-11-17 2013-11-18 2013-11-19 2013-11-20]                type : hivecolumnhandle{clientiddefault nametype ordinalposition3 hivetypestring hivecolumnindex-1 partitionkeytrue}                    :: [a b null]``````output[ds id count]        id : id        count : count    aggregate[ds id] > [ds:varchar id:varchar count:bigint]             count : count(""""expr"""")        project > [ds:varchar id:varchar expr:bigint]                expr : 1            tablescan[default table original constraint((""""ds"""" > 2013-11-15) and ((""""type""""  a) or (""""type""""  b)))] > [id:varchar ds:varchar]                     id : hivecolumnhandle{clientiddefault nameid ordinalposition1 hivetypestring hivecolumnindex6 partitionkeyfalse}                     ds : hivecolumnhandle{clientiddefault nameds ordinalposition2 hivetypestring hivecolumnindex-1 partitionkeytrue}                         :: [2013-11-152013-11-20]                    type : hivecolumnhandle{clientiddefault nametype ordinalposition3 hivetypestring hivecolumnindex-1 partitionkeytrue}                        :: [a b null]```btw i dont think calling out whether its a summary or not is important ||  "";;;;1;1;add a summarized print of tablescannode tupledomain to cut down on logging size;"
912;1;0;0;0;1;1;0;0;1;0;0;1;1;0;0;0;1;0;1;0;0;1;0;1;0;1;0;add support for distinct in aggregations for simple cases;supports count(distinct) and distinct in other aggregations  as long as there is only one distinct expression  and all the aggregations use this expression. also  using it with group by is not supported yet.;;0;add support for distinct in aggregations for simple cases;supports count(distinct) and distinct in other aggregations as long asthere is only one distinct expression and all the aggregations use thisexpression also using it with group by is not supported yet;;;;;1;1;add support for distinct in aggregations for simple casessupports count(distinct) and distinct in other aggregations as long asthere is only one distinct expression and all the aggregations use thisexpression also using it with group by is not supported yet;
915;1;0;0;1;1;1;1;0;0;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;set no more buffers for hash distributed node;;;0;set no more buffers for hash distributed node;;;;;;1;1;set no more buffers for hash distributed node;
916;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;add create table as select for native tables;;;0;add create table as select for native tables;;other than the comments looks good  i would have liked to see the connector providing the `tablewriteroperator` and `tablecommitoperator` directly  this would allow the two operators to define the protocol between themselves  this means that your code would not need to encode the `nodeid` and `sharduuid` into a string but instead they could have just had multiple columns  we still need the `recordsink` and existing `tablewriteroperator` and `tablecommitoperator` to ease connector development (much like we have the recordprojectionoperator for reading)  my guess is this would make planning a lot more difficult implementthat said this is definitely good enough for a first pas on this feature ||;;;;1;1;add null checks and fix warnings;
917;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix querying tables with missing bucket columns;;;0;fix querying tables with missing bucket columns;;;;;;1;1;fix querying tables with missing bucket columns;
919;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;fix handling of hive bucketed tables;this 918.;;918.0;fix handling of hive bucketed tables;this 918;;fix handling of hive bucketed tables;the bucketing code assumes that tables declared as being bucketed actually have the correct file layout in hdfs `hivesplititerable` currently walks the directly structure as normal when bucketing is enabled and skips any files that dont match the bucket file it should do this instead:- verify that the directory has exactly the right number of files- verify that the directory has no subdirectories- if all checks pass return splits for the bucket file- otherwise ignore bucketing and return splits for all files as normalthe bucket file is determined by sorting the filenames lexicographically and returning the nth file;;1;0;fix handling of hive bucketed tables;
920;1;0;0;1;1;1;1;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;1;1;0;1;0;fix hash distributed aggregations;split distribution strategy and output buffer partition strategy;;0;fix hash distributed aggregations;split distribution strategy and output buffer partition strategy;;;;;1;1;fix hash distributed aggregationssplit distribution strategy and output buffer partition strategy;
927;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add table creation for hive;;;0;add table creation for hive;;;;;;1;1;add table creation for hive;
929;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;fix table creation;;;0;fix table creation;;@dain needs to review the execution changes || ;;;;1;1;fix closing of unpartitioned driver factories;
930;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;don t swallow exception when dropping table;;;0;dont swallow exception when dropping table;;;;;;1;1;dont swallow exception when dropping table;
932;1;0;0;0;1;1;0;0;1;0;0;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;remove support for implicit cross joins;the pre-ansi join syntax makes it very easy to accidentally perform a cross join when an inner join was intended  not to mention resulting in harder to read queries  so we need a way to disable it via configuration.;;0;remove support for implicit cross joins;the pre-ansi join syntax makes it very easy to accidentally perform across join when an inner join was intended not to mention resulting inharder to read queries so we need a way to disable it via configuration;;;;;1;1;remove support for implicit cross joinsthe pre-ansi join syntax makes it very easy to accidentally perform across join when an inner join was intended not to mention resulting inharder to read queries so we need a way to disable it via configuration;
940;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;simplify handling multiple hadoop versions;;;0;simplify handling multiple hadoop versions;;;;;;1;1;simplify handling multiple hadoop versions;
943;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add hive plugin for apache hadoop 2.x;;;0;add hive plugin for apache hadoop 2x;;;;;;1;1;add hive plugin for apache hadoop 2x;
944;1;0;1;1;1;0;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;tpch plugin;add a plugin based on the airlift tpch data generator.  this also converts test and benchmarks to use generated data instead of static files.  for benchmarks this code replaces tpchblocksprovider with create table commands using localqueryrunner.  the means that benchmarks now use the native plugin which adds about 1-3ms to the benchmarks times.  for super fast benchmarks (e.g.  count_agg and raw_stream)  this appears as a huge performance drop.  before:                                count_agg ::    0.697 cpu ms :: in  1.5m   12.9mb    2.15b/s     18gb/s :: out     1       9b    1.43k/s   12.6kb/s                      double_sum_agg ::   10.741 cpu ms :: in  1.5m   12.9mb     140m/s   1.17gb/s :: out     1       9b       93/s     837b/s                            hash_agg ::  137.724 cpu ms :: in  1.5m   21.5mb    10.9m/s    156mb/s :: out     3      45b       21/s     326b/s                    predicate_filter ::   55.698 cpu ms :: in  1.5m   12.9mb    26.9m/s    231mb/s :: out 1.29m   11.1mb    23.1m/s    199mb/s                          raw_stream ::    0.810 cpu ms :: in  1.5m   12.9mb    1.85b/s   15.5gb/s :: out  1.5m   12.9mb    1.85b/s   15.5gb/s                              top100 ::   41.238 cpu ms :: in  1.5m   12.9mb    36.4m/s    312mb/s :: out   100     900b    2.42k/s   21.3kb/s              in_memory_orderby_1.5m :: 1521.210 cpu ms :: in  1.5m   41.5mb     986k/s   27.3mb/s :: out  1.5m   28.6mb     986k/s   18.8mb/s                          hash_build ::  529.348 cpu ms :: in  1.5m   25.7mb    2.83m/s   48.6mb/s :: out  1.5m   25.7mb    2.83m/s   48.6mb/s                           hash_join :: 1643.575 cpu ms :: in    6m    103mb    3.65m/s   62.7mb/s :: out    6m    206mb    3.65m/s    125mb/s                 hash_build_and_join :: 2215.610 cpu ms :: in  7.5m    129mb    3.39m/s   58.1mb/s :: out    6m    206mb    2.71m/s     93mb/s                   hand_tpch_query_1 :: 2450.150 cpu ms :: in    6m    361mb    2.45m/s    147mb/s :: out     4     300b        1/s     122b/s                   hand_tpch_query_6 ::  289.359 cpu ms :: in    6m    240mb    20.7m/s    831mb/s :: out     1       9b        3/s      31b/s     sql_groupby_agg_with_arithmetic ::  891.984 cpu ms :: in    6m    137mb    6.73m/s    154mb/s :: out     2      30b        2/s      33b/s                       sql_count_agg ::    1.578 cpu ms :: in  1.5m   12.9mb     950m/s   7.97gb/s :: out     1       9b      633/s   5.57kb/s                  sql_double_sum_agg ::   12.196 cpu ms :: in  1.5m   12.9mb     123m/s   1.03gb/s :: out     1       9b       81/s     737b/s               sql_count_with_filter ::   61.586 cpu ms :: in  1.5m   8.58mb    24.4m/s    139mb/s :: out     1       9b       16/s     146b/s                     sql_groupby_agg ::  139.857 cpu ms :: in  1.5m   21.5mb    10.7m/s    153mb/s :: out     3      45b       21/s     321b/s                sql_predicate_filter ::   37.860 cpu ms :: in  1.5m   12.9mb    39.6m/s    340mb/s :: out 1.29m   11.1mb      34m/s    292mb/s                      sql_raw_stream ::    1.508 cpu ms :: in  1.5m   12.9mb     995m/s   8.34gb/s :: out  1.5m   12.9mb     995m/s   8.34gb/s                         sql_top_100 ::   42.490 cpu ms :: in  1.5m   12.9mb    35.3m/s    303mb/s :: out   100     900b    2.35k/s   20.7kb/s                       sql_hash_join :: 3281.675 cpu ms :: in  7.5m    129mb    2.29m/s   39.2mb/s :: out    6m    206mb    1.83m/s   62.8mb/s             sql_join_with_predicate ::  787.630 cpu ms :: in  7.5m    116mb    9.52m/s    147mb/s :: out     1       9b        1/s      11b/s                   sql_varbinary_max ::  182.818 cpu ms :: in    6m   97.3mb    32.8m/s    532mb/s :: out     1      21b        5/s     114b/s                  sql_distinct_multi ::  199.495 cpu ms :: in  1.5m     32mb    7.52m/s    161mb/s :: out     5     112b       25/s     561b/s                 sql_distinct_single ::   93.074 cpu ms :: in  1.5m   12.9mb    16.1m/s    138mb/s :: out     1       9b       10/s      96b/s                    sql_tpch_query_1 :: 2503.541 cpu ms :: in    6m    361mb     2.4m/s    144mb/s :: out     4     336b        1/s     134b/s                    sql_tpch_query_6 ::  268.098 cpu ms :: in    6m    240mb    22.4m/s    897mb/s :: out     1       9b        3/s      33b/s                            sql_like :: 2812.936 cpu ms :: in    6m    232mb    2.13m/s   82.4mb/s :: out 1.15m   9.84mb     408k/s    3.5mb/s                              sql_in ::   67.976 cpu ms :: in    6m   51.5mb    88.3m/s    758mb/s :: out    25     225b      367/s   3.23kb/s                     sql_semijoin_in :: 1660.280 cpu ms :: in  7.5m   64.4mb    4.52m/s   38.8mb/s :: out    3m   25.8mb    1.81m/s   15.5mb/s                     sql_regexp_like :: 1853.437 cpu ms :: in  1.5m   76.6mb     809k/s   41.3mb/s :: out     1       9b        0/s       4b/s          sql_approx_percentile_long ::  559.526 cpu ms :: in  1.5m   12.9mb    2.68m/s     23mb/s :: out     1       9b        1/s      16b/s                  stat_long_variance ::   21.974 cpu ms :: in  1.5m   12.9mb    68.3m/s    586mb/s :: out     1       9b       45/s     409b/s              stat_long_variance_pop ::   21.928 cpu ms :: in  1.5m   12.9mb    68.4m/s    587mb/s :: out     1       9b       45/s     410b/s                stat_double_variance ::   19.587 cpu ms :: in  1.5m   12.9mb    76.6m/s    657mb/s :: out     1       9b       51/s     459b/s            stat_double_variance_pop ::   19.382 cpu ms :: in  1.5m   12.9mb    77.4m/s    664mb/s :: out     1       9b       51/s     464b/s                    stat_long_stddev ::   22.252 cpu ms :: in  1.5m   12.9mb    67.4m/s    579mb/s :: out     1       9b       44/s     404b/s                stat_long_stddev_pop ::   22.540 cpu ms :: in  1.5m   12.9mb    66.5m/s    571mb/s :: out     1       9b       44/s     399b/s                  stat_double_stddev ::   19.305 cpu ms :: in  1.5m   12.9mb    77.7m/s    667mb/s :: out     1       9b       51/s     466b/s              stat_double_stddev_pop ::   19.459 cpu ms :: in  1.5m   12.9mb    77.1m/s    662mb/s :: out     1       9b       51/s     462b/s      sql_approx_count_distinct_long ::  128.087 cpu ms :: in  1.5m   12.9mb    11.7m/s    101mb/s :: out     1       9b        7/s      70b/s    sql_approx_count_distinct_double ::  134.577 cpu ms :: in  1.5m   12.9mb    11.1m/s   95.7mb/s :: out     1       9b        7/s      66b/s sql_approx_count_distinct_varbinary ::  227.544 cpu ms :: in  1.5m   21.5mb    6.59m/s   94.3mb/s :: out     1       9b        4/s      39b/s      after:                                count_agg ::    1.781 cpu ms :: in  1.5m   12.9mb     842m/s   7.06gb/s :: out     1       9b      561/s   4.93kb/s                      double_sum_agg ::   12.181 cpu ms :: in  1.5m   12.9mb     123m/s   1.03gb/s :: out     1       9b       82/s     738b/s                            hash_agg ::  141.757 cpu ms :: in  1.5m   21.5mb    10.6m/s    151mb/s :: out     3      45b       21/s     317b/s                    predicate_filter ::   58.120 cpu ms :: in  1.5m   12.9mb    25.8m/s    222mb/s :: out 1.29m   11.1mb    22.2m/s    190mb/s                          raw_stream ::    1.696 cpu ms :: in  1.5m   12.9mb     885m/s   7.41gb/s :: out  1.5m   12.9mb     885m/s   7.41gb/s                              top100 ::   45.253 cpu ms :: in  1.5m   12.9mb    33.1m/s    285mb/s :: out   100     900b    2.21k/s   19.4kb/s              in_memory_orderby_1.5m :: 1531.159 cpu ms :: in  1.5m   41.5mb     980k/s   27.1mb/s :: out  1.5m   28.6mb     980k/s   18.7mb/s                          hash_build ::  541.420 cpu ms :: in  1.5m   25.7mb    2.77m/s   47.6mb/s :: out  1.5m   25.7mb    2.77m/s   47.6mb/s                           hash_join :: 1673.213 cpu ms :: in    6m    103mb    3.59m/s   61.6mb/s :: out    6m    206mb    3.59m/s    123mb/s                 hash_build_and_join :: 2204.910 cpu ms :: in  7.5m    129mb     3.4m/s   58.4mb/s :: out    6m    206mb    2.72m/s   93.4mb/s                   hand_tpch_query_1 :: 2464.116 cpu ms :: in    6m    361mb    2.44m/s    146mb/s :: out     4     300b        1/s     121b/s                   hand_tpch_query_6 ::  293.306 cpu ms :: in    6m    240mb    20.5m/s    820mb/s :: out     1       9b        3/s      30b/s     sql_groupby_agg_with_arithmetic ::  904.943 cpu ms :: in    6m    137mb    6.63m/s    152mb/s :: out     2      30b        2/s      33b/s                       sql_count_agg ::    3.073 cpu ms :: in  1.5m   12.9mb     488m/s   4.09gb/s :: out     1       9b      325/s   2.86kb/s                  sql_double_sum_agg ::   14.070 cpu ms :: in  1.5m   12.9mb     107m/s    915mb/s :: out     1       9b       71/s     639b/s               sql_count_with_filter ::   64.687 cpu ms :: in  1.5m   8.58mb    23.2m/s    133mb/s :: out     1       9b       15/s     139b/s                     sql_groupby_agg ::  142.734 cpu ms :: in  1.5m   21.5mb    10.5m/s    150mb/s :: out     3      45b       21/s     315b/s                sql_predicate_filter ::   39.810 cpu ms :: in  1.5m   12.9mb    37.7m/s    323mb/s :: out 1.29m   11.1mb    32.4m/s    278mb/s                      sql_raw_stream ::    3.085 cpu ms :: in  1.5m   12.9mb     486m/s   4.08gb/s :: out  1.5m   12.9mb     486m/s   4.08gb/s                         sql_top_100 ::   44.824 cpu ms :: in  1.5m   12.9mb    33.5m/s    287mb/s :: out   100     900b    2.23k/s   19.6kb/s                       sql_hash_join :: 3308.330 cpu ms :: in  7.5m    129mb    2.27m/s   38.9mb/s :: out    6m    206mb    1.81m/s   62.3mb/s             sql_join_with_predicate ::  794.320 cpu ms :: in  7.5m    116mb    9.44m/s    146mb/s :: out     1       9b        1/s      11b/s                   sql_varbinary_max ::  184.251 cpu ms :: in    6m   97.3mb    32.6m/s    528mb/s :: out     1      21b        5/s     113b/s                  sql_distinct_multi ::  213.832 cpu ms :: in  1.5m     32mb    7.01m/s    150mb/s :: out     5     112b       23/s     523b/s                 sql_distinct_single ::   94.300 cpu ms :: in  1.5m   12.9mb    15.9m/s    137mb/s :: out     1       9b       10/s      95b/s                    sql_tpch_query_1 :: 2532.160 cpu ms :: in    6m    361mb    2.37m/s    142mb/s :: out     4     336b        1/s     132b/s                    sql_tpch_query_6 ::  248.466 cpu ms :: in    6m    240mb    24.2m/s    967mb/s :: out     1       9b        4/s      36b/s                            sql_like :: 2732.147 cpu ms :: in    6m    232mb     2.2m/s   84.8mb/s :: out 1.15m   9.84mb     420k/s    3.6mb/s                              sql_in ::   66.849 cpu ms :: in    6m   51.5mb    89.8m/s    771mb/s :: out    25     225b      373/s   3.29kb/s                     sql_semijoin_in :: 1675.488 cpu ms :: in  7.5m   64.4mb    4.48m/s   38.4mb/s :: out    3m   25.8mb    1.79m/s   15.4mb/s                     sql_regexp_like :: 1891.597 cpu ms :: in  1.5m   76.6mb     793k/s   40.5mb/s :: out     1       9b        0/s       4b/s          sql_approx_percentile_long ::  560.500 cpu ms :: in  1.5m   12.9mb    2.68m/s     23mb/s :: out     1       9b        1/s      16b/s                  stat_long_variance ::   24.178 cpu ms :: in  1.5m   12.9mb      62m/s    532mb/s :: out     1       9b       41/s     372b/s              stat_long_variance_pop ::   23.890 cpu ms :: in  1.5m   12.9mb    62.8m/s    539mb/s :: out     1       9b       41/s     376b/s                stat_double_variance ::   21.324 cpu ms :: in  1.5m   12.9mb    70.3m/s    604mb/s :: out     1       9b       46/s     422b/s            stat_double_variance_pop ::   21.284 cpu ms :: in  1.5m   12.9mb    70.5m/s    605mb/s :: out     1       9b       46/s     422b/s                    stat_long_stddev ::   23.768 cpu ms :: in  1.5m   12.9mb    63.1m/s    542mb/s :: out     1       9b       42/s     378b/s                stat_long_stddev_pop ::   23.717 cpu ms :: in  1.5m   12.9mb    63.2m/s    543mb/s :: out     1       9b       42/s     379b/s                  stat_double_stddev ::   21.165 cpu ms :: in  1.5m   12.9mb    70.9m/s    608mb/s :: out     1       9b       47/s     425b/s              stat_double_stddev_pop ::   21.314 cpu ms :: in  1.5m   12.9mb    70.4m/s    604mb/s :: out     1       9b       46/s     422b/s      sql_approx_count_distinct_long ::  132.816 cpu ms :: in  1.5m   12.9mb    11.3m/s   96.9mb/s :: out     1       9b        7/s      67b/s    sql_approx_count_distinct_double ::  136.426 cpu ms :: in  1.5m   12.9mb      11m/s   94.4mb/s :: out     1       9b        7/s      65b/s sql_approx_count_distinct_varbinary ::  218.193 cpu ms :: in  1.5m   21.5mb    6.87m/s   98.3mb/s :: out     1       9b        4/s      41b/s;;0;tpch plugin;add a plugin based on the airlift tpch data generator  this also converts test and benchmarks to use generated data instead of static filesfor benchmarks this code replaces tpchblocksprovider with create table commands using localqueryrunner  the means that benchmarks now use the native plugin which adds about 1-3ms to the benchmarks times  for super fast benchmarks (eg count_agg and raw_stream) this appears as a huge performance dropbefore:```                          count_agg ::    0697 cpu ms :: in  15m  129mb   215b/s    18gb/s :: out     1      9b   143k/s  126kb/s                     double_sum_agg ::   10741 cpu ms :: in  15m  129mb    140m/s  117gb/s :: out     1      9b      93/s    837b/s                           hash_agg ::  137724 cpu ms :: in  15m  215mb   109m/s   156mb/s :: out     3     45b      21/s    326b/s                   predicate_filter ::   55698 cpu ms :: in  15m  129mb   269m/s   231mb/s :: out 129m  111mb   231m/s   199mb/s                         raw_stream ::    0810 cpu ms :: in  15m  129mb   185b/s  155gb/s :: out  15m  129mb   185b/s  155gb/s                             top100 ::   41238 cpu ms :: in  15m  129mb   364m/s   312mb/s :: out   100    900b   242k/s  213kb/s             in_memory_orderby_15m :: 1521210 cpu ms :: in  15m  415mb    986k/s  273mb/s :: out  15m  286mb    986k/s  188mb/s                         hash_build ::  529348 cpu ms :: in  15m  257mb   283m/s  486mb/s :: out  15m  257mb   283m/s  486mb/s                          hash_join :: 1643575 cpu ms :: in    6m   103mb   365m/s  627mb/s :: out    6m   206mb   365m/s   125mb/s                hash_build_and_join :: 2215610 cpu ms :: in  75m   129mb   339m/s  581mb/s :: out    6m   206mb   271m/s    93mb/s                  hand_tpch_query_1 :: 2450150 cpu ms :: in    6m   361mb   245m/s   147mb/s :: out     4    300b       1/s    122b/s                  hand_tpch_query_6 ::  289359 cpu ms :: in    6m   240mb   207m/s   831mb/s :: out     1      9b       3/s     31b/s    sql_groupby_agg_with_arithmetic ::  891984 cpu ms :: in    6m   137mb   673m/s   154mb/s :: out     2     30b       2/s     33b/s                      sql_count_agg ::    1578 cpu ms :: in  15m  129mb    950m/s  797gb/s :: out     1      9b     633/s  557kb/s                 sql_double_sum_agg ::   12196 cpu ms :: in  15m  129mb    123m/s  103gb/s :: out     1      9b      81/s    737b/s              sql_count_with_filter ::   61586 cpu ms :: in  15m  858mb   244m/s   139mb/s :: out     1      9b      16/s    146b/s                    sql_groupby_agg ::  139857 cpu ms :: in  15m  215mb   107m/s   153mb/s :: out     3     45b      21/s    321b/s               sql_predicate_filter ::   37860 cpu ms :: in  15m  129mb   396m/s   340mb/s :: out 129m  111mb     34m/s   292mb/s                     sql_raw_stream ::    1508 cpu ms :: in  15m  129mb    995m/s  834gb/s :: out  15m  129mb    995m/s  834gb/s                        sql_top_100 ::   42490 cpu ms :: in  15m  129mb   353m/s   303mb/s :: out   100    900b   235k/s  207kb/s                      sql_hash_join :: 3281675 cpu ms :: in  75m   129mb   229m/s  392mb/s :: out    6m   206mb   183m/s  628mb/s            sql_join_with_predicate ::  787630 cpu ms :: in  75m   116mb   952m/s   147mb/s :: out     1      9b       1/s     11b/s                  sql_varbinary_max ::  182818 cpu ms :: in    6m  973mb   328m/s   532mb/s :: out     1     21b       5/s    114b/s                 sql_distinct_multi ::  199495 cpu ms :: in  15m    32mb   752m/s   161mb/s :: out     5    112b      25/s    561b/s                sql_distinct_single ::   93074 cpu ms :: in  15m  129mb   161m/s   138mb/s :: out     1      9b      10/s     96b/s                   sql_tpch_query_1 :: 2503541 cpu ms :: in    6m   361mb    24m/s   144mb/s :: out     4    336b       1/s    134b/s                   sql_tpch_query_6 ::  268098 cpu ms :: in    6m   240mb   224m/s   897mb/s :: out     1      9b       3/s     33b/s                           sql_like :: 2812936 cpu ms :: in    6m   232mb   213m/s  824mb/s :: out 115m  984mb    408k/s   35mb/s                             sql_in ::   67976 cpu ms :: in    6m  515mb   883m/s   758mb/s :: out    25    225b     367/s  323kb/s                    sql_semijoin_in :: 1660280 cpu ms :: in  75m  644mb   452m/s  388mb/s :: out    3m  258mb   181m/s  155mb/s                    sql_regexp_like :: 1853437 cpu ms :: in  15m  766mb    809k/s  413mb/s :: out     1      9b       0/s      4b/s         sql_approx_percentile_long ::  559526 cpu ms :: in  15m  129mb   268m/s    23mb/s :: out     1      9b       1/s     16b/s                 stat_long_variance ::   21974 cpu ms :: in  15m  129mb   683m/s   586mb/s :: out     1      9b      45/s    409b/s             stat_long_variance_pop ::   21928 cpu ms :: in  15m  129mb   684m/s   587mb/s :: out     1      9b      45/s    410b/s               stat_double_variance ::   19587 cpu ms :: in  15m  129mb   766m/s   657mb/s :: out     1      9b      51/s    459b/s           stat_double_variance_pop ::   19382 cpu ms :: in  15m  129mb   774m/s   664mb/s :: out     1      9b      51/s    464b/s                   stat_long_stddev ::   22252 cpu ms :: in  15m  129mb   674m/s   579mb/s :: out     1      9b      44/s    404b/s               stat_long_stddev_pop ::   22540 cpu ms :: in  15m  129mb   665m/s   571mb/s :: out     1      9b      44/s    399b/s                 stat_double_stddev ::   19305 cpu ms :: in  15m  129mb   777m/s   667mb/s :: out     1      9b      51/s    466b/s             stat_double_stddev_pop ::   19459 cpu ms :: in  15m  129mb   771m/s   662mb/s :: out     1      9b      51/s    462b/s     sql_approx_count_distinct_long ::  128087 cpu ms :: in  15m  129mb   117m/s   101mb/s :: out     1      9b       7/s     70b/s   sql_approx_count_distinct_double ::  134577 cpu ms :: in  15m  129mb   111m/s  957mb/s :: out     1      9b       7/s     66b/ssql_approx_count_distinct_varbinary ::  227544 cpu ms :: in  15m  215mb   659m/s  943mb/s :: out     1      9b       4/s     39b/s```after:```                          count_agg ::    1781 cpu ms :: in  15m  129mb    842m/s  706gb/s :: out     1      9b     561/s  493kb/s                     double_sum_agg ::   12181 cpu ms :: in  15m  129mb    123m/s  103gb/s :: out     1      9b      82/s    738b/s                           hash_agg ::  141757 cpu ms :: in  15m  215mb   106m/s   151mb/s :: out     3     45b      21/s    317b/s                   predicate_filter ::   58120 cpu ms :: in  15m  129mb   258m/s   222mb/s :: out 129m  111mb   222m/s   190mb/s                         raw_stream ::    1696 cpu ms :: in  15m  129mb    885m/s  741gb/s :: out  15m  129mb    885m/s  741gb/s                             top100 ::   45253 cpu ms :: in  15m  129mb   331m/s   285mb/s :: out   100    900b   221k/s  194kb/s             in_memory_orderby_15m :: 1531159 cpu ms :: in  15m  415mb    980k/s  271mb/s :: out  15m  286mb    980k/s  187mb/s                         hash_build ::  541420 cpu ms :: in  15m  257mb   277m/s  476mb/s :: out  15m  257mb   277m/s  476mb/s                          hash_join :: 1673213 cpu ms :: in    6m   103mb   359m/s  616mb/s :: out    6m   206mb   359m/s   123mb/s                hash_build_and_join :: 2204910 cpu ms :: in  75m   129mb    34m/s  584mb/s :: out    6m   206mb   272m/s  934mb/s                  hand_tpch_query_1 :: 2464116 cpu ms :: in    6m   361mb   244m/s   146mb/s :: out     4    300b       1/s    121b/s                  hand_tpch_query_6 ::  293306 cpu ms :: in    6m   240mb   205m/s   820mb/s :: out     1      9b       3/s     30b/s    sql_groupby_agg_with_arithmetic ::  904943 cpu ms :: in    6m   137mb   663m/s   152mb/s :: out     2     30b       2/s     33b/s                      sql_count_agg ::    3073 cpu ms :: in  15m  129mb    488m/s  409gb/s :: out     1      9b     325/s  286kb/s                 sql_double_sum_agg ::   14070 cpu ms :: in  15m  129mb    107m/s   915mb/s :: out     1      9b      71/s    639b/s              sql_count_with_filter ::   64687 cpu ms :: in  15m  858mb   232m/s   133mb/s :: out     1      9b      15/s    139b/s                    sql_groupby_agg ::  142734 cpu ms :: in  15m  215mb   105m/s   150mb/s :: out     3     45b      21/s    315b/s               sql_predicate_filter ::   39810 cpu ms :: in  15m  129mb   377m/s   323mb/s :: out 129m  111mb   324m/s   278mb/s                     sql_raw_stream ::    3085 cpu ms :: in  15m  129mb    486m/s  408gb/s :: out  15m  129mb    486m/s  408gb/s                        sql_top_100 ::   44824 cpu ms :: in  15m  129mb   335m/s   287mb/s :: out   100    900b   223k/s  196kb/s                      sql_hash_join :: 3308330 cpu ms :: in  75m   129mb   227m/s  389mb/s :: out    6m   206mb   181m/s  623mb/s            sql_join_with_predicate ::  794320 cpu ms :: in  75m   116mb   944m/s   146mb/s :: out     1      9b       1/s     11b/s                  sql_varbinary_max ::  184251 cpu ms :: in    6m  973mb   326m/s   528mb/s :: out     1     21b       5/s    113b/s                 sql_distinct_multi ::  213832 cpu ms :: in  15m    32mb   701m/s   150mb/s :: out     5    112b      23/s    523b/s                sql_distinct_single ::   94300 cpu ms :: in  15m  129mb   159m/s   137mb/s :: out     1      9b      10/s     95b/s                   sql_tpch_query_1 :: 2532160 cpu ms :: in    6m   361mb   237m/s   142mb/s :: out     4    336b       1/s    132b/s                   sql_tpch_query_6 ::  248466 cpu ms :: in    6m   240mb   242m/s   967mb/s :: out     1      9b       4/s     36b/s                           sql_like :: 2732147 cpu ms :: in    6m   232mb    22m/s  848mb/s :: out 115m  984mb    420k/s   36mb/s                             sql_in ::   66849 cpu ms :: in    6m  515mb   898m/s   771mb/s :: out    25    225b     373/s  329kb/s                    sql_semijoin_in :: 1675488 cpu ms :: in  75m  644mb   448m/s  384mb/s :: out    3m  258mb   179m/s  154mb/s                    sql_regexp_like :: 1891597 cpu ms :: in  15m  766mb    793k/s  405mb/s :: out     1      9b       0/s      4b/s         sql_approx_percentile_long ::  560500 cpu ms :: in  15m  129mb   268m/s    23mb/s :: out     1      9b       1/s     16b/s                 stat_long_variance ::   24178 cpu ms :: in  15m  129mb     62m/s   532mb/s :: out     1      9b      41/s    372b/s             stat_long_variance_pop ::   23890 cpu ms :: in  15m  129mb   628m/s   539mb/s :: out     1      9b      41/s    376b/s               stat_double_variance ::   21324 cpu ms :: in  15m  129mb   703m/s   604mb/s :: out     1      9b      46/s    422b/s           stat_double_variance_pop ::   21284 cpu ms :: in  15m  129mb   705m/s   605mb/s :: out     1      9b      46/s    422b/s                   stat_long_stddev ::   23768 cpu ms :: in  15m  129mb   631m/s   542mb/s :: out     1      9b      42/s    378b/s               stat_long_stddev_pop ::   23717 cpu ms :: in  15m  129mb   632m/s   543mb/s :: out     1      9b      42/s    379b/s                 stat_double_stddev ::   21165 cpu ms :: in  15m  129mb   709m/s   608mb/s :: out     1      9b      47/s    425b/s             stat_double_stddev_pop ::   21314 cpu ms :: in  15m  129mb   704m/s   604mb/s :: out     1      9b      46/s    422b/s     sql_approx_count_distinct_long ::  132816 cpu ms :: in  15m  129mb   113m/s  969mb/s :: out     1      9b       7/s     67b/s   sql_approx_count_distinct_double ::  136426 cpu ms :: in  15m  129mb     11m/s  944mb/s :: out     1      9b       7/s     65b/ssql_approx_count_distinct_varbinary ::  218193 cpu ms :: in  15m  215mb   687m/s  983mb/s :: out     1      9b       4/s     41b/s```;someone else should probably review the spi changes the rest of it looks good to me except for a couple minor comments ||;;;;1;1;convert benchmarks to use create table for data loading;
947;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add support for reading hive data from s3;;;0;add support for reading hive data from s3;;code looks fine @dain or @martint any thoughts on this general approach? || thanks for the support for reading hive data from s3 i tried this patch deployed and trying to do the following:this query works ok benchmark> select \* from table where dateint20130601 limit 10while when i try the following query benchmark> select count(*) from table where dateint20130601query 20140108_072340_00008_4yrya failed 10 nodes 301 total 0 done (000%)cpu time: 1686s total 329k rows/s 137mb/s 96% activeper node: 28 parallelism 906k rows/s 378mb/sparallelism: 2750:06 [555m rows 226gb] [906k rows/s 378mb/s]query 20140108_072340_00008_4yrya failed: nulljavalangnullpointerexception    at orgapachehadoopfsbufferedfsinputstreamgetpos(bufferedfsinputstreamjava:50)    at orgapachehadoopfsfsdatainputstreamgetpos(fsdatainputstreamjava:41)    at orgapachehadoopiosequencefile$readergetposition(sequencefilejava:2257)    at orgapachehadoopmapredsequencefilerecordreadergetprogress(sequencefilerecordreaderjava:114)    at comfacebookprestohivegenerichiverecordcursorgetcompletedbytes(generichiverecordcursorjava:194)    at comfacebookprestooperatorrecordprojectoperatorgetoutput(recordprojectoperatorjava:157)    at comfacebookprestooperatortablescanoperatorgetoutput(tablescanoperatorjava:201)    at comfacebookprestooperatordriverprocess(driverjava:214)    at comfacebookprestooperatordriverprocessfor(driverjava:243)    at comfacebookprestoexecutionsqltaskexecution$driversplitrunnerprocessfor(sqltaskexecutionjava:636)    at comfacebookprestoexecutiontaskexecutor$prioritizedsplitrunnerprocess(taskexecutorjava:436)    at comfacebookprestoexecutiontaskexecutor$runnerrun(taskexecutorjava:570)    at javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145)    at javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615)    at javalangthreadrun(threadjava:744)at the worker node i found the following in serverlog:2014-01-08t07 36075+0000    error   splitrunner-12-93       comfacebookprestoexecutiontaskexecutor      error processing split 20140108_071330_00006_ibafm19-0 (start  1389165210832 wall  5236 ms cpu  4044 ms calls  4)javalangnullpointerexception: null        at orgapachehadoopfsbufferedfsinputstreamgetpos(bufferedfsinputstreamjava:50) ~[na:na]        at orgapachehadoopfsfsdatainputstreamgetpos(fsdatainputstreamjava:41) ~[na:na]        at orgapachehadoopiosequencefile$readergetposition(sequencefilejava:2257) ~[na:na]        at orgapachehadoopmapredsequencefilerecordreadergetprogress(sequencefilerecordreaderjava:114) ~[na:na]        at comfacebookprestohivegenerichiverecordcursorgetcompletedbytes(generichiverecordcursorjava:194) ~[na:na]        at comfacebookprestooperatorrecordprojectoperatorgetoutput(recordprojectoperatorjava:157) ~[presto-main-057-snapshotjar:057-snapshot]        at comfacebookprestooperatortablescanoperatorgetoutput(tablescanoperatorjava:201) ~[presto-main-057-snapshotjar:057-snapshot]        at comfacebookprestooperatordriverprocess(driverjava:214) ~[presto-main-057-snapshotjar:057-snapshot]        at comfacebookprestooperatordriverprocessfor(driverjava:243) ~[presto-main-057-snapshotjar:057-snapshot]        at comfacebookprestoexecutionsqltaskexecution$driversplitrunnerprocessfor(sqltaskexecutionjava:636) ~[presto-main-057-snapshotjar:057-snapshot]        at comfacebookprestoexecutiontaskexecutor$prioritizedsplitrunnerprocess(taskexecutorjava:436) ~[presto-main-057-snapshotjar:057-snapshot]        at comfacebookprestoexecutiontaskexecutor$runnerrun(taskexecutorjava:570) ~[presto-main-057-snapshotjar:057-snapshot]        at javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145) [na:170_45]        at javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615) [na:170_45]        at javalangthreadrun(threadjava:744) [na:170_45]is it a bug? || im not sure i like the idea of coding the aws credentials into the hiveclientconfig but i cant think of a better way to do this in the current plugin system  in the case of aws the user base is so large this seems reasonable for now but we should think about this more over time  || @zhenxiao im looking through the hadoop code and trying to determine how this error occurs it seems that the only way for an npe to happen in `bufferedfsinputstreamgetpos()` is if `in` is null and that can only occur if `bufferedinputstreamclose()` was called previouslycan you reproduce this by running presto in your ide? if so maybe you can use the debugger to figure out how this happens?also the stack trace indicates you are using `sequencefile` (which is probably the slowest format we support) does this error occur with other file formats? we recommend `rcfile` with `lazybinarycolumnarserde` || @electrum thanks sure i am looking into it || is the s3 support part of a public release yet? ||;;;;1;1;add support for reading hive data from s3;
950;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;fix nullpointerexception when reading from s3;when presto reading from s3  get the following nullpointerexception:  presto:benchmark> select dateint  hour  hostname  count(*) as cnt from streaming_client_log where dateint=20130701 group by dateint  hour  hostname order by cnt   query 20140109_060239_00014_ddzak  failed  8 nodes  splits: 10 total  8 done (80.00%) cpu time: 0.0s total      0 rows/s      0b/s  50% active per node: 0.0 parallelism      0 rows/s      0b/s parallelism: 0.0 0:01 [0 rows  0b] [0 rows/s  0b/s]  query 20140109_060239_00014_ddzak failed: null java.lang.nullpointerexception     at org.apache.hadoop.fs.bufferedfsinputstream.getpos(bufferedfsinputstream.java:50)     at org.apache.hadoop.fs.fsdatainputstream.getpos(fsdatainputstream.java:41)     at org.apache.hadoop.io.sequencefile$reader.getposition(sequencefile.java:2257)     at org.apache.hadoop.mapred.sequencefilerecordreader.getprogress(sequencefilerecordreader.java:114)     at com.facebook.presto.hive.generichiverecordcursor.getcompletedbytes(generichiverecordcursor.java:194)     at com.facebook.presto.operator.recordprojectoperator.getoutput(recordprojectoperator.java:157)     at com.facebook.presto.operator.tablescanoperator.getoutput(tablescanoperator.java:201)     at com.facebook.presto.operator.driver.process(driver.java:214)     at com.facebook.presto.operator.driver.processfor(driver.java:243)     at com.facebook.presto.execution.sqltaskexecution$driversplitrunner.processfor(sqltaskexecution.java:636)     at com.facebook.presto.execution.taskexecutor$prioritizedsplitrunner.process(taskexecutor.java:436)     at com.facebook.presto.execution.taskexecutor$runner.run(taskexecutor.java:570)     at java.util.concurrent.threadpoolexecutor.runworker(threadpoolexecutor.java:1145)     at java.util.concurrent.threadpoolexecutor$worker.run(threadpoolexecutor.java:615)     at java.lang.thread.run(thread.java:744)  this root reason is  in recordprojectoperator.getoutput()  advancenextposition() will close the cursor when reaching the end of file  the following cursor.getcompletedbytes() will get nullpointerexception  since cursor is already closed.  this patch fixes the bug.;;0;fix nullpointerexception when reading from s3;when presto reading from s3 get the following nullpointerexception benchmark> select dateint hour hostname count(*) as cnt from streaming_client_log where dateint20130701 group by dateint hour hostname order by cntquery 20140109_060239_00014_ddzak failed 8 nodes 10 total 8 done (8000%)cpu time: 00s total     0 rows/s     0b/s 50% activeper node: 00 parallelism     0 rows/s     0b/sparallelism: 000:01 [0 rows 0b] [0 rows/s 0b/s]query 20140109_060239_00014_ddzak failed: nulljavalangnullpointerexception    at orgapachehadoopfsbufferedfsinputstreamgetpos(bufferedfsinputstreamjava:50)    at orgapachehadoopfsfsdatainputstreamgetpos(fsdatainputstreamjava:41)    at orgapachehadoopiosequencefile$readergetposition(sequencefilejava:2257)    at orgapachehadoopmapredsequencefilerecordreadergetprogress(sequencefilerecordreaderjava:114)    at comfacebookprestohivegenerichiverecordcursorgetcompletedbytes(generichiverecordcursorjava:194)    at comfacebookprestooperatorrecordprojectoperatorgetoutput(recordprojectoperatorjava:157)    at comfacebookprestooperatortablescanoperatorgetoutput(tablescanoperatorjava:201)    at comfacebookprestooperatordriverprocess(driverjava:214)    at comfacebookprestooperatordriverprocessfor(driverjava:243)    at comfacebookprestoexecutionsqltaskexecution$driversplitrunnerprocessfor(sqltaskexecutionjava:636)    at comfacebookprestoexecutiontaskexecutor$prioritizedsplitrunnerprocess(taskexecutorjava:436)    at comfacebookprestoexecutiontaskexecutor$runnerrun(taskexecutorjava:570)    at javautilconcurrentthreadpoolexecutorrunworker(threadpoolexecutorjava:1145)    at javautilconcurrentthreadpoolexecutor$workerrun(threadpoolexecutorjava:615)    at javalangthreadrun(threadjava:744)this root reason is in recordprojectoperatorgetoutput() advancenextposition() will close the cursor when reaching the end of file the following cursorgetcompletedbytes() will get nullpointerexception since cursor is already closedthis patch fixes the bug;very nice thanks for tracking this down! || this fixes the bug though it means we dont record the stats for the last batch of rows i think it would be better to have `generichiverecordcursor` save the final completed byte count in its `close()` method so that `getcompletedbytes()` can be called after it is closed || @electrum thanks i get the patch updated || @electrum thanks comments addressed in the new diff || thanks pushed! this change is small enough that it shouldnt matter but would you mind signing the cla? it will save time for future contributions  || thanks @electrum i just singed the cla more than happy to do more contributions ||;;;;1;1;fix nullpointerexception when reading from s3;
951;1;0;1;1;1;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add support for connectors with sampled data;;;0;add support for connectors with sampled data;;ok ive finished support for aggregation queries and thats ready for review || planning some major changes to this after discussing with eric || ok hopefully weve settled on the final design if this looks good to everyone ill start on an optimizer to pull the decompression up through the plan so that its done as late as possible || im done for now but @martint or @erichwang should review the planner changes || i ran the benchmarks and everything looks like its within the margin of errorbefore:```                          count_agg ::    2068 cpu ms :: in  15m  129mb    725m/s  608gb/s :: out     1      9b     483/s  425kb/s                     double_sum_agg ::   11996 cpu ms :: in  15m  129mb    125m/s  105gb/s :: out     1      9b      83/s    750b/s                           hash_agg ::  136079 cpu ms :: in  15m  215mb     11m/s   158mb/s :: out     3     45b      22/s    330b/s                   predicate_filter ::   57581 cpu ms :: in  15m  129mb   261m/s   224mb/s :: out 129m  111mb   224m/s   192mb/s                         raw_stream ::    2007 cpu ms :: in  15m  129mb    747m/s  626gb/s :: out  15m  129mb    747m/s  626gb/s                             top100 ::   44139 cpu ms :: in  15m  129mb     34m/s   292mb/s :: out   100    900b   227k/s  199kb/s             in_memory_orderby_15m :: 1738121 cpu ms :: in  15m  415mb    863k/s  239mb/s :: out  15m  286mb    863k/s  165mb/s                         hash_build ::  487388 cpu ms :: in  15m  257mb   308m/s  528mb/s :: out  15m  257mb   308m/s  528mb/s                          hash_join :: 1655461 cpu ms :: in    6m   103mb   363m/s  622mb/s :: out    6m   206mb   363m/s   124mb/s                hash_build_and_join :: 2137342 cpu ms :: in  75m   129mb   351m/s  602mb/s :: out    6m   206mb   281m/s  964mb/s                  hand_tpch_query_1 :: 2394402 cpu ms :: in    6m   361mb   251m/s   151mb/s :: out     4    300b       1/s    125b/s                  hand_tpch_query_6 ::  285625 cpu ms :: in    6m   240mb     21m/s   842mb/s :: out     1      9b       3/s     31b/s    sql_groupby_agg_with_arithmetic ::  875608 cpu ms :: in    6m   137mb   685m/s   157mb/s :: out     2     30b       2/s     34b/s                      sql_count_agg ::    3588 cpu ms :: in  15m  129mb    418m/s   35gb/s :: out     1      9b     278/s  245kb/s                 sql_double_sum_agg ::   13911 cpu ms :: in  15m  129mb    108m/s   926mb/s :: out     1      9b      71/s    646b/s              sql_count_with_filter ::   60796 cpu ms :: in  15m  858mb   247m/s   141mb/s :: out     1      9b      16/s    148b/s                    sql_groupby_agg ::  135916 cpu ms :: in  15m  215mb     11m/s   158mb/s :: out     3     45b      22/s    331b/s               sql_predicate_filter ::   38066 cpu ms :: in  15m  129mb   394m/s   338mb/s :: out 129m  111mb   339m/s   291mb/s                     sql_raw_stream ::    3498 cpu ms :: in  15m  129mb    429m/s  359gb/s :: out  15m  129mb    429m/s  359gb/s                        sql_top_100 ::   46006 cpu ms :: in  15m  129mb   326m/s   280mb/s :: out   100    900b   217k/s  191kb/s                      sql_hash_join :: 3243355 cpu ms :: in  75m   129mb   231m/s  397mb/s :: out    6m   206mb   185m/s  635mb/s            sql_join_with_predicate ::  786535 cpu ms :: in  75m   116mb   954m/s   147mb/s :: out     1      9b       1/s     11b/s                  sql_varbinary_max ::  180388 cpu ms :: in    6m  973mb   333m/s   539mb/s :: out     1     21b       5/s    116b/s                 sql_distinct_multi ::  211105 cpu ms :: in  15m    32mb   711m/s   152mb/s :: out     5    112b      23/s    530b/s                sql_distinct_single ::   89806 cpu ms :: in  15m  129mb   167m/s   143mb/s :: out     1      9b      11/s    100b/s                   sql_tpch_query_1 :: 2439468 cpu ms :: in    6m   361mb   246m/s   148mb/s :: out     4    336b       1/s    137b/s                   sql_tpch_query_6 ::  243682 cpu ms :: in    6m   240mb   246m/s   986mb/s :: out     1      9b       4/s     36b/s                           sql_like :: 2782665 cpu ms :: in    6m   232mb   216m/s  833mb/s :: out 115m  984mb    412k/s  354mb/s                             sql_in ::   59077 cpu ms :: in    6m  515mb    102m/s   872mb/s :: out    25    225b     423/s  372kb/s                    sql_semijoin_in :: 1740353 cpu ms :: in  75m  644mb   431m/s    37mb/s :: out    3m  258mb   172m/s  148mb/s                    sql_regexp_like :: 1872116 cpu ms :: in  15m  766mb    801k/s  409mb/s :: out     1      9b       0/s      4b/s         sql_approx_percentile_long ::  603892 cpu ms :: in  15m  129mb   248m/s  213mb/s :: out     1      9b       1/s     14b/s                 stat_long_variance ::   23740 cpu ms :: in  15m  129mb   632m/s   542mb/s :: out     1      9b      42/s    379b/s             stat_long_variance_pop ::   23642 cpu ms :: in  15m  129mb   634m/s   545mb/s :: out     1      9b      42/s    380b/s               stat_double_variance ::   20128 cpu ms :: in  15m  129mb   745m/s   640mb/s :: out     1      9b      49/s    447b/s           stat_double_variance_pop ::   19959 cpu ms :: in  15m  129mb   752m/s   645mb/s :: out     1      9b      50/s    450b/s                   stat_long_stddev ::   23699 cpu ms :: in  15m  129mb   633m/s   543mb/s :: out     1      9b      42/s    379b/s               stat_long_stddev_pop ::   24376 cpu ms :: in  15m  129mb   615m/s   528mb/s :: out     1      9b      41/s    369b/s                 stat_double_stddev ::   19970 cpu ms :: in  15m  129mb   751m/s   645mb/s :: out     1      9b      50/s    450b/s             stat_double_stddev_pop ::   20010 cpu ms :: in  15m  129mb     75m/s   643mb/s :: out     1      9b      49/s    449b/s     sql_approx_count_distinct_long ::  126555 cpu ms :: in  15m  129mb   119m/s   102mb/s :: out     1      9b       7/s     71b/s   sql_approx_count_distinct_double ::  131460 cpu ms :: in  15m  129mb   114m/s  979mb/s :: out     1      9b       7/s     68b/ssql_approx_count_distinct_varbinary ::  211182 cpu ms :: in  15m  215mb    71m/s   102mb/s :: out     1      9b       4/s     42b/s```after:```                          count_agg ::    2003 cpu ms :: in  15m  129mb    749m/s  628gb/s :: out     1      9b     499/s  439kb/s                     double_sum_agg ::   12419 cpu ms :: in  15m  129mb    121m/s  101gb/s :: out     1      9b      80/s    724b/s                           hash_agg ::  134266 cpu ms :: in  15m  215mb   112m/s   160mb/s :: out     3     45b      22/s    335b/s                   predicate_filter ::   57368 cpu ms :: in  15m  129mb   261m/s   224mb/s :: out 129m  111mb   225m/s   193mb/s                         raw_stream ::    1973 cpu ms :: in  15m  129mb    760m/s  637gb/s :: out  15m  129mb    760m/s  637gb/s                             top100 ::   45235 cpu ms :: in  15m  129mb   332m/s   285mb/s :: out   100    900b   221k/s  194kb/s             in_memory_orderby_15m :: 1767711 cpu ms :: in  15m  415mb    849k/s  235mb/s :: out  15m  286mb    849k/s  162mb/s                         hash_build ::  485009 cpu ms :: in  15m  257mb   309m/s  531mb/s :: out  15m  257mb   309m/s  531mb/s                          hash_join :: 1639296 cpu ms :: in    6m   103mb   366m/s  628mb/s :: out    6m   206mb   366m/s   126mb/s                hash_build_and_join :: 2137782 cpu ms :: in  75m   129mb   351m/s  602mb/s :: out    6m   206mb   281m/s  964mb/s                  hand_tpch_query_1 :: 2407029 cpu ms :: in    6m   361mb   249m/s   150mb/s :: out     4    300b       1/s    124b/s                  hand_tpch_query_6 ::  285025 cpu ms :: in    6m   240mb   211m/s   843mb/s :: out     1      9b       3/s     31b/s    sql_groupby_agg_with_arithmetic ::  889896 cpu ms :: in    6m   137mb   674m/s   154mb/s :: out     2     30b       2/s     33b/s                      sql_count_agg ::    3698 cpu ms :: in  15m  129mb    406m/s   34gb/s :: out     1      9b     270/s  238kb/s                 sql_double_sum_agg ::   13955 cpu ms :: in  15m  129mb    107m/s   923mb/s :: out     1      9b      71/s    644b/s              sql_count_with_filter ::   60747 cpu ms :: in  15m  858mb   247m/s   141mb/s :: out     1      9b      16/s    148b/s                    sql_groupby_agg ::  134597 cpu ms :: in  15m  215mb   111m/s   159mb/s :: out     3     45b      22/s    334b/s               sql_predicate_filter ::   38041 cpu ms :: in  15m  129mb   394m/s   338mb/s :: out 129m  111mb   339m/s   291mb/s                     sql_raw_stream ::    3531 cpu ms :: in  15m  129mb    425m/s  356gb/s :: out  15m  129mb    425m/s  356gb/s                        sql_top_100 ::   46920 cpu ms :: in  15m  129mb     32m/s   274mb/s :: out   100    900b   213k/s  187kb/s                      sql_hash_join :: 3251799 cpu ms :: in  75m   129mb   231m/s  396mb/s :: out    6m   206mb   185m/s  634mb/s            sql_join_with_predicate ::  797253 cpu ms :: in  75m   116mb   941m/s   145mb/s :: out     1      9b       1/s     11b/s                  sql_varbinary_max ::  181134 cpu ms :: in    6m  973mb   331m/s   537mb/s :: out     1     21b       5/s    115b/s                 sql_distinct_multi ::  207403 cpu ms :: in  15m    32mb   723m/s   154mb/s :: out     5    112b      24/s    540b/s                sql_distinct_single ::   89521 cpu ms :: in  15m  129mb   168m/s   144mb/s :: out     1      9b      11/s    100b/s                   sql_tpch_query_1 :: 2504990 cpu ms :: in    6m   361mb    24m/s   144mb/s :: out     4    336b       1/s    134b/s                   sql_tpch_query_6 ::  244862 cpu ms :: in    6m   240mb   245m/s   982mb/s :: out     1      9b       4/s     36b/s                           sql_like :: 2757497 cpu ms :: in    6m   232mb   218m/s    84mb/s :: out 115m  984mb    416k/s  357mb/s                             sql_in ::   59185 cpu ms :: in    6m  515mb    101m/s   870mb/s :: out    25    225b     422/s  371kb/s                    sql_semijoin_in :: 1723921 cpu ms :: in  75m  644mb   435m/s  373mb/s :: out    3m  258mb   174m/s  149mb/s                    sql_regexp_like :: 1870424 cpu ms :: in  15m  766mb    802k/s  409mb/s :: out     1      9b       0/s      4b/s         sql_approx_percentile_long ::  597518 cpu ms :: in  15m  129mb   251m/s  215mb/s :: out     1      9b       1/s     15b/ssampled_sql_groupby_agg_with_arithmetic :: 1038829 cpu ms :: in    6m   189mb   578m/s   182mb/s :: out     2     30b       1/s     28b/s              sampled_sql_count_agg ::    9274 cpu ms :: in  15m  129mb    162m/s  136gb/s :: out     1      9b     107/s    970b/s    sampled_sql_join_with_predicate :: 1007711 cpu ms :: in  75m   180mb   744m/s   179mb/s :: out     1      9b       0/s      8b/s         sampled_sql_double_sum_agg ::   20150 cpu ms :: in  15m  257mb   744m/s  125gb/s :: out     1      9b      49/s    446b/s                 stat_long_variance ::   19950 cpu ms :: in  15m  129mb   752m/s   645mb/s :: out     1      9b      50/s    451b/s             stat_long_variance_pop ::   19983 cpu ms :: in  15m  129mb   751m/s   644mb/s :: out     1      9b      50/s    450b/s               stat_double_variance ::   20141 cpu ms :: in  15m  129mb   745m/s   639mb/s :: out     1      9b      49/s    446b/s           stat_double_variance_pop ::   20050 cpu ms :: in  15m  129mb   748m/s   642mb/s :: out     1      9b      49/s    448b/s                   stat_long_stddev ::   19958 cpu ms :: in  15m  129mb   752m/s   645mb/s :: out     1      9b      50/s    450b/s               stat_long_stddev_pop ::   19830 cpu ms :: in  15m  129mb   756m/s   649mb/s :: out     1      9b      50/s    453b/s                 stat_double_stddev ::   19966 cpu ms :: in  15m  129mb   751m/s   645mb/s :: out     1      9b      50/s    450b/s             stat_double_stddev_pop ::   20062 cpu ms :: in  15m  129mb   748m/s   642mb/s :: out     1      9b      49/s    448b/s     sql_approx_count_distinct_long ::  123309 cpu ms :: in  15m  129mb   122m/s   104mb/s :: out     1      9b       8/s     72b/s   sql_approx_count_distinct_double ::  131018 cpu ms :: in  15m  129mb   114m/s  983mb/s :: out     1      9b       7/s     68b/ssql_approx_count_distinct_varbinary ::  209859 cpu ms :: in  15m  215mb   715m/s   102mb/s :: out     1      9b       4/s     42b/s``` || also since this is a fairly significant change a cool thing to do would be to see if we can have all of our unit tests run with rle encoded tables for example if we had some mechanism where if we did an assertquery and it would run the test query against a normal table and an rle encoded table (maybe defaulting with rle of length 1) or something just an idea || the last two commits look good to me but eric should review the planner changes || after fixing those last comments ;;;;1;1;run all abstracttestqueries over sampled data with a weight of 1;
952;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;fix use of closed recordreader;;;0;fix use of closed recordreader;;;;;;1;1;fix use of closed recordreader;
"953;1;0;0;0;1;1;0;0;0;0;1;1;0;1;0;0;1;0;0;0;0;0;0;0;0;1;0;cassandra plugin;this pull request contain an updated version of martin weindel s cassandra plugin for presto.  the changes include the following:  updated the code to the presto coding style. (  split cassandraclient into separate services.  this is how the other connectors are designed  and hive is only this way for legacy reasons.  remove the classloader wrappers because cassandra client does not seem to load class dynamically (like hive does).  we can add this back if we find out the client is loading classes.  added some initial tests that start an embedded cassandra server.  we need much more extensive tests  but i think this is a good starting point.;;0;cassandra plugin;this pull request contain an updated version of martin weindels cassandra plugin for presto  the changes include the following:updated the code to the presto coding style ( cassandraclient into separate services  this is how the other connectors are designed and hive is only this way for legacy reasonsremove the classloader wrappers because cassandra client does not seem to load class dynamically (like hive does)  we can add this back if we find out the client is loading classesadded some initial tests that start an embedded cassandra server  we need much more extensive tests but i think this is a good starting point;""on reviewing the changes to my original code i have found three minor issues:1 in `cassandraclientconfig` the default value for cassandranative-protocol-port is set to `9142` this should changed to `9042` as this is the correct default port used by cassandra there seems to be a red hat installation package which uses `9142` (see  but all installation packages from the apache cassandra project and also from datastax use `9042` as far as i know   if you take a look into the jdbc driver code it has also `9042` by default2 `cassandrarecordcursorgetlong(int)` now returns a value for the varint type this can lead to wrong results if the value is outside the 64bit integer range according to javadoc of bitinteger which backs the varint type: """"if this biginteger is too big to fit in a long only the low-order 64 bits are returned"""" if we want to allow this conversion a range check should be performed before returning the value3 `rowutil` class in the package `comdatastaxdrivercore` we should not pollute the jdbc driver package it would be better to move this class to the package `comfacebookprestocassandrautil` for `testhost` this is not possible as the constructor of the super class is package privatethanks again for your cleanup work || thanks!1 ill change it to 90422 should i make it `double` for now or just remove the mapping?  if i remove it people wont be able to access varint data  in general i think we should hide any column with an unsupported type3  iirc i had to put `rowutil` in that package because the `row` constructor is package protected (which sucks)let me know what you think about 2  then ill make the changes and push this  id also appreciate it if you can look at adding tests for super columns and more types (with nulls) || my solution was to map `varint` to `string` then its up to the user to decide what to do with itand yes i will work on adding more tests after we have a common starting point || thanks for the great contribution! || "";;;;1;1;remove thread context classloader logic from cassandra plugin;"
956;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;refactor localexecutionplanner;replace multimap with map  now that all our channels contain only a single symbol;;0;refactor localexecutionplanner;replace multimap with map now that all our channels contain only asingle symbol;;;;;1;1;refactor localexecutionplannerreplace multimap with map now that all our channels contain only asingle symbol;
957;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add unit test for distinct aggregation on a join;;;0;add unit test for distinct aggregation on a join;;;;;;1;1;add unit test for distinct aggregation on a join;
965;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix warnings in unit tests  and reformat some files;;;0;fix warnings in unit tests and reformat some files;;this has some overlap with  || ;;;;1;1;fix warnings in hive file format tests;
"971;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;0;explain (format json  type source);;;0;explain (format json type source);;""what does type """"source"""" mean? || heh we had some discussion on names and """"source"""" was the best we could come up with a """"source plan"""" explains the sources (inputs) for a query it seemed better than """"inputs"""" its not very good -- please help us find a better name || i dont think we should have a special """"source"""" type id rather a single type that returns one """"explanation"""" that includes the actual plan a description of the sources etc || also source is confusing since we already use that term to indicate which tool/app/client submitted the query i do think """"inputs"""" is a better name we use it in the querycompletionevent to represent exactly this concept || ok so my proposal is to just add syntax for:```explain (format json)```initially the output will just contain information about the inputs to the query eventually well add additional information such as ast + semantic annotations (needed for syntax highlighting and auto-complete) plan structure output columns/types etc || all of these should use the guava `objectsequal()` and `objectshashcode()` || you should rebase on top of  || title the commit something like """"add json version of explain"""" || @electrum : squashed the commits and addressed recent comments || title the commit something like """"add json format for explain"""" || @electrum: updated thanks  ||  "";;;;1;1;add json format for explain- currently only inputs (input tables) is included;"
"983;1;0;0;1;0;1;0;0;0;1;1;1;0;0;0;0;1;0;1;0;0;1;1;1;0;1;0;add new s3 filesystem using aws sdk;this is a new proof-of-concept s3 filesystem implementation that uses the aws sdk. it passes the basic unit tests but has not been tested otherwise.;;0;add new s3 filesystem using aws sdk;this is a new proof-of-concept s3 filesystem implementation that uses the aws sdk it passes the basic unit tests but has not been tested otherwise;""hi davidthis is great for presto working on s3 relieved the packaging worki tried this on a 11 node cluster it is running ok just have a few questions:#1 still could not figure out a way to disable logging extensive logging made prestos performance on s3 not so good compared with reading from hdfs here is my etc/logproperties:comfacebookprestodebugorgapachehadoopwarnorgapache still i get tens of:2014-01-30t22 03945+0000     info   20140130_221259_00004_56i9816-0-81    stdout  22 03945 [20140130_221259_00004_56i9816-0-81] debug orgapache - << """"[0xbd][0x14]5[0xe2]b[0xe6][0xf3][0xc9][0x9]s[0xbc][0x9a][0xd9][0xb6][0xa4]y9[0xc9][0x7][0xdf][0xe9][0x13][0xc7][0xfd][0xa2][0x13][0x88][0xfe][0xfa][0xbf]z[0x9][0xea][0xcc][0x7][0xd3][0x96][0x11][0xd0][0xa6]a7[0x1d]q[0xac][0xb5]`[0x83][0x2][0x84])h[0xca]rq[0xde][0xa9]3[0xa0]yo[\n]""""2014-01-30t22 03946+0000     info   20140130_221259_00004_56i9816-0-81    stdout  22 03946 [20140130_221259_00004_56i9816-0-81] debug orgapache - << """"[0xa4][0xda][0x18][0x95]gb[0xbd]2[0xc0][0xe4]t[0xc7][0xc8][0xc9][0x6]][0xc3][0x1c]1:[0x9b]:[0x9f]w`[0xaf]k[0x9d]cp[0x2][0xb4][\r][0x8c]?)[0xf5]<[0x1b][0xcb][0xa8]u[0x1a]+i[0xbb][0xf]:which not only made presto running slow but also consumed lots of disk space do you have any hints about how to disable the log(as how presto is running on hdfs)?#2 the  deadlock problem is still there i found a way to get it  will post my patch following this onethis is really great work to start trying presto on s3 i tried some experiments(not using this patch but using emrs hadoop jars) and it showed that presto on s3 could be as fast as presto on hdfs i think we should put all s3 related work in this packaging structure and make its performance as fast as using emrs hadoopthankszhenxiao || this seem like a reasonable start   updated to address review comments will push after release || "";;;;1;1;add new s3 filesystem using aws sdk;"
985;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hang in hive split source;correctly decrement the outstandingsplitcount in getnextbatch;;0;fix hang in hive split source;correctly decrement the outstandingsplitcount in getnextbatch;looks good otherwise ||;;;;1;1;fix hang in hive split sourcecorrectly decrement the outstandingsplitcount in getnextbatch;
"987;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;serdeutils;rewrite of hive serdeutils.getjsonstring() using jackson.;;0;serdeutils;rewrite of hive serdeutilsgetjsonstring() using jackson;""other than switching the tests back to `string`  also squash the changes before pushing || this needs a more descriptive commit message than simply """"serdeutils"""" || addressed review comments @electrum : i will squash the commits and update the commit message before i push  || @dain : addressed all comments by you  squashed to one commit pushing it now  || "";;;;1;1;rewrite of hive serdeutilsgetjsonstring() using jackson;"
988;1;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix memory (estimate) leak in topnoperator;;;0;fix memory (estimate) leak in topnoperator;;;;;;1;1;fix memory (estimate) leak in topnoperator;
998;1;0;0;1;1;0;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add ordering and pattern matching to databasemetadata;;;0;add ordering and pattern matching to databasemetadata;;;;;;1;1;use like in databasemetadata for pattern arguments;
1000;1;0;1;1;1;1;1;0;0;0;1;1;1;1;0;0;1;0;1;0;0;0;1;1;0;1;0;improve encapsulation of native connector interfaces;- inject nativemetadata into nativeconnectorfactory  just like datastreamprovider et al. - make nativesplitmanager depend on the connector-specific nativemetadata instead of global metadata;;0;improve encapsulation of native connector interfaces;- inject nativemetadata into nativeconnectorfactory just like datastreamprovider et al- make nativesplitmanager depend on the connector-specific nativemetadata instead of global metadata;;;;;1;1;improve encapsulation of native connector interfaces- inject nativemetadata into nativeconnectorfactory just like datastreamprovider et al- make nativesplitmanager depend on the connector-specific nativemetadata instead of global metadata;
1001;1;0;0;0;1;0;0;0;1;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;predicate optimization improvements;- between ranges - simplified effective predicates from partitions;;0;predicate optimization improvements;- between ranges- simplified effective predicates from partitions;;;;;1;1;simplify the effective predicate from table scan partitions;
1003;1;0;0;1;1;1;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;1;0;1;0;fix state machine and info objects;;;0;fix state machine and info objects;;;;;;1;1;deep copy taskinfo outputs in constructor to avoid concurrentmodificationexception;
"1004;1;0;0;1;1;1;0;0;1;1;1;1;0;1;0;0;1;0;1;0;1;1;0;1;0;1;0;replace generic  getservice  method in connector with explicit methods;;;0;""replace generic """"getservice"""" method in connector with explicit methods"";;;;;;1;1;""replace generic """"getservice"""" method in connector with explicit methods"";"
1005;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;synchronize before copying the output items;;;0;synchronize before copying the output items;;;;;;1;1;when driver creation fails properly fire failed event;
1006;1;0;0;0;1;0;0;0;0;1;1;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fully stop tasks;;;0;fully stop tasks;;;;;;1;1;add close to exchangeoperator to assure exchangeclient is closed;
1007;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix overflow bug in hashpagepartitionfunction;;;0;fix overflow bug in hashpagepartitionfunction;;;;;;1;1;fix overflow bug in hashpagepartitionfunction;
"1008;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;1;1;1;1;1;0;1;1;add experimental support for approximate queries;note  most of these are from my sample weight pr. the one that needs review is  experimental support for approximate queries;;0;add experimental support for approximate queries;""note most of these are from my sample weight pr the one that needs review is """"experimental support for approximate queries"""""";;;;;1;1;experimental support for approximate queriescurrently only avg is supported the syntax is:select avg(a)from my_sampled_tableapproximate at 950 confidencethis is disabled by default but can be enabled with the config option analyzerapproximate-queries-enabledtrue;"
1009;1;0;0;1;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;do not close output buffers on failure;;;0;do not close output buffers on failure;;;;;;1;1;do not close output buffers on failure;
1014;1;0;0;1;1;1;1;0;0;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;distribute splits evenly among nodes;;;0;distribute splits evenly among nodes;;other then fixing the test this ;;;;1;1;distribute splits evenly among nodes;
1016;1;0;0;0;1;0;0;0;0;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add checkstyle rule for colon in foreach loops;;;0;add checkstyle rule for colon in foreach loops;;;;;;1;1;add checkstyle rule for colon in foreach loops;
1017;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;refactor sampled test queries into a separate abstract class;;;0;refactor sampled test queries into a separate abstract class;;;;;;1;1;refactor sampled test queries into a separate abstract class;
1018;1;0;0;0;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;1;fix localexecutionplanner handling of null literal projections;disable compiler tests involving untyped nulls;;0;fix localexecutionplanner handling of null literal projections;disable compiler tests involving untyped nulls;;;;;1;1;fix localexecutionplanner handling of null literal projectionsdisable compiler tests involving untyped nulls and mixed numeric types;
1029;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;0;1;1;0;1;0;remove materialized view and alias support;;;0;remove materialized view and alias support;;;;;;1;1;remove aliased table support;
1030;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;allow optimization of subexpressions in certain cases;;;0;allow optimization of subexpressions in certain cases;;;;;;1;1;allow optimization of subexpressions in certain cases;
1032;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix information schema predicate extraction;;;0;fix information schema predicate extraction;;;;;;1;1;fix information schema predicate extraction;
1034;1;0;0;1;1;0;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix jdbc tests;;;0;fix jdbc tests;;;;;;1;1;configure logging for tests;
1036;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;add poissonized sampling;;;0;add poissonized sampling;;@martint can you give this a once over? || ok i addressed all of @dain s comments || other than those minor comments it ;;;;1;1;add support for rescaled poissonized sampling;
1037;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;fix scheduling bug where drivers queued in taskexecutor are not counted;create drivercontext when split is added instead of waiting until a thread is associated with the split.;;0;fix scheduling bug where drivers queued in taskexecutor are not counted;create drivercontext when split is added instead of waiting until a thread is associated with the split;;;;;1;1;fix scheduling bug where drivers queued in taskexecutor are not countedcreate drivercontext when split is added instead of waiting until a thread is associated with the split;
1040;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;check for no tpch nodes when generating splits;;;0;check for no tpch nodes when generating splits;;;;;;1;1;check for no tpch nodes when generating splits;
1042;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add support for sampled tables to hive connector;;;0;add support for sampled tables to hive connector;;addressed @dain s comments @electrum can you take a look? || ;;;;1;1;add support for sampled tables to hive connector;
1046;1;0;0;1;0;1;0;0;0;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;add tracking of failures for metastore api calls;;;0;add tracking of failures for metastore api calls;;;;;;1;1;add tracking of failures for metastore api calls;
"1050;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;1;implement values;;;0;implement values;;"" we should be able to prune the columns for queries like:``` sqlselect count(*) from (values (11 2) (sin(33) 2+2)) x (a b)select a from (values (11 2) (sin(33) 2+2)) x (a b)```but i dont know where we would put that code  also it would require special handling for no-columns || i dont know this syntax and we (at my company) only need simple implementation of _values_sql-92 say that :> values <row value constructor>> it is a function>         specify a set of <row value constructor>s to be constructed into a tabledoes this pr implements the """"simple"""" way ? || > we should be able to prune the columns for queries like > but i dont know where we would put that code also it would require special handling for no-columnsyou need to add a rule in `pruneunreferencedoutputs` for `valuesnode` it needs to look at the list of expected outputs that gets passed in and drop anything the node produces that is not in that list || other than those comments  "";;;;1;1;implement values;"
1054;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;add tracking of latency and failures for hadoop api calls;;;0;add tracking of latency and failures for hadoop api calls;;;;;;1;1;add tracking of latency and failures for hadoop api calls;
1056;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix effectivepredicateextractor range summary bug;occurs when the rangeset has no ranges.;;0;fix effectivepredicateextractor range summary bug;occurs when the rangeset has no ranges;;;;;1;1;fix effectivepredicateextractor range summary bugoccurs when the rangeset has no ranges;
"1061;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix joins that have order by rand();;;0;fix joins that have order by rand();;whats the failure mode without this fix? (maybe add a quick explanation in the commit message) || updated the commit message || ;;;;1;1;""fix joins that have order by rand()previously """"only deterministic expressions may be considered for rewrite"""" exception was thrown"";"
1065;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix handling of hive timestamp in maps/lists;also  add more unit tests for rcfile formats;;0;fix handling of hive timestamp in maps/lists;also add more unit tests for rcfile formats;add a comment to the commit message describing what the issue was otherwise ;;;;1;1;fix handling of hive timestamp in maps/listshive timestamp was serialized as a string when it was in a map/list butas a bigint when it was a primitive this makes it always be serializedas a bigint of secondsalso add more unit tests for rcfile formats;
1069;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;rename analyzer.approximate-queries-enabled;change name of config flag to analyzer.experimental-syntax-enabled  since it s used to gate more than just approximate queries (rescaled sampling);;0;rename analyzerapproximate-queries-enabled;change name of config flag to analyzerexperimental-syntax-enabledsince its used to gate more than just approximate queries (rescaledsampling);;;;;1;1;rename analyzerapproximate-queries-enabledchange name of config flag to analyzerexperimental-syntax-enabledsince its used to gate more than just approximate queries (rescaledsampling);
1077;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add more details to time logging in test queries;;;0;add more details to time logging in test queries;;thanks!  ;;;;1;1;add more details to time logging in test queries;
"1087;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;change default read timeout to 1 second;i m not sure if the values are correct  but this shows how the default config system works;;0;change default read timeout to 1 second;im not sure if the values are correct but this shows how the default config system works;""updated to new configuration defaults system || looks good but i had some questions || ready to go but waiting on a review of  by @electrum  || @cberner i added a new commit """"update to new config binder api"""" and changed the defaults for  client a bit ||  "";;;;1;1;set  client defaultschange default idle timeout to 2 secondchange default request timeout to 10 secondchange default connections per host to 250;"
1088;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;add error codes;;;0;add error codes;;the code in `cachinghivemetastore` is already complex and this makes it worse we should consider how this can be simplified || if its not too difficult it would be good to make the hive changes in a separate commit || ;;;;1;1;add error codes for hive;
1089;1;0;0;1;1;1;1;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;parallelize test queries in presto-main;make all unit tests in presto-main run in parallel by default  and annotate non-threadsafe tests with singlethreaded=true;;0;parallelize test queries in presto-main;make all unit tests in presto-main run in parallel by default andannotate non-threadsafe tests with singlethreadedtrue;;;;;1;1;parallelize test queries in presto-mainmake all unit tests in presto-main run in parallel by default andannotate non-threadsafe tests with singlethreadedtrue;
1100;1;0;0;1;1;1;1;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;run all tests in parallel by default;annotate all tests that use @beforemethod with singlethreaded=true;;0;run all tests in parallel by default;annotate all tests that use @beforemethod with singlethreadedtrue;;;;;1;1;run all tests in parallel by defaultannotate all tests that use @beforemethod with singlethreadedtrue;
1105;1;0;1;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;remove potential deadlock with broken connectors;replace synchronized lock with a custom lock with timeout support  for close and updatesource stage change and then attempt to acquire lock.  if lock is acquired  process change  otherwise lock holder will process change before releasing lock.  for close  if lock can not be acquired  interrupt lock holder.;;0;remove potential deadlock with broken connectors;replace synchronized lock with a custom lock with timeout supportfor close and updatesource stage change and then attempt to acquirelock  if lock is acquired process change otherwise lock holderwill process change before releasing lockfor close if lock can not be acquired interrupt lock holder;its hard to play out all the concurrency scenarios in my mind but it looks reasonable assuming tests pass im ok you may also want to try it out in the scale cluster ||;;;;1;1;remove potential deadlock with broken connectorsreplace synchronized lock with a custom lock with timeout supportfor close and updatesource stage change and then attempt to acquirelock  if lock is acquired process change otherwise lock holderwill process change before releasing lockfor close if lock can not be acquired interrupt lock holder;
1108;1;0;0;0;1;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;1;0;fix division by zero in varianceaggregation;;;0;fix division by zero in varianceaggregation;;add a test that reproduces the issueother than that ;;;;1;1;fix division by zero in some aggregationsfix both varianceaggregation and approximateaverageaggregation;
"1109;1;0;0;0;0;1;0;0;0;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;update s3 filesystem;this is an updated version of #1044.;;1044.0;update s3 filesystem;this is an updated version of #1044;;support write and retry in prestos3filesystem;1 support writing to s32 implement retry when reading from s33 disable the extensive logging;""@electrum comments addressed i get this deployed and running on a 10 node presto cluster reading/writing to/from s3 || are you going to open a new pull request? || whoops i accidentally close it reopen now || kindly ping || does this support writing result tables to s3? || yes this supports """"create table as select"""" to create table in s3 || great does it already support that for hdfs?  i didnt see that ability in the documentation || """"create table as select"""" should already be supported: || @zhenxiao in order to avoid more back and forth on the review i made some changes to your commit and created a new pull request #1109 with it and added some additional commits with other fixes and unit tests it would be great if you can review and try it out (will also have someone else on our end review it maybe @dain) sorry that i kept you waiting for so long on this || @electrum thanks i will review and test it over the weekend || "";1;0;add tests for s3 table creation;"
1115;1;0;0;1;1;0;0;0;0;0;1;1;0;0;0;0;1;0;0;0;0;0;0;0;0;1;0;fix null values for databasemetadata.getcolumns;;;0;fix null values for databasemetadatagetcolumns;;sure ||;;;;1;1;fix null values for databasemetadatagetcolumns;
1116;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fixes;;;0;fixes;;ship it! ||;;;;1;1;fix bug in nodeschedulerhashmap was being recreated on every iteration of loop;
1122;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;indivisible;;;0;indivisible;;looks good but wait until i cut release 061 before pushing ||;;;;1;1;add missing @override annotations;
1125;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;read timing;;;0;read timing;;;;;;1;1;add support for tracking connector read time;
1128;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;add directorylister interface;use dependency injection instead of a static method call.;;0;add directorylister interface;use dependency injection instead of a static method call;;;;;1;1;add directorylister interface;
1129;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;refactor failure handling;- split failureinfo into clientfailureinfo and failureinfo  so that error codes can be propagated back from workers - change errorcode to a concrete class  instead of an interface  to allow it to be json serialized;;0;refactor failure handling;- split failureinfo into clientfailureinfo and failureinfo so that error codes can be propagated back from workers- change errorcode to a concrete class instead of an interface to allow it to be json serialized;split the commit into two one for each logical change || other than those comments ;;;;1;1;refactor failure handlingsplit failureinfo into executionfailureinfo and failureinfo so that error codes can be propagated back from workers;
"1131;1;0;0;1;1;1;0;0;0;0;1;1;1;1;0;0;0;0;1;0;0;0;1;1;0;1;0;record  started  counter for queries that fail to parse;in the last release we started tracking parsing failures for error categorization  but the change was missing the call to increment the started counter.  as a result  the started and completed counters get permanently out of sync and cause the number of running queries to be reported as 0.  fixes https://github.com/facebook/presto/issues/1130;;0;""record """"started"""" counter for queries that fail to parse"";in the last release we started tracking parsing failures for error categorizationbut the change was missing the call to increment the started counteras a result the started and completed counters get permanently out of syncand cause the number of running queries to be reported as 0fixes https://githubcom/facebook/presto/issues/1130;;;;;1;1;""record """"started"""" counter for queries that fail to parsein the last release we started tracking parsing failures for error categorizationbut the change was missing the call to increment the started counteras a result the started and completed counters get permanently out of syncand cause the number of running queries to be reported as 0"";"
1132;1;0;0;1;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;rename hadoopapistats and move it out of util package;;;0;rename hadoopapistats and move it out of util package;;;;;;1;1;rename hadoopapistats and move it out of util package;
1134;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;categorize user errors;- categorize a bunch of illegal argument exceptions as user errors - categorize division by zero as a user error;;0;categorize user errors;- categorize a bunch of illegal argument exceptions as user errors- categorize division by zero as a user error;;;;;1;1;categorize user errors* categorize a bunch of illegal argument exceptions as user errors* categorize division by zero as a user error;
1136;1;0;0;1;0;1;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;include metastore host name in exception message;;;0;include metastore host name in exception message;;;;;;1;1;include metastore host name in exception message;
1143;0;0;0;0;0;0;0;0;0;0;1;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;use a private i/o thread pool for failure detector;;;0;use a private i/o thread pool for failure detector;;interesting config option;;;;1;1;use a private i/o thread pool for failure detector;
1145;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;allow additional modules with testingprestoserver;;;0;allow additional modules with testingprestoserver;;;;;;1;1;allow additional modules with testingprestoserver;
1151;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;0;add experimental syntax flag to functionregistry;- gate approximate functions with experimental syntax flag - will also be used to gate future experimental functions  like the ml functions;;0;add experimental syntax flag to functionregistry;- gate approximate functions with experimental syntax flag- will also be used to gate future experimental functions like the ml functions;;;;;1;1;add experimental syntax flag to functionregistry* gate approximate functions with experimental syntax flag* will also be used to gate future experimental functions like the ml functions;
1153;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;1;0;categorize errors and improve prestoexception message;;;0;categorize errors and improve prestoexception message;;;;;;1;1;categorize invalid regex errors;
1154;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;1;0;categorize partition offline exceptions;also preserve their exception type by making partitionofflineexception extend prestoexception. this fixes our internal tests;;0;categorize partition offline exceptions;also preserve their exception type by making partitionofflineexception extend prestoexception this fixes our internal tests;;;;;1;1;categorize partition offline exceptionsalso preserve their exception type by making partitionofflineexception extend prestoexception this fixes our internal tests;
1156;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;rename abstracthiverecordcursor to hiverecordcursor;;;0;rename abstracthiverecordcursor to hiverecordcursor;;;;;;1;1;rename abstracthiverecordcursor to hiverecordcursor;
1160;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;0;0;1;0;1;0;0;1;0;1;0;fix npe in planprinter;;;0;fix npe in planprinter;;;;;;1;1;fix npe in planprinter;
1162;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;rewrite identical projection expressions in terms of the same symbol;this is an existing gap in our optimizer whereby a projection may have the same deterministic expression being generated for multiple output symbols. this results in the expression being computed and stored multiple times unnecessarily.  for example  consider this query:   previously our plan would look like this:   with the fix it looks like this: https://gist.github.com/erichwang/e08606ae5fe17dc52a6c;;0;rewrite identical projection expressions in terms of the same symbol;this is an existing gap in our optimizer whereby a projection may have the same deterministic expression being generated for multiple output symbols this results in the expression being computed and stored multiple times unnecessarilyfor example consider this query: our plan would look like this: the fix it looks like this //gistgithubcom/erichwang/e08606ae5fe17dc52a6c;thats odd that used to work before there wasnt any explicit optimization step but it was a side-effect of how the planner worksanyway  actually this is a slightly different case than what you are thinking of so the planner does take care of this if you explicitly call out a the expressions in a projection: like select a+1 a+1 from a and it happens in the initial planning phase the problem here is that the duplicate projections expressions are implicitly generated when we coalesce multiple consecutive projections together from under a join for example consider this:select \* from (select dummy || x as dummy from dual) a join dual b on adummy  bdummythe join planner will add a projection to generate a new adummy for the equijoin even though an existing one was already used to produce the query output ||;;;;1;1;rewrite identical projection expressions in terms of the same symbol;
1163;1;0;0;0;0;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;fix range bug in spi;this is a nasty one.;;0;fix range bug in spi;this is a nasty one;;;;;1;1;fix range bug in spi;
1167;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix race condition in hive tests;;;0;fix race condition in hive tests;;;;;;1;1;fix race condition in hive tests;
1168;1;0;0;0;1;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;1;0;fix error bounds for approximate sum and avg;;;0;fix error bounds for approximate sum and avg;;;;;;1;1;bug fix for approximate avg and sum error bounds* fix avg error bound so that we divide by the unweighted number of samples instead of the weighted number* fix sum error bound to include missing samples term and to compute the variance of the unweighted data* include derivation of error bounds in comments* improve unit tests for approximate aggregations:** check that error bound is neither too tight nor too loose** test on random number of samples instead of always testing on a  size** increase amount of data used in testing;
1172;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;errors;;;0;errors;;;;;;1;1;categorize errors with json functions;
1173;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;resize group by builder;;;0;resize group by builder;;@cberner will this get merged soon? we hit this problem frequently with our customers so hope this change will be merged into upstream sooner than later || yes it just needs a quick round of review and then well merge it hopefully tomorrow but definitely before the next release || cool thank you very much! || other than the minor comments  ;;;;1;1;change canuse() to return true on success instead of false;
1178;1;0;0;1;1;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add helper methods similar to checkargument;;;0;add helper methods similar to checkargument;;;;;;1;1;add helper methods similar to checkargument;
1179;1;0;0;1;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;1;fix bug in create table as select;;;0;fix bug in create table as select;;;;;;1;1;fix bug where fields may be written in the wrong orderthis bug in create table as select was introduced by ad73cf8f57f70da2b165f0128c4c84ed6f5b2c14with the removal of the call to unpack() this of this method was to turn multi-fieldchannels into one channel per field but also reordered channels to match what the operatorexpected;
1185;1;0;0;0;1;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;1;0;1;1;0;1;0;fix npe in sqltaskexecution.isfinished;;;0;fix npe in sqltaskexecutionisfinished;;;;;;1;1;fix npe in sqltaskexecutionisfinished;
"1190;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;fix numberformatexception killing cli bug;;;0;fix numberformatexception killing cli bug;;""please squash the commits || this looks good but please title the commit """"handle numberformatexception in parser"""" since this is not directly related to the cli || "";;;;1;1;handle numberformatexception in parser;"
1194;1;0;0;0;1;1;0;0;0;0;0;1;0;0;0;0;1;0;0;0;1;0;0;1;0;1;0;reuse pre computed partitiondomainsummary;partitiondomainsummary computation is an expensive operation(250ms for 12k partitions). instead of computing it every time a new instance of tablescannode is created  we can use pre computed partitiondomainsummary value.;;0;reuse pre computed partitiondomainsummary;partitiondomainsummary computation is an expensive operation(250ms for 12k partitions) instead of computing it every time a new instance of tablescannode is created we can use pre computed partitiondomainsummary value;this is an ok workaround but the question is why its so slow to compute 12k partitions is it algorithmic? do the primitives were using have hidden costs that are not being accounted for? || @martint : it doesnt seem to be algorithmic right now it takes o(n lg(n)) time to compute union of ranges on a single column since we need to sort and merge ranges o(n lg(n)) is expected i tried to reduce constant factor by using minheap instead of treemap but didnt see any performance improvement i will look for hidden cost in primitives  || @martint : liststransform returns transformingrandomaccesslist which is view on existing list and every time we have to do get() on list it applies transform function on underlying list element so iteration on tupledomains(which is transformingrandomaccesslist here) was slow after getting rid of transformingrandomaccesslist columnwiseunion computation time goes down from 170ms to 40ms for 6k partitions || whats the effect on performance due to memoization vs the fix to avoid the list transformer view? || we are using memoization 3 out of 4 times so its 4 times faster when we avoid the list transfer view domainsummary computation time goes down from 170ms to 40ms on 6k partitions so its 4 times faster here as well combining both we should see 16x performance gain  || cool ok once you fix the couple of comments i made ship it ||;;;;1;1;reuse pre computed partitiondomainsummary;
1197;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;allow setting time zone for hive data;;;0;allow setting time zone for hive data;;;;;;1;1;allow setting time zone for hive data;
1201;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;full type support updated with feedback;this included all code from udt and  full-type-support and has been updated based on feedback from the reviews.;;0;full type support updated with feedback;this included all code from udt and  full-type-support and has been updated based on feedback from the reviews;;;;;1;1;fix timestamp type in hive connector;
1202;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;1;0;0;1;0;1;0;index joins;updated for new type system;;0;index joins;updated for new type system;im done but @martint should review the planner stuff || ;;;;1;1;add unit tests for index joins;
1205;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add date_trunc function;;;0;add date_trunc function;;aside from century calculation  postgresql and derivatives say this:```1999  202000  202001  21``` || the problem is presto uses iso chronology to perform all date time calculations and postgres is likely using the gregorianjuliani chronology  the main difference is gj does not have a year zero and numbers years of the century from [1100] where as iso has a year 0 and numbers years in centuries from [099]  the nice thing is i dont think anyone actually ever uses the century field so i just removed it  if we want to add it back in the future we should make the chronology settable in the session first ||;;;;1;1;remove century date time field;
1206;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;1;1;0;1;0;add color type and use it in color functions;;;0;add color type and use it in color functions;;;;;;1;1;add color type and use it in color functions;
"1208;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;0;0;1;0;1;0;0;1;0;1;0;explain missing column type bug fix;;;0;explain missing column type bug fix;;""also change the commit message to say """" with missing column types in explain"""" ||  "";;;;1;1; with missing column types in explain;"
1210;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix regression with varchar partitions in hive;fix the hive connector to return slice objects for the values of varchar partition columns instead of string objects. also fix the hive tests to use slice instead of string.;;0;fix regression with varchar partitions in hive;fix the hive connector to return slice objects for the values of varcharpartition columns instead of string objects also fix the hive tests touse slice instead of string;;;;;1;1;fix regression with varchar partitions in hivefix the hive connector to return slice objects for the values of varcharpartition columns instead of string objects also fix the hive tests touse slice instead of string;
1211;1;0;0;1;1;0;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;0;0;1;0;1;0;jdbc date time types;;;0;jdbc date time types;;;;;;1;1;add support for interval types to jdbc driver;
1213;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;minor fixes;;;0;minor fixes;;;;;;1;1;add check for unsupported hive partition type;
1216;1;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;1;0;0;0;0;0;0;spi cleanup;remove unnecessary methods use consistent naming add javadocs to interfaces change recordcursor getstring to getslice returning a slice allow plugins to register new types and blockencodingfactories;;0;spi cleanup;remove unnecessary methodsuse consistent namingadd javadocs to interfaceschange recordcursor getstring to getslice returning a sliceallow plugins to register new types and blockencodingfactories;;;;;1;1;cleanup parsing of the time zonesadd test for time zone key parsingmake timezonekey case insensitivefix handling of utc equivalent time zonesremove gmt0 from zone file since it is utc equivalent and the zone file has not been published yet;
1218;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;fix exchange client leak when queries are abandoned;the query purger in statementresource wasn t calling close() on query objects when purging them from the list of active queries. as a result  abandonded queries would result in statementresource leaking an exchange client;;0;fix exchange client leak when queries are abandoned;the query purger in statementresource wasnt calling close() on query objects when purgingthem from the list of active queries as a result abandonded queries would resultin statementresource leaking an exchange client;;;;;1;1;fix exchange client leak when queries are abandonedthe query purger in statementresource wasnt calling close() on query objects when purgingthem from the list of active queries as a result abandonded queries would resultin statementresource leaking an exchange client;
1223;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;1;0;1;0;1;0;fix implicit coercion of aggregates;;;0;fix implicit coercion of aggregates;;;;;;1;1;fix implicit coercion of aggregation and window functions;
1224;1;0;0;0;0;1;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;pagesserde fixes;;;0;pagesserde fixes;;looks good  please push soon as i have some more fixes for this code id like to get in also ||;;;;1;1;simplify pagesserde;
1226;1;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;fix a few thread-safety/concurrency issues;;;0;fix a few thread-safety/concurrency issues;;;;;;1;1;merge operator stats atomically;
1227;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;implement tostring for hll;;;0;implement tostring for hll;;;;;;1;1;implement tostring for hll;
1230;1;0;0;1;1;1;1;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;fix incorrect output from show schemas;there was a bug in the way metadatamanager keeps track and resolves information schema connector registrations that caused the wrong connectormetadata to be picked. as a result  show schemas would display schemas from another catalog.;;0;fix incorrect output from show schemas;there was a bug in the way metadatamanager keeps track and resolves information schemaconnector registrations that caused the wrong connectormetadata to be picked as a resultshow schemas would display schemas from another catalog;;;;;1;1;fix incorrect output from show schemasthere was a bug in the way metadatamanager keeps track and resolves information schemaconnector registrations that caused the wrong connectormetadata to be picked as a resultshow schemas would display schemas from another catalog;
1232;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;cleanup serdeutils;;;0;cleanup serdeutils;; btw this is going to conflict with the spi-cleanup pr ||;;;;1;1;cleanup serdeutils;
"1234;1;0;0;0;1;1;0;0;1;0;1;1;0;1;0;0;1;0;1;0;0;0;0;1;0;1;0;fix memory leak in bootstrapfunctionbinder;callsites were being registered in a global bootstrapfunctionbinder but were never removed.  in this implementation  we create one bootrapfunctionbinder per dynamic classloader and load an  isolated  version of the bootstrap class used by invokedynamic calls. when the classloader is garbage-collected (i.e.  the compiled code is no longer needed)  the callsite registrations are collected  too.;;0;fix memory leak in bootstrapfunctionbinder;""callsites were being registered in a global bootstrapfunctionbinder but were never removedin this implementation we create one bootrapfunctionbinder per dynamic classloader and loadan """"isolated"""" version of the bootstrap class used by invokedynamic calls when the classloaderis garbage-collected (ie the compiled code is no longer needed) the callsite registrationsare collected too"";;;;;1;1;""fix memory leak in bootstrapfunctionbindercallsites were being registered in a global bootstrapfunctionbinder but were never removedin this implementation we create one bootrapfunctionbinder per dynamic classloader and loadan """"isolated"""" version of the bootstrap class used by invokedynamic calls when the classloaderis garbage-collected (ie the compiled code is no longer needed) the callsite registrationsare collected too"";"
1236;1;0;0;0;1;1;0;0;1;1;1;1;1;0;0;0;1;0;1;0;1;1;0;1;0;1;1;use valuesnode instead of dual table for planning queries w/o from;;;0;use valuesnode instead of dual table for planning queries w/o from;;very nice! ship it ||;;;;1;1;use valuesnode instead of dual table for planning queries w/o from;
1237;1;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;fix warnings in blockencodingmanager;;;0;fix warnings in blockencodingmanager;;;;;;1;1;fix warnings in blockencodingmanager;
1238;1;0;0;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;0;0;0;1;0;1;0;exchange client improvements;;;0;exchange client improvements;;i finished the review but i think we need to find a solution to the timing problem ||;;;;1;1;fail queries after too many exchangeclient errorsa query will fail if errors continue for longer than the minimum duration;
1239;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix memory (estimate) leak and reduce memory usage of group by and distinct;;;0;fix memory (estimate) leak and reduce memory usage of group by and distinct;;;;;;1;1;reduce memory usage of groupbyhashpreviously memory usage was proportional to the size of the input pagesand the number of distinct groups now its only dependent on the numberof distinct groups;
1240;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;1;1;1;0;1;0;add support for plugins to register new types and blockencodingfactories;;;0;add support for plugins to register new types and blockencodingfactories;;;;;;1;1;add support for plugins to register new types and blockencodingfactories;
1242;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hive client tests using getslice as byte array;;;0;fix hive client tests using getslice as byte array;;;;;;1;1;fix hive client tests using getslice as byte array;
1245;1;0;0;1;1;1;0;0;0;0;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;provide locale via x-presto-language header;the expected format is as defined by ietf bcp 47 (http://tools.ietf.org/html/bcp47);;0;provide locale via x-presto-language header;the expected format is as defined by ietf bcp 47 (http://toolsietforg/html/bcp47);;;;;1;1;provide locale via x-presto-language headerthe expected format is as defined by ietf bcp 47 (http://toolsietforg/html/bcp47);
1247;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;0;0;hive timestamp fixes;;;0;hive timestamp fixes;;;;;;1;1;handle broken timestamp objectinspectors;
1248;1;0;0;1;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add hive plugin for cdh 5;;;0;add hive plugin for cdh 5;;i thought we were going to implement this by changing `hiveplugin` constructor to take a var args list of names and then changing the hadoop 2x connector to declare both? || why a separate plugin rather than exporting multiple connectors:- easier to implement- fits with existing `hiveplugin` structure- allows configuring unit tests separately and running them together with hadoop 2x tests when building the whole project- conceptually simpler for users and developers: there is a real module in the source tree and a real plugin directory in the tarballthe main downside is it adds nearly 50mb to the server tarball this could be  by using hard links inside the tarball || ;;;;1;1;add hive plugin for cdh 5;
1249;1;0;0;1;1;1;0;0;1;1;1;1;0;0;0;0;1;1;1;0;1;1;1;1;0;1;0;add support for plugin provided operators;;;0;add support for plugin provided operators;;;;;;1;1;add support for plugin provided operators;
1250;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix planning issues with non-trivial types and date/time constructs in values;;;0;fix planning issues with non-trivial types and date/time constructs in values;;;;;;1;1;fix planning issue with date/time constructs in valuesplanning values requires optimizing and constant-folding expressionsthe interpreter/optimizer can only deal with a subset of ast node types(eg currenttime is not supported)to work around this until the new expression tree is implemented canonicalizeexpressions before feeding them to the optimizer/interpreter;
1252;1;0;0;1;0;1;0;0;0;1;1;1;1;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add backoff for httppagebufferclient;;;0;add backoff for httppagebufferclient;;;;;;1;1;add delegated constructor for httppagebufferclient;
1253;1;0;0;1;1;1;1;0;0;1;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix tracking of time for splitsource.getnextbatch;;;0;fix tracking of time for splitsourcegetnextbatch;;;;;;1;1;fix tracking of time for splitsourcegetnextbatch;
1254;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;0;0;0;1;0;1;0;allow non-grouped aggregations to report their memory usage;;;0;allow non-grouped aggregations to report their memory usage;;;;;;1;1;allow non-grouped aggregations to report their memory usage;
1255;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add config to disable proximity scheduling;add a config parameter to disable scheduling based on proximity. this will enable us to remove a variable and help us drill down into the cause of uneven split distribution.;;0;add config to disable proximity scheduling;add a config parameter to disable scheduling based on proximity this will enable us to remove a variable and help us drill down into the cause of uneven split distribution;;;;;1;1;add config to disable location aware scheduling;
1256;1;0;0;0;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;hide internal functions;;;0;hide internal functions;;;;;;1;1;hide internal functions;
1257;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;1;session cleanups;;;0;session cleanups;;;;;;1;1;rename session to connectorsession;
1258;1;0;0;0;0;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;cleanup date time functions;;;0;cleanup date time functions;;;;;;1;1;remove millis_to_time functions;
1260;1;0;0;0;0;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;implement weekyear (%x) in date_parse and date_format;;;0;implement weekyear (%x) in date_parse and date_format;;;;;;1;1;implement weekyear (%x) in date_parse and date_format;
1261;1;0;1;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;1;1;0;0;1;0;1;0;cli and example- fixes;;;0;cli and example- fixes;;looks good but i dont understand why the cli changes fix a hang ||;;;;1;1;fix cli hang after use statement;
1263;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add hive format test for null lists;;;0;add hive format test for null lists;;;;;;1;1;add hive format test for null lists;
1268;1;0;0;1;1;1;0;0;0;0;1;0;0;0;0;0;0;0;1;0;0;1;0;1;0;1;0;fixes;;;0;fixes;;;;;;1;1;add slice to parent first class list;
1272;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;minor cleanup;;;0;minor cleanup;;;;;;1;1;replace instanceof with checktype in hive connector;
1273;1;0;0;1;0;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;categorize invalid varchar casts;;;0;categorize invalid varchar casts;;can you add this to all methods annotated with @scalaroperator(cast) || ;;;;1;1;categorize invalid varchar casts;
1274;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;1;1;0;1;0;1;1;1;1;0;1;1;add formatting for every statement type;;;0;add formatting for every statement type;;;;;;1;1;move parser utility classes out of tree package;
1275;1;0;1;1;1;0;0;0;0;0;1;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;add machine learning functions plugin;add functions to train and use machine learning models (classifiers and regressors) in presto. this is currently only a proof of concept  and is not ready for use in production. example usage is as follows:      sql select evaluate_classifier_predictions(label  classify(features  model)) from (     select learn_classifier(label  features) as model     from my_training_data  ) cross join my_validation_data;;0;add machine learning functions plugin;add functions to train and use machine learning models (classifiers andregressors) in presto this is currently only a proof of concept and isnot ready for use in production example usage is as follows:``` sqlselect evaluate_classifier_predictions(label classify(features model))from (    select learn_classifier(label features) as model    from my_training_data)cross join my_validation_data```;;;;;1;1;add machine learning functions pluginadd functions to train and use machine learning models (classifiers andregressors) in presto this is currently only a proof of concept and isnot ready for use in production example usage is as follows:select evaluate_classifier_predictions(label classify(features model))from (    select learn_classifier(label features) as model    from my_training_data)cross join my_validation_data;
1276;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;add tostring to hivebucket;;;0;add tostring to hivebucket;;;;;;1;1;add tostring to hivebucket;
"1279;1;0;0;1;1;1;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;categorize more errors;;;0;categorize more errors;;;;;;1;1;""add error code for """"no nodes available"""" error"";"
1280;1;0;0;0;0;0;0;0;0;1;1;0;0;0;0;0;1;0;0;0;1;0;0;0;0;1;0;error code improvements;;;0;error code improvements;;;;;;1;1;add validation to errorcode;
1281;1;0;0;1;0;1;0;0;0;1;1;0;0;0;0;0;1;0;1;0;1;0;0;0;0;1;0;finish properly parameterizing tupledomain;;;0;finish properly parameterizing tupledomain;;;;;;1;1;finish properly parameterizing tupledomain;
1282;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;http500;;;0;http500;;see comments but ;;;;1;1;suppress exceptions closing record reader when handling an exception;
1289;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;update to hive 0.13;;;0;update to hive 013;; any chance to see it in next release? ||;;;;1;1;update to hive 0131;
1296;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;1;0;add timestamp with time zone minus interval year month operator;;;0;add timestamp with time zone minus interval year month operator;;;;;;1;1;add timestamp with time zone minus interval year month operator;
1297;1;0;0;1;1;1;0;0;1;0;1;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;various cleanup;;;0;various cleanup;;;;;;1;1;fix warnings in metadatamanager;
"1302;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;fix build;;;0;fix build;;""maybe update the commit message to say """"add missing file"""" instead of just """"fix build"""" ||  "";;;;1;1;add missing file;"
1303;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;fix mappedrecordcursor bug;;;0;fix mappedrecordcursor bug;;;;;;1;1;fix mappedrecordcursor bug;
1305;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;0;0;0;0;0;0;0;0;0;make testdatetimefunctions single threaded;;;0;make testdatetimefunctions single threaded;;;;;;1;1;make testdatetimefunctions single threaded;
1306;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;implement varbinary type;adds a varbinary type and basic operators/functions;;0;implement varbinary type;adds a varbinary type and basic operators/functions;thank you for signing our contributor license agreement we can now accept your code for this (and any) facebook open source project  ;;;;1;1;map hive binary type to varbinary;
"1309;1;0;0;1;1;1;1;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;add option to disable scheduling tasks on coordinator;;;0;add option to disable scheduling tasks on coordinator;;""updated because i found a bug in my implementation || thank you for signing our contributor license agreement we can now accept your code for this (and any) facebook open source project  for my understanding how is the system data source part of the change related to scheduling? || system splits can only be processed on the coordinator and if they dont have a datasource set they go through the else branch of this if ( and then fail because nothing can process them if you turn off work scheduling on the coordinatorwith the datasource set the coordinator will still process them because turning off work scheduling only turns off splits that have no datasource || thanks! one more question: i was testing this change out since i needed to disable scheduling on coordinator i made one change to your patch which was to initialize scheduleworkoncoordinator  false however i still see some tasks getting executed on the coordinator im yet to debug it in detail - but wanted to check if this is the right way to change the default value || perhaps i should make the name of that a little more specific it only disables work that is not """"source"""" work meaning that it will still process table scan operations if you have datasources configured on the coordinator if you want to remove those also you should remove them from the datasources list in the config file_edit_ even then it will still process splits for the system connector as that cannot be disabled as presto relies on it to run queries however those shouldnt create very much load ||  "";;;;1;1;add option to disable scheduling tasks on coordinator;"
1310;1;0;0;0;0;1;0;0;0;0;1;0;0;0;0;0;1;0;1;0;1;0;0;0;0;0;0;simplify sortedrangeset.builder and add benchmark;collect ranges and do one pass at the end to merge adjacent and overlapping ranges.  this improves performance for this class by about 6x for a synthetic benchmark with 10000 ranges              benchmark                                            mode   samples   mean  mean error   units before: c.f.p.s.benchmarksortedrangeset.benchmarkbuilder     avgt        10  5.416       0.150   ms/op after:  c.f.p.s.benchmarksortedrangeset.benchmarkbuilder     avgt        10  0.867       0.016   ms/op;;0;simplify sortedrangesetbuilder and add benchmark;collect ranges and do one pass at the end to merge adjacent and overlapping rangesthis improves performance for this class by about 6x for a synthetic benchmark with 10000 ranges```        benchmark                                            mode   samples   mean  mean error   unitsbefore: cfpsbenchmarksortedrangesetbenchmarkbuilder     avgt        10  5416       0150   ms/opafter:  cfpsbenchmarksortedrangesetbenchmarkbuilder     avgt        10  0867       0016   ms/op```;;;;;1;1;simplify sortedrangesetbuilder and add benchmarkcollect ranges and do one pass at the end to merge adjacent and overlapping rangesthis improves performance for this class by about 6x for a synthetic benchmark with 10000 ranges        benchmark                                            mode   samples   mean  mean error   unitsbefore: cfpsbenchmarksortedrangesetbenchmarkbuilder     avgt        10  5416       0150   ms/opafter:  cfpsbenchmarksortedrangesetbenchmarkbuilder     avgt        10  0867       0016   ms/op;
"1316;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;1;0;1;0;1;0;0;1;0;1;0;hidden columns;allow connectors to expose columns that are hidden.  a hidden column will not appear in describe table or information schema  columns  table  and will not be selected with  * .  the only way to access a hidden column is explicitly by name.  additionally  i have added a hidden column   row_number   to the tpch connector for testing.;;0;hidden columns;allow connectors to expose columns that are hidden  a hidden column will not appear in describe table or information schema `columns` table and will not be selected with `*`  the only way to access a hidden column is explicitly by nameadditionally i have added a hidden column `row_number` to the tpch connector for testing;"" @martint can you review this again i had to rewrite the change to fix some bugs || sounds very interesting idea :+1:we want to provide a special hidden column named v map<stringstring> which represents the row itself its useful for us because we store schema-less json records users sometimes include special characters (like : or ) in field names which cant be a part of column names or they sometime include special fields depending on """"type"""" of the rowfor example `select case type when job then v[q:start_time] else v[q:access_time]` this query needs hidden v column because q:start_time is invalid column name and they dont want to include v or q:start_time in """"select *"""" || "";;;;1;1;add hidden row_number column to tpch connector;"
1317;1;0;0;0;1;1;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix varbinary-related test failures;;;0;fix varbinary-related test failures;;;;;;1;1;fix failing unit test;
1319;1;0;1;1;1;1;1;0;1;1;1;1;1;1;0;0;1;1;1;0;1;1;1;1;0;1;1;extract native connector into separate plugin;;;0;extract native connector into separate plugin;;;;;;1;1;extract native connector into separate pluginthe native connector is now called raptor and lives in presto-raptor;
1320;1;0;0;0;1;1;0;0;1;1;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;refactor aggregations;introduce a new base class for aggregation functions that makes them simpler to write.  it looks like there s a small (~3% performance regression)  but given how much this simplifies the code  i think it s worthwhile. we could also try to get that back with byte code generation.  master:                   hand_tpch_query_1 :: 2907.023 cpu ms :: in    6m    361mb    2.06m/s    124mb/s :: out     4     300b        1/s     103b/s                   hand_tpch_query_6 ::  308.901 cpu ms :: in    6m    240mb    19.4m/s    778mb/s :: out     1       9b        3/s      29b/s  my branch:                   hand_tpch_query_1 :: 2937.362 cpu ms :: in    6m    361mb    2.04m/s    123mb/s :: out     4     300b        1/s     102b/s                   hand_tpch_query_6 ::  321.828 cpu ms :: in    6m    240mb    18.6m/s    747mb/s :: out     1       9b        3/s      27b/s;;0;refactor aggregations;introduce a new base class for aggregation functions that makes themsimpler to writeit looks like theres a small (~3% performance regression) but given how much this simplifies the code i think its worthwhile we could also try to get that back with byte code generationmaster:                  hand_tpch_query_1 :: 2907023 cpu ms :: in    6m   361mb   206m/s   124mb/s :: out     4    300b       1/s    103b/s                  hand_tpch_query_6 ::  308901 cpu ms :: in    6m   240mb   194m/s   778mb/s :: out     1      9b       3/s     29b/smy branch:                  hand_tpch_query_1 :: 2937362 cpu ms :: in    6m   361mb   204m/s   123mb/s :: out     4    300b       1/s    102b/s                  hand_tpch_query_6 ::  321828 cpu ms :: in    6m   240mb   186m/s   747mb/s :: out     1      9b       3/s     27b/s;;;;;1;1;refactor aggregationsintroduce a new base class for aggregation functions that makes themsimpler to write;
1321;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;1;1;0;1;0;fix show partitions and dual catalog with include-coordinator=false;mark dual and information schema as system datasources. also add more unit tests for disabling coordinator work scheduling;;0;fix show partitions and dual catalog with include-coordinatorfalse;mark dual and information schema as system datasources also add more unit tests for disabling coordinator work scheduling;;;;;1;1;fix show partitions and dual catalog with include-coordinatorfalsemark dual and information schema as system datasources also add more unit tests for disabling coordinator work scheduling;
1322;1;0;0;0;1;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;0;categorize invalid argument errors to approx_percentile;;;0;categorize invalid argument errors to approx_percentile;;updated to remove the percentile parameter || ;;;;1;1;categorize invalid argument errors to approx_percentile;
1324;1;0;0;0;1;0;0;0;0;0;1;1;0;0;0;1;1;0;1;0;0;0;0;1;0;1;0;add more configurable learn methods for ml plugin;;;0;add more configurable learn methods for ml plugin;;;;;;1;1;add function to train libsvm modelsadd special learning functions that allow you to configure thehyperparameters of the model;
1325;1;0;0;0;1;0;0;0;1;0;0;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix parsing and formatting of sign expressions;;;0;fix parsing and formatting of sign expressions;;;;;;1;1;fix parsing and formatting of sign expressions;
1326;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;1;1;1;0;1;0;deprecate the datasources configuration property;this property  if not set  is now configured automatically at startup based on the list of installed catalogs.  this will be completely removed later.;;0;deprecate the datasources configuration property;this property if not set is now configured automatically at startup based onthe list of installed catalogs  this will be completely removed later;;;;;1;1;deprecate the datasources configuration propertythis property if not set is now configured automatically at startup basedon the list of installed catalogs  this will be completely removed later;
1327;1;0;0;1;1;1;0;0;1;1;1;0;1;1;0;0;0;0;1;0;1;0;1;1;0;1;0;remove dual connector;;;0;remove dual connector;;can you add an error message to `tupleanalyzervisittable` that lets users know that the dual table is no longer supported and they can use from-less select or values(x) instead? || ;;;;1;1;remove dual connector;
1328;1;0;0;0;1;0;0;0;0;0;0;1;0;0;0;0;0;0;1;0;0;1;1;1;0;1;0;rewrite explain to a values query;this helps avoid bytecode generation failures when plan string is too large due to max constant pool size being exceeded.;;0;rewrite explain to a values query;this helps avoid bytecode generation failures when plan string is too large dueto max constant pool size being exceeded;;;;;1;1;rewrite explain to a values querythis helps avoid bytecode generation failures when plan string is too large dueto max constant pool size being exceeded;
1329;1;0;0;1;1;1;1;0;0;1;1;1;1;1;0;0;1;0;1;0;1;1;0;1;0;1;0;fix tests for datasources change;;;0;fix tests for datasources change;;;;;;1;1;fix tests for datasources change;
1333;1;0;0;1;0;0;0;0;0;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix failing unit tests in java 8;the user.timezone property for the surefire plugin must match the setting via argline. the pom was inheriting the property from airbase set to utc  but argline was set to asia/katmandu.  as far as i can tell  the surefire plugin executes the following steps: - create a vm using the argline arguments - call setproperty for each systempropertyvariable - run the tests  unlike java 7  calling system.setproperty for user.timezone in java 8 after the vm is initialized has no effect. see d2fee8d93952054883bf94a65576cead632314cf for additional details;;0;fix failing unit tests in java 8;the usertimezone property for the surefire plugin must matchthe setting via argline the pom was inheriting the property fromairbase set to utc but argline was set to asia/katmanduas far as i can tell the surefire plugin executes the following steps:- create a vm using the argline arguments- call setproperty for each systempropertyvariable- run the testsunlike java 7 calling systemsetproperty for usertimezone in java 8 after the vm is initializedhas no effect see d2fee8d93952054883bf94a65576cead632314cf for additional details;;;;;1;1;fix failing unit test in java 8the expected stack overflow error occurs in the parser instead of in the analyzer in java 8;
1334;1;0;1;1;1;1;0;0;0;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;0;extract integration tests into separate module for reuse in connectors;;;0;extract integration tests into separate module for reuse in connectors;;;;;;1;1;change localqueryrunner to create and manage executor directly;
1335;1;0;0;0;0;1;0;0;0;1;0;0;0;0;0;0;1;0;1;0;0;0;0;0;0;0;0;replace unsafe constants with slice sizeof;;;0;replace unsafe constants with slice sizeof;;;;;;1;1;replace unsafe constants with slice sizeof;
1336;1;0;0;1;1;1;0;0;1;1;1;1;1;1;0;0;1;0;1;0;1;0;0;1;0;1;0;fix sql formatter;;;0;fix sql formatter;;;;;;1;1;fix sql formatterthis fixes the formatting of explicit table queries and adds missingformatters for certain constructs:* union except intersect* drop table* approximate atadditionally every local test query is verfied to round-trip;
1340;1;0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;1;0;fix hidden columns in union planning;;;0;fix hidden columns in union planning;;;;;;1;1;fix hidden columns in union planning;
1341;1;0;0;0;1;0;0;0;1;0;1;1;0;0;0;0;1;0;1;0;0;0;0;1;0;1;0;fix hive tests for varbinary;;;0;fix hive tests for varbinary;;;;;;1;1;fix hive tests for varbinary;
1342;1;0;0;1;1;1;0;0;0;0;1;1;0;1;0;0;1;0;1;0;0;0;0;0;0;0;0;cassandra patches;;;0;cassandra patches;;thank you these improvements are greatly appreciated! is this work in progress or supposed to be finished? im asking because were experiencing various problems after merging the pull request (mostly related to low-level cassandra connectivity)  || it is supposed to be finishedwhen testing this i had to increase the cassandra timeouts to get the tests to pass (  i have very little cassandra experience so any help would be greatly appreciated || we should fix the commit messages to match the standard format || @zirpins and i were able to hunt down the problem we encountered due to some reason only a single cassandraclient is being created (using a bunch of injections which i can not fully oversee) while a whole bunch of threads is using it cassandraclient is not thread safe the following patch gets rid of the problem we encountered but is not the optimum solution (which would be to get the injections to produce multiple cassandraclient instances):<pre><code>diff --git a/presto-cassandra/src/main/java/com/facebook/presto/cassandra/cassandratokensplitmanagerjava b/presto-cassandra/src/main/java/com/facebook/presto/cassandra/cassandratokensplitmanagerjavaindex 387fb937958652 100644--- a/presto-cassandra/src/main/java/com/facebook/presto/cassandra/cassandratokensplitmanagerjava+++ b/presto-cassandra/src/main/java/com/facebook/presto/cassandra/cassandratokensplitmanagerjava@@ -9328 +9336 @@             throws ioexception     {         try {-            return clientdescribe_ring(keyspace)+            synchronized (client) {+               return clientdescribe_ring(keyspace)+            }         }         catch (texception e) {             throw new runtimeexception(e)         }     } -    private static list<cfsplit> getsubsplits(string keyspace string columnfamily tokenrange range int splitsize cassandraclient client)-            throws ioexception+    private static list<cfsplit> getsubsplits(string keyspace+            string columnfamily tokenrange range int splitsize+            cassandraclient client) throws ioexception     {         try {-            clientset_keyspace(keyspace)-            try {-                return clientdescribe_splits_ex(columnfamily rangestart_token rangeend_token splitsize)-            }-            catch (tapplicationexception e) {-                // fallback to guessing split size if talking to a server without describe_splits_ex method-                if (egettype()  tapplicationexceptionunknown_method) {-                    list<string> splitpoints  clientdescribe_splits(columnfamily rangestart_token rangeend_token splitsize)-                    return tokenlisttosplits(splitpoints splitsize)+            synchronized (client) {+                clientset_keyspace(keyspace)+                try {+                    return clientdescribe_splits_ex(columnfamily rangestart_token rangeend_token splitsize)                 }-                throw e+                catch (tapplicationexception e) {+                    // fallback to guessing split size if talking to a server+                    // without describe_splits_ex method+                    if (egettype()  tapplicationexceptionunknown_method) {+                        list<string> splitpoints  clientdescribe_splits(+                                columnfamily rangestart_token+                                rangeend_token splitsize)+                       return tokenlisttosplits(splitpoints splitsize)+                    }+                    throw e+                }             }         }         catch (texception e) {</code></pre> || awesome!  ill try this out || maybe include #1312 would really help us out || @flxrobin i will || thanks a lot || i think you should squash 77072ba  d365e81 37b4d28 and 232f8ed because theyre very difficult to review as-is since the latter commits fix bugs in the earlier ones || ;;;;1;1;add cassandra authentication credentials;
